{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Sample BigCode Results Comparison\n",
    "\n",
    "Enhanced analysis for comparing CAA vs Unsteered results with n_samples > 1.\n",
    "Includes task-level pass@k analysis, per-sample success rates, and completion patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CAA Results: /workspace/wisent-guard/evaluation_results/caa_mbppplus_20250822_131751/consolidated_results_20250822_131751.json\n",
      "Unsteered Results: /workspace/wisent-guard/evaluation_results/unsteered_mbppplus_20250822_144202/consolidated_results_20250822_144202.json\n"
     ]
    }
   ],
   "source": [
    "ROOT_PATH = \"/workspace/wisent-guard/\"\n",
    "\n",
    "# File paths - modify these to compare different results\n",
    "CAA_RESULTS_PATH = ROOT_PATH + \"evaluation_results/caa_mbppplus_20250822_131751/consolidated_results_20250822_131751.json\"\n",
    "UNSTEERED_RESULTS_PATH = ROOT_PATH + \"evaluation_results/unsteered_mbppplus_20250822_144202/consolidated_results_20250822_144202.json\"\n",
    "\n",
    "print(f\"CAA Results: {CAA_RESULTS_PATH}\")\n",
    "print(f\"Unsteered Results: {UNSTEERED_RESULTS_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Examine Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Data Overview ===\n",
      "CAA: 3780 completions\n",
      "Unsteered: 3780 completions\n",
      "CAA: 378 tasks, 10.0 samples per task\n",
      "Unsteered: 378 tasks, 10.0 samples per task\n",
      "\n",
      "CAA columns: ['task_id', 'completion_id', 'generation', 'reference', 'passed', 'result']\n",
      "Unsteered columns: ['task_id', 'completion_id', 'generation', 'reference', 'passed', 'result']\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "with open(CAA_RESULTS_PATH, \"r\") as f:\n",
    "    caa_data = json.load(f)\n",
    "with open(UNSTEERED_RESULTS_PATH, \"r\") as f:\n",
    "    unsteered_data = json.load(f)\n",
    "\n",
    "# Create DataFrames\n",
    "df_caa = pd.DataFrame(caa_data[\"detailed_results\"])\n",
    "df_unsteered = pd.DataFrame(unsteered_data[\"detailed_results\"])\n",
    "\n",
    "print(\"=== Data Overview ===\")\n",
    "print(f\"CAA: {len(df_caa)} completions\")\n",
    "print(f\"Unsteered: {len(df_unsteered)} completions\")\n",
    "\n",
    "if 'completion_id' in df_caa.columns:\n",
    "    caa_tasks = df_caa['task_id'].nunique()\n",
    "    caa_samples_per_task = len(df_caa) / caa_tasks\n",
    "    print(f\"CAA: {caa_tasks} tasks, {caa_samples_per_task:.1f} samples per task\")\n",
    "\n",
    "if 'completion_id' in df_unsteered.columns:\n",
    "    unsteered_tasks = df_unsteered['task_id'].nunique()\n",
    "    unsteered_samples_per_task = len(df_unsteered) / unsteered_tasks\n",
    "    print(f\"Unsteered: {unsteered_tasks} tasks, {unsteered_samples_per_task:.1f} samples per task\")\n",
    "\n",
    "print(f\"\\nCAA columns: {list(df_caa.columns)}\")\n",
    "print(f\"Unsteered columns: {list(df_unsteered.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task-Level Analysis (Pass@K Logic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Task-Level Results ===\n",
      "Total tasks compared: 378\n",
      "\n",
      "CAA: 295 / 378 tasks passed (0.780)\n",
      "Unsteered: 296 / 378 tasks passed (0.783)\n",
      "\n",
      "Average pass rate per task:\n",
      "CAA: 0.660\n",
      "Unsteered: 0.673\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>caa_task_passed</th>\n",
       "      <th>caa_num_passed</th>\n",
       "      <th>caa_total_attempts</th>\n",
       "      <th>caa_pass_rate</th>\n",
       "      <th>unsteered_task_passed</th>\n",
       "      <th>unsteered_num_passed</th>\n",
       "      <th>unsteered_total_attempts</th>\n",
       "      <th>unsteered_pass_rate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>task_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.2</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>0.7</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         caa_task_passed  caa_num_passed  caa_total_attempts  caa_pass_rate  \\\n",
       "task_id                                                                       \n",
       "0                   True              10                  10            1.0   \n",
       "1                   True              10                  10            1.0   \n",
       "2                   True              10                  10            1.0   \n",
       "3                  False               0                  10            0.0   \n",
       "4                   True              10                  10            1.0   \n",
       "5                   True              10                  10            1.0   \n",
       "6                   True               2                  10            0.2   \n",
       "7                   True               7                  10            0.7   \n",
       "8                   True              10                  10            1.0   \n",
       "9                   True              10                  10            1.0   \n",
       "\n",
       "         unsteered_task_passed  unsteered_num_passed  \\\n",
       "task_id                                                \n",
       "0                         True                    10   \n",
       "1                         True                     7   \n",
       "2                         True                    10   \n",
       "3                        False                     0   \n",
       "4                         True                    10   \n",
       "5                         True                    10   \n",
       "6                         True                     1   \n",
       "7                         True                     9   \n",
       "8                         True                    10   \n",
       "9                         True                    10   \n",
       "\n",
       "         unsteered_total_attempts  unsteered_pass_rate  \n",
       "task_id                                                 \n",
       "0                              10                  1.0  \n",
       "1                              10                  0.7  \n",
       "2                              10                  1.0  \n",
       "3                              10                  0.0  \n",
       "4                              10                  1.0  \n",
       "5                              10                  1.0  \n",
       "6                              10                  0.1  \n",
       "7                              10                  0.9  \n",
       "8                              10                  1.0  \n",
       "9                              10                  1.0  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group by task_id and calculate task-level pass status (pass@k logic)\n",
    "def calculate_task_level_results(df, method_name):\n",
    "    \"\"\"Calculate task-level pass/fail status using pass@k logic (ANY completion passes = task passes)\"\"\"\n",
    "    task_results = df.groupby('task_id').agg({\n",
    "        'passed': ['any', 'sum', 'count']  # any=task_passed, sum=num_passed, count=total_attempts\n",
    "    }).round(3)\n",
    "    \n",
    "    # Flatten column names\n",
    "    task_results.columns = [f'{method_name}_task_passed', f'{method_name}_num_passed', f'{method_name}_total_attempts']\n",
    "    \n",
    "    # Calculate pass rate per task (num_passed / total_attempts)\n",
    "    task_results[f'{method_name}_pass_rate'] = (\n",
    "        task_results[f'{method_name}_num_passed'] / task_results[f'{method_name}_total_attempts']\n",
    "    ).round(3)\n",
    "    \n",
    "    return task_results\n",
    "\n",
    "# Calculate task-level results\n",
    "caa_task_results = calculate_task_level_results(df_caa, 'caa')\n",
    "unsteered_task_results = calculate_task_level_results(df_unsteered, 'unsteered')\n",
    "\n",
    "# Merge task-level results\n",
    "task_comparison = pd.merge(caa_task_results, unsteered_task_results, left_index=True, right_index=True, how='inner')\n",
    "\n",
    "print(\"=== Task-Level Results ===\")\n",
    "print(f\"Total tasks compared: {len(task_comparison)}\")\n",
    "print(f\"\\nCAA: {task_comparison['caa_task_passed'].sum()} / {len(task_comparison)} tasks passed ({task_comparison['caa_task_passed'].mean():.3f})\")\n",
    "print(f\"Unsteered: {task_comparison['unsteered_task_passed'].sum()} / {len(task_comparison)} tasks passed ({task_comparison['unsteered_task_passed'].mean():.3f})\")\n",
    "\n",
    "print(f\"\\nAverage pass rate per task:\")\n",
    "print(f\"CAA: {task_comparison['caa_pass_rate'].mean():.3f}\")\n",
    "print(f\"Unsteered: {task_comparison['unsteered_pass_rate'].mean():.3f}\")\n",
    "\n",
    "task_comparison.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XOR Analysis: Tasks Where Methods Differ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== XOR ANALYSIS (Task-Level Differences) ===\n",
      "Tasks where both methods agree: 357\n",
      "  - Both pass: 285 tasks\n",
      "  - Both fail: 72 tasks\n",
      "\n",
      "Tasks where methods differ: 21\n",
      "  - CAA passes, Unsteered fails: 10 tasks\n",
      "  - Unsteered passes, CAA fails: 11 tasks\n",
      "\n",
      "=== TASK IDs WHERE RESULTS DIFFER ===\n",
      "\n",
      "CAA WINS (10 tasks): [25, 30, 33, 53, 235, 275, 288, 321, 330, 366]\n",
      "\n",
      "UNSTEERED WINS (11 tasks): [52, 61, 71, 148, 168, 177, 206, 223, 276, 308, 339]\n"
     ]
    }
   ],
   "source": [
    "# Find tasks where pass/fail status differs (XOR at task level)\n",
    "task_comparison['xor_diff'] = task_comparison['caa_task_passed'] ^ task_comparison['unsteered_task_passed']\n",
    "\n",
    "# Categorize differences\n",
    "caa_wins = task_comparison[\n",
    "    task_comparison['caa_task_passed'] & ~task_comparison['unsteered_task_passed']\n",
    "]\n",
    "\n",
    "unsteered_wins = task_comparison[\n",
    "    ~task_comparison['caa_task_passed'] & task_comparison['unsteered_task_passed']\n",
    "]\n",
    "\n",
    "both_pass = task_comparison[\n",
    "    task_comparison['caa_task_passed'] & task_comparison['unsteered_task_passed']\n",
    "]\n",
    "\n",
    "both_fail = task_comparison[\n",
    "    ~task_comparison['caa_task_passed'] & ~task_comparison['unsteered_task_passed']\n",
    "]\n",
    "\n",
    "print(\"=== XOR ANALYSIS (Task-Level Differences) ===\")\n",
    "print(f\"Tasks where both methods agree: {len(both_pass) + len(both_fail)}\")\n",
    "print(f\"  - Both pass: {len(both_pass)} tasks\")\n",
    "print(f\"  - Both fail: {len(both_fail)} tasks\")\n",
    "print(f\"\\nTasks where methods differ: {len(caa_wins) + len(unsteered_wins)}\")\n",
    "print(f\"  - CAA passes, Unsteered fails: {len(caa_wins)} tasks\")\n",
    "print(f\"  - Unsteered passes, CAA fails: {len(unsteered_wins)} tasks\")\n",
    "\n",
    "print(f\"\\n=== TASK IDs WHERE RESULTS DIFFER ===\")\n",
    "if len(caa_wins) > 0:\n",
    "    print(f\"\\nCAA WINS ({len(caa_wins)} tasks): {sorted(caa_wins.index.tolist())}\")\n",
    "    \n",
    "if len(unsteered_wins) > 0:\n",
    "    print(f\"\\nUNSTEERED WINS ({len(unsteered_wins)} tasks): {sorted(unsteered_wins.index.tolist())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Per-Sample Success Rate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== PER-SAMPLE SUCCESS RATES ===\n",
      "               caa_count  caa_passed  caa_rate  unsteered_count  \\\n",
      "completion_id                                                     \n",
      "0                    378         248     0.656              378   \n",
      "1                    378         252     0.667              378   \n",
      "2                    378         252     0.667              378   \n",
      "3                    378         247     0.653              378   \n",
      "4                    378         250     0.661              378   \n",
      "5                    378         248     0.656              378   \n",
      "6                    378         242     0.640              378   \n",
      "7                    378         259     0.685              378   \n",
      "8                    378         247     0.653              378   \n",
      "9                    378         248     0.656              378   \n",
      "\n",
      "               unsteered_passed  unsteered_rate  \n",
      "completion_id                                    \n",
      "0                           250           0.661  \n",
      "1                           256           0.677  \n",
      "2                           262           0.693  \n",
      "3                           252           0.667  \n",
      "4                           256           0.677  \n",
      "5                           260           0.688  \n",
      "6                           254           0.672  \n",
      "7                           248           0.656  \n",
      "8                           253           0.669  \n",
      "9                           254           0.672  \n",
      "\n",
      "=== AVERAGE OF AVERAGES ===\n",
      "CAA average across all samples: 0.659\n",
      "Unsteered average across all samples: 0.673\n",
      "CAA improvement: -0.014\n"
     ]
    }
   ],
   "source": [
    "# Analyze per-sample (completion_id) success rates\n",
    "def analyze_per_sample_rates(df, method_name):\n",
    "    \"\"\"Calculate success rate for each completion_id (sample)\"\"\"\n",
    "    if 'completion_id' not in df.columns:\n",
    "        print(f\"{method_name}: No completion_id column found - assuming single sample per task\")\n",
    "        return pd.DataFrame({f'{method_name}_sample_0': [df['passed'].mean()]})\n",
    "    \n",
    "    per_sample = df.groupby('completion_id')['passed'].agg(['count', 'sum', 'mean']).round(3)\n",
    "    per_sample.columns = [f'{method_name}_count', f'{method_name}_passed', f'{method_name}_rate']\n",
    "    return per_sample\n",
    "\n",
    "# Calculate per-sample rates\n",
    "caa_per_sample = analyze_per_sample_rates(df_caa, 'caa')\n",
    "unsteered_per_sample = analyze_per_sample_rates(df_unsteered, 'unsteered')\n",
    "\n",
    "# Merge per-sample results\n",
    "per_sample_comparison = pd.merge(\n",
    "    caa_per_sample, unsteered_per_sample, \n",
    "    left_index=True, right_index=True, how='outer'\n",
    ").fillna(0)\n",
    "\n",
    "print(\"=== PER-SAMPLE SUCCESS RATES ===\")\n",
    "print(per_sample_comparison)\n",
    "\n",
    "if len(per_sample_comparison) > 1:\n",
    "    print(f\"\\n=== AVERAGE OF AVERAGES ===\")\n",
    "    caa_avg_of_avgs = per_sample_comparison['caa_rate'].mean()\n",
    "    unsteered_avg_of_avgs = per_sample_comparison['unsteered_rate'].mean()\n",
    "    \n",
    "    print(f\"CAA average across all samples: {caa_avg_of_avgs:.3f}\")\n",
    "    print(f\"Unsteered average across all samples: {unsteered_avg_of_avgs:.3f}\")\n",
    "    print(f\"CAA improvement: {caa_avg_of_avgs - unsteered_avg_of_avgs:+.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Completion Pattern Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== FIRST SUCCESS TIMING DISTRIBUTION ===\n",
      "               caa_count  unsteered_count\n",
      "completion_id                            \n",
      "0                    248              250\n",
      "1                     23               20\n",
      "2                      7               10\n",
      "3                      4                4\n",
      "4                      5                2\n",
      "5                      1                5\n",
      "6                      0                1\n",
      "7                      4                1\n",
      "8                      2                0\n",
      "9                      1                3\n",
      "\n",
      "=== SUCCESS TIMING STATS ===\n",
      "CAA average first success at completion: 0.43\n",
      "Unsteered average first success at completion: 0.42\n"
     ]
    }
   ],
   "source": [
    "# Analyze when tasks first succeed (completion timing)\n",
    "def analyze_first_success_patterns(df, method_name):\n",
    "    \"\"\"Find the first completion_id where each task succeeds\"\"\"\n",
    "    if 'completion_id' not in df.columns:\n",
    "        return None\n",
    "        \n",
    "    # Find first success for each task\n",
    "    successful_completions = df[df['passed'] == True].copy()\n",
    "    first_success = successful_completions.groupby('task_id')['completion_id'].min()\n",
    "    \n",
    "    # Count distribution of first success timing\n",
    "    first_success_dist = first_success.value_counts().sort_index()\n",
    "    \n",
    "    return first_success_dist, first_success\n",
    "\n",
    "# Analyze completion patterns\n",
    "caa_first_success_dist, caa_first_success = analyze_first_success_patterns(df_caa, 'caa')\n",
    "unsteered_first_success_dist, unsteered_first_success = analyze_first_success_patterns(df_unsteered, 'unsteered')\n",
    "\n",
    "if caa_first_success_dist is not None and unsteered_first_success_dist is not None:\n",
    "    print(\"=== FIRST SUCCESS TIMING DISTRIBUTION ===\")\n",
    "    timing_comparison = pd.DataFrame({\n",
    "        'caa_count': caa_first_success_dist,\n",
    "        'unsteered_count': unsteered_first_success_dist\n",
    "    }).fillna(0).astype(int)\n",
    "    \n",
    "    print(timing_comparison)\n",
    "    \n",
    "    print(f\"\\n=== SUCCESS TIMING STATS ===\")\n",
    "    if len(caa_first_success) > 0:\n",
    "        print(f\"CAA average first success at completion: {caa_first_success.mean():.2f}\")\n",
    "    if len(unsteered_first_success) > 0:\n",
    "        print(f\"Unsteered average first success at completion: {unsteered_first_success.mean():.2f}\")\n",
    "else:\n",
    "    print(\"=== COMPLETION PATTERN ANALYSIS ===\")\n",
    "    print(\"Single sample per task - no timing patterns to analyze\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detailed Analysis of Differing Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== CAA WINS - DETAILED BREAKDOWN ===\n",
      "\n",
      "Task 25:\n",
      "  CAA: 2/10 completions passed (0.20)\n",
      "  Unsteered: 0/10 completions passed (0.00)\n",
      "\n",
      "Task 30:\n",
      "  CAA: 1/10 completions passed (0.10)\n",
      "  Unsteered: 0/10 completions passed (0.00)\n",
      "\n",
      "Task 33:\n",
      "  CAA: 2/10 completions passed (0.20)\n",
      "  Unsteered: 0/10 completions passed (0.00)\n",
      "\n",
      "Task 53:\n",
      "  CAA: 1/10 completions passed (0.10)\n",
      "  Unsteered: 0/10 completions passed (0.00)\n",
      "\n",
      "Task 235:\n",
      "  CAA: 1/10 completions passed (0.10)\n",
      "  Unsteered: 0/10 completions passed (0.00)\n",
      "\n",
      "Task 275:\n",
      "  CAA: 5/10 completions passed (0.50)\n",
      "  Unsteered: 0/10 completions passed (0.00)\n",
      "\n",
      "Task 288:\n",
      "  CAA: 1/10 completions passed (0.10)\n",
      "  Unsteered: 0/10 completions passed (0.00)\n",
      "\n",
      "Task 321:\n",
      "  CAA: 1/10 completions passed (0.10)\n",
      "  Unsteered: 0/10 completions passed (0.00)\n",
      "\n",
      "Task 330:\n",
      "  CAA: 1/10 completions passed (0.10)\n",
      "  Unsteered: 0/10 completions passed (0.00)\n",
      "\n",
      "Task 366:\n",
      "  CAA: 1/10 completions passed (0.10)\n",
      "  Unsteered: 0/10 completions passed (0.00)\n",
      "\n",
      "=== UNSTEERED WINS - DETAILED BREAKDOWN ===\n",
      "\n",
      "Task 52:\n",
      "  CAA: 0/10 completions passed (0.00)\n",
      "  Unsteered: 1/10 completions passed (0.10)\n",
      "\n",
      "Task 61:\n",
      "  CAA: 0/10 completions passed (0.00)\n",
      "  Unsteered: 1/10 completions passed (0.10)\n",
      "\n",
      "Task 71:\n",
      "  CAA: 0/10 completions passed (0.00)\n",
      "  Unsteered: 1/10 completions passed (0.10)\n",
      "\n",
      "Task 148:\n",
      "  CAA: 0/10 completions passed (0.00)\n",
      "  Unsteered: 2/10 completions passed (0.20)\n",
      "\n",
      "Task 168:\n",
      "  CAA: 0/10 completions passed (0.00)\n",
      "  Unsteered: 3/10 completions passed (0.30)\n",
      "\n",
      "Task 177:\n",
      "  CAA: 0/10 completions passed (0.00)\n",
      "  Unsteered: 4/10 completions passed (0.40)\n",
      "\n",
      "Task 206:\n",
      "  CAA: 0/10 completions passed (0.00)\n",
      "  Unsteered: 1/10 completions passed (0.10)\n",
      "\n",
      "Task 223:\n",
      "  CAA: 0/10 completions passed (0.00)\n",
      "  Unsteered: 3/10 completions passed (0.30)\n",
      "\n",
      "Task 276:\n",
      "  CAA: 0/10 completions passed (0.00)\n",
      "  Unsteered: 3/10 completions passed (0.30)\n",
      "\n",
      "Task 308:\n",
      "  CAA: 0/10 completions passed (0.00)\n",
      "  Unsteered: 6/10 completions passed (0.60)\n",
      "\n",
      "Task 339:\n",
      "  CAA: 0/10 completions passed (0.00)\n",
      "  Unsteered: 2/10 completions passed (0.20)\n"
     ]
    }
   ],
   "source": [
    "# Detailed breakdown of differing tasks\n",
    "def analyze_task_details(task_ids, df_caa, df_unsteered, title):\n",
    "    \"\"\"Show detailed completion patterns for specific tasks\"\"\"\n",
    "    if len(task_ids) == 0:\n",
    "        return\n",
    "        \n",
    "    print(f\"\\n=== {title} ===\")\n",
    "    \n",
    "    for task_id in sorted(task_ids):  # Limit to first 10 for readability\n",
    "        print(f\"\\nTask {task_id}:\")\n",
    "        \n",
    "        # CAA details\n",
    "        caa_task = df_caa[df_caa['task_id'] == task_id]\n",
    "        if len(caa_task) > 0:\n",
    "            caa_passed = caa_task['passed'].sum()\n",
    "            caa_total = len(caa_task)\n",
    "            print(f\"  CAA: {caa_passed}/{caa_total} completions passed ({caa_passed/caa_total:.2f})\")\n",
    "            \n",
    "        # Unsteered details\n",
    "        unsteered_task = df_unsteered[df_unsteered['task_id'] == task_id]\n",
    "        if len(unsteered_task) > 0:\n",
    "            unsteered_passed = unsteered_task['passed'].sum()\n",
    "            unsteered_total = len(unsteered_task)\n",
    "            print(f\"  Unsteered: {unsteered_passed}/{unsteered_total} completions passed ({unsteered_passed/unsteered_total:.2f})\")\n",
    "\n",
    "# Show details for differing tasks\n",
    "if len(caa_wins) > 0:\n",
    "    analyze_task_details(caa_wins.index.tolist(), df_caa, df_unsteered, \"CAA WINS - DETAILED BREAKDOWN\")\n",
    "\n",
    "if len(unsteered_wins) > 0:\n",
    "    analyze_task_details(unsteered_wins.index.tolist(), df_caa, df_unsteered, \"UNSTEERED WINS - DETAILED BREAKDOWN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 25,  30,  33,  53, 235, 275, 288, 321, 330, 366])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find task_ids where CAA wins\n",
    "caa_win_task_ids = caa_wins.index.tolist()\n",
    "\n",
    "# Filter all_detailed_results for these tasks and both methods\n",
    "caa_vs_unsteered = all_detailed_results[\n",
    "    (all_detailed_results['task_id'].isin(caa_win_task_ids))\n",
    "]\n",
    "\n",
    "# For each task, check if any unsteered generation does NOT end with '\"\"\"'\n",
    "def unsteered_produced_output(group):\n",
    "    unsteered = group[group['method'] == 'unsteered']\n",
    "    # True if any unsteered generation does NOT end with triple quotes\n",
    "    return any(not str(gen).strip().endswith('\"\"\"') for gen in unsteered['generation'])\n",
    "\n",
    "# Group by task_id and filter\n",
    "tasks_with_unsteered_output = (\n",
    "    caa_vs_unsteered.groupby('task_id')\n",
    "    .filter(unsteered_produced_output)\n",
    "    ['task_id']\n",
    "    .unique()\n",
    ")\n",
    "\n",
    "# Prepare a DataFrame with these tasks, showing both CAA and unsteered generations\n",
    "examples = caa_vs_unsteered[\n",
    "    caa_vs_unsteered['task_id'].isin(tasks_with_unsteered_output)\n",
    "].sort_values(['task_id', 'method', 'completion_id'])\n",
    "\n",
    "# Show a sample (first 10 tasks) for review\n",
    "examples.task_id.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== EXPORTING RESULTS TO EXCEL ===\n",
      "✅ All detailed results saved to: /workspace/wisent-guard/all_detailed_results.xlsx\n",
      "✅ Task-level comparison saved to: /workspace/wisent-guard/task_level_comparison.xlsx\n",
      "✅ Per-sample comparison saved to: /workspace/wisent-guard/per_sample_comparison.xlsx\n"
     ]
    }
   ],
   "source": [
    "print(\"=== EXPORTING RESULTS TO EXCEL ===\")\n",
    "\n",
    "# Export all detailed results\n",
    "all_detailed_results.to_excel(ROOT_PATH + \"all_detailed_results.xlsx\", index=False)\n",
    "print(f\"✅ All detailed results saved to: {ROOT_PATH}all_detailed_results.xlsx\")\n",
    "\n",
    "# Export task-level comparison\n",
    "task_comparison.to_excel(ROOT_PATH + \"task_level_comparison.xlsx\")\n",
    "print(f\"✅ Task-level comparison saved to: {ROOT_PATH}task_level_comparison.xlsx\")\n",
    "\n",
    "# Export per-sample comparison\n",
    "per_sample_comparison.to_excel(ROOT_PATH + \"per_sample_comparison.xlsx\")\n",
    "print(f\"✅ Per-sample comparison saved to: {ROOT_PATH}per_sample_comparison.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
