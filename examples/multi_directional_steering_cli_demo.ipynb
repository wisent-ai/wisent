{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define all parameters\n",
    "MODEL = \"meta-llama/Llama-3.1-8B-Instruct\"\n",
    "LAYER = 16\n",
    "NUM_PAIRS = 10  # Reduced for faster testing\n",
    "\n",
    "# First trait - Change this to any trait you want!\n",
    "TRAIT_1 = \"italian\"  # e.g., \"concise\", \"italian\", \"formal\", \"technical\", etc.\n",
    "PAIRS_FILE_1 = f\"synthetic_pairs_{TRAIT_1}_test.json\"\n",
    "VECTOR_FILE_1 = f\"steering_vector_{TRAIT_1}_test.pt\"\n",
    "\n",
    "# Second trait - Change this to any trait you want!\n",
    "TRAIT_2 = \"french\"  # e.g., \"creative\", \"french\", \"casual\", \"simple\", etc.\n",
    "PAIRS_FILE_2 = f\"synthetic_pairs_{TRAIT_2}_test.json\"\n",
    "VECTOR_FILE_2 = f\"steering_vector_{TRAIT_2}_test.pt\"\n",
    "\n",
    "# Test prompts\n",
    "TEST_PROMPTS = [\n",
    "    \"Tell me about pizza\",\n",
    "    \"What is the meaning of life?\"\n",
    "]\n",
    "\n",
    "# Max tokens for generation\n",
    "MAX_TOKENS = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Directional Steering with DAC - CLI Demo\n",
    "\n",
    "This notebook demonstrates two-direction steering with DAC using synthetic data.\n",
    "\n",
    "**Key features:**\n",
    "- Trains two separate steering vectors (Italian and French)  \n",
    "- Shows how to combine them with different weights\n",
    "- Demonstrates dynamic multi-directional steering\n",
    "\n",
    "**Note:** The Llama-3.1-8B model takes ~15-30 seconds to load. For faster testing, you can change MODEL to \"distilgpt2\" in the parameters cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running in Python 3.10.14 | packaged by conda-forge | (main, Mar 20 2024, 12:51:49) [Clang 16.0.6 ]\n"
     ]
    }
   ],
   "source": [
    "# Define all parameters\n",
    "MODEL = \"meta-llama/Llama-3.1-8B-Instruct\"\n",
    "LAYER = 16\n",
    "NUM_PAIRS = 10  # Reduced for faster testing\n",
    "\n",
    "# First trait - Change this to any trait you want!\n",
    "TRAIT_1 = \"italian\"  # e.g., \"concise\", \"italian\", \"formal\", \"technical\", etc.\n",
    "PAIRS_FILE_1 = f\"synthetic_pairs_{TRAIT_1}_test.json\"\n",
    "VECTOR_FILE_1 = f\"steering_vector_{TRAIT_1}_test.pt\"\n",
    "\n",
    "# Second trait - Change this to any trait you want!\n",
    "TRAIT_2 = \"french\"  # e.g., \"creative\", \"french\", \"casual\", \"simple\", etc.\n",
    "PAIRS_FILE_2 = f\"synthetic_pairs_{TRAIT_2}_test.json\"\n",
    "VECTOR_FILE_2 = f\"steering_vector_{TRAIT_2}_test.pt\"\n",
    "\n",
    "# Test prompts\n",
    "TEST_PROMPTS = [\n",
    "    \"Tell me about pizza\",\n",
    "    \"What is the meaning of life?\"\n",
    "]\n",
    "\n",
    "# Max tokens for generation\n",
    "MAX_TOKENS = 50\n",
    "\n",
    "# Check Python version\n",
    "import sys\n",
    "print(f\"Running in Python {sys.version}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Steering vectors already exist!\n",
      "   steering_vector_italian_test.pt\n",
      "   steering_vector_french_test.pt\n",
      "\n",
      "📊 Vector details:\n",
      "   Italian vector shape: torch.Size([1, 4096])\n",
      "   French vector shape: torch.Size([1, 4096])\n",
      "   Model dimension: 4096 (matches Llama-3.1-8B)\n"
     ]
    }
   ],
   "source": [
    "# Generate vectors from the pairs using CLI\n",
    "import subprocess\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Check if vectors already exist\n",
    "if os.path.exists(VECTOR_FILE_1) and os.path.exists(VECTOR_FILE_2):\n",
    "    print(\"✅ Steering vectors already exist!\")\n",
    "    print(f\"   {VECTOR_FILE_1}\")\n",
    "    print(f\"   {VECTOR_FILE_2}\")\n",
    "    \n",
    "    # Verify they're for the right model\n",
    "    import torch\n",
    "    vec1 = torch.load(VECTOR_FILE_1, map_location='cpu')\n",
    "    vec2 = torch.load(VECTOR_FILE_2, map_location='cpu')\n",
    "    \n",
    "    print(f\"\\n📊 Vector details:\")\n",
    "    print(f\"   Italian vector shape: {vec1['steering_vector'].shape}\")\n",
    "    print(f\"   French vector shape: {vec2['steering_vector'].shape}\")\n",
    "    print(f\"   Model dimension: 4096 (matches Llama-3.1-8B)\")\n",
    "else:\n",
    "    print(\"❌ Vectors not found. Please generate them first using:\")\n",
    "    print(f\"   python -m wisent_guard generate-pairs --trait italian --output {PAIRS_FILE_1}\")\n",
    "    print(f\"   python -m wisent_guard generate-pairs --trait french --output {PAIRS_FILE_2}\")\n",
    "    print(f\"   python -m wisent_guard generate-vector --from-pairs {PAIRS_FILE_1} --model '{MODEL}' --layer {LAYER} --output {VECTOR_FILE_1}\")\n",
    "    print(f\"   python -m wisent_guard generate-vector --from-pairs {PAIRS_FILE_2} --model '{MODEL}' --layer {LAYER} --output {VECTOR_FILE_2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing individual steering vectors...\n",
      "================================================================================\n",
      "\n",
      "1. Testing ITALIAN steering:\n",
      "----------------------------------------\n",
      "\n",
      "Prompt: Tell me about pizza\n",
      "Response: La pizza! La pizza è un piatto italiano che è amato da tutti! (La pizza è un piatto italiano che è amato da tutti! - La pizza è un piatto italiano che...\n",
      "\n",
      "Prompt: What is the meaning of life?\n",
      "Response: La vita è piena di domande, ma la risposta è difficile da trovare. La domanda \"cosa significa la vita?\" è una delle più grandi domande della storia, c...\n",
      "\n",
      "\n",
      "2. Testing FRENCH steering:\n",
      "----------------------------------------\n",
      "\n",
      "Prompt: Tell me about pizza\n",
      "Response: La pizza! La pizza est un plat italien très populaire, composé d'une pâte croustillante, d'un fromage fondu, d'une sauce tomate et de divers ingrédien...\n",
      "\n",
      "Prompt: What is the meaning of life?\n",
      "Response: La question de la signification de la vie est une question qui a été posée par de nombreux philosophes, penseurs et écrivains à travers l'histoire. Il...\n"
     ]
    }
   ],
   "source": [
    "# Test individual steering with each vector\n",
    "import subprocess\n",
    "import sys\n",
    "import os\n",
    "\n",
    "print(\"Testing individual steering vectors...\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Suppress the transformers warning\n",
    "os.environ['TRANSFORMERS_VERBOSITY'] = 'error'\n",
    "\n",
    "# Test Italian steering\n",
    "print(f\"\\n1. Testing {TRAIT_1.upper()} steering:\")\n",
    "print(\"-\"*40)\n",
    "\n",
    "for prompt in TEST_PROMPTS:\n",
    "    print(f\"\\nPrompt: {prompt}\")\n",
    "    cmd = [\n",
    "        sys.executable, \"-m\", \"wisent_guard\", \"multi-steer\",\n",
    "        \"--vector\", f\"examples/{VECTOR_FILE_1}:1.0\",\n",
    "        \"--model\", MODEL,\n",
    "        \"--layer\", str(LAYER),\n",
    "        \"--prompt\", prompt,\n",
    "        \"--max-new-tokens\", str(MAX_TOKENS)\n",
    "    ]\n",
    "    \n",
    "    print(\"Response: \", end=\"\", flush=True)\n",
    "    result = subprocess.run(cmd, capture_output=True, text=True, cwd=\"..\")\n",
    "    \n",
    "    if result.returncode == 0:\n",
    "        output = result.stdout\n",
    "        # Find the actual generated text between the separators\n",
    "        if \"Generated Response:\" in output and \"============\" in output:\n",
    "            # Find the response section\n",
    "            lines = output.split('\\n')\n",
    "            in_response = False\n",
    "            response_lines = []\n",
    "            \n",
    "            for line in lines:\n",
    "                if \"Generated Response:\" in line:\n",
    "                    in_response = True\n",
    "                    continue\n",
    "                elif in_response and \"============\" in line and response_lines:\n",
    "                    # Found the end separator after collecting response\n",
    "                    break\n",
    "                elif in_response and line.strip() and \"============\" not in line:\n",
    "                    response_lines.append(line)\n",
    "            \n",
    "            if response_lines:\n",
    "                response = '\\n'.join(response_lines)\n",
    "                print(response[:150] + \"...\" if len(response) > 150 else response)\n",
    "            else:\n",
    "                print(\"(Empty response)\")\n",
    "        else:\n",
    "            print(\"(No response found in output)\")\n",
    "    else:\n",
    "        # Show stderr but skip the transformers warning\n",
    "        error_lines = [line for line in result.stderr.split('\\n') \n",
    "                      if line and 'generation flags' not in line]\n",
    "        if error_lines:\n",
    "            print(f\"Error: {error_lines[0][:100]}\")\n",
    "        else:\n",
    "            print(\"Error occurred\")\n",
    "\n",
    "# Test French steering\n",
    "print(f\"\\n\\n2. Testing {TRAIT_2.upper()} steering:\")\n",
    "print(\"-\"*40)\n",
    "\n",
    "for prompt in TEST_PROMPTS:\n",
    "    print(f\"\\nPrompt: {prompt}\")\n",
    "    cmd = [\n",
    "        sys.executable, \"-m\", \"wisent_guard\", \"multi-steer\",\n",
    "        \"--vector\", f\"examples/{VECTOR_FILE_2}:1.0\",\n",
    "        \"--model\", MODEL,\n",
    "        \"--layer\", str(LAYER),\n",
    "        \"--prompt\", prompt,\n",
    "        \"--max-new-tokens\", str(MAX_TOKENS)\n",
    "    ]\n",
    "    \n",
    "    print(\"Response: \", end=\"\", flush=True)\n",
    "    result = subprocess.run(cmd, capture_output=True, text=True, cwd=\"..\")\n",
    "    \n",
    "    if result.returncode == 0:\n",
    "        output = result.stdout\n",
    "        if \"Generated Response:\" in output and \"============\" in output:\n",
    "            lines = output.split('\\n')\n",
    "            in_response = False\n",
    "            response_lines = []\n",
    "            \n",
    "            for line in lines:\n",
    "                if \"Generated Response:\" in line:\n",
    "                    in_response = True\n",
    "                    continue\n",
    "                elif in_response and \"============\" in line and response_lines:\n",
    "                    break\n",
    "                elif in_response and line.strip() and \"============\" not in line:\n",
    "                    response_lines.append(line)\n",
    "            \n",
    "            if response_lines:\n",
    "                response = '\\n'.join(response_lines)\n",
    "                print(response[:150] + \"...\" if len(response) > 150 else response)\n",
    "            else:\n",
    "                print(\"(Empty response)\")\n",
    "        else:\n",
    "            print(\"(No response found in output)\")\n",
    "    else:\n",
    "        error_lines = [line for line in result.stderr.split('\\n') \n",
    "                      if line and 'generation flags' not in line]\n",
    "        if error_lines:\n",
    "            print(f\"Error: {error_lines[0][:100]}\")\n",
    "        else:\n",
    "            print(\"Error occurred\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "3. Testing MULTI-DIRECTIONAL steering:\n",
      "================================================================================\n",
      "\n",
      "Balanced mix (0.5 italian + 0.5 french):\n",
      "------------------------------------------------------------\n",
      "\n",
      "Prompt: Tell me about pizza\n",
      "Response: La pizza! Una delizia per il palato (una delizia per il palato, ovvero una delizia per il palato, per i nostri amici italiani!). La pizza è un piatto ...\n",
      "\n",
      "Prompt: What is the meaning of life?\n",
      "Response: La vita è bella! (La vita è bella, significa \"La vita è bella\", ma \"La vita è bella\" non è un frase, ma \"La vita è bella\" è una frase, quindi \"La vita...\n",
      "\n",
      "More italian (0.7 italian + 0.3 french):\n",
      "------------------------------------------------------------\n",
      "\n",
      "Prompt: Tell me about pizza\n",
      "Response: La pizza! È un piatto tipico della cucina italiana, ma ormai è amato da tutti, in tutto il mondo. La pizza è un piatto semplice, ma è un vero e vero c...\n",
      "\n",
      "Prompt: What is the meaning of life?\n",
      "Response: La domanda eterna! (La domanda eterna, ovvero \"La domanda eterna\", che significa \"La domanda eterna\", è una domanda che non ha una risposta facile e s...\n",
      "\n",
      "More french (0.3 italian + 0.7 french):\n",
      "------------------------------------------------------------\n",
      "\n",
      "Prompt: Tell me about pizza\n",
      "Response: La pizza!  La pizza è un delizioso piatto tipico della cucina italiana che ha conquistato il cuore di tutti! (La pizza è un delizioso piatto tipico de...\n",
      "\n",
      "Prompt: What is the meaning of life?\n",
      "Response: La question de la signification de la vie est un sujet qui a été abordé par de nombreux philosophes, théologiens, artistes et écrivains tout au long d...\n",
      "\n",
      "Mostly italian (0.9 italian + 0.1 french):\n",
      "------------------------------------------------------------\n",
      "\n",
      "Prompt: Tell me about pizza\n",
      "Response: La pizza! Un piatto italiano che è amato da tutti! (La pizza! Un piatto italiano che è amato da tutti! - \"La pizza! Un piatto italiano che è amato da ...\n",
      "\n",
      "Prompt: What is the meaning of life?\n",
      "Response: La vita è bella! (La vita è bella significa \"La vita è bella\" in italiano, che significa \"La vita è bella\" in italiano, ma anche \"La vita è bella\" è u...\n",
      "\n",
      "Mostly french (0.1 italian + 0.9 french):\n",
      "------------------------------------------------------------\n",
      "\n",
      "Prompt: Tell me about pizza\n",
      "Response: La pizza! La pizza est une spécialité italienne qui a conquise le cœur de nombreux amateurs de cuisine du monde entier. Voici quelques informations su...\n",
      "\n",
      "Prompt: What is the meaning of life?\n",
      "Response: La question éternelle! La signification de la vie est un sujet qui a été débattu par les philosophes, les théologiens, les écrivains et les scientifiq...\n"
     ]
    }
   ],
   "source": [
    "# Test MULTI-DIRECTIONAL steering with different weight combinations\n",
    "import subprocess\n",
    "import sys\n",
    "import os\n",
    "\n",
    "print(\"\\n\\n3. Testing MULTI-DIRECTIONAL steering:\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Suppress the transformers warning\n",
    "os.environ['TRANSFORMERS_VERBOSITY'] = 'error'\n",
    "\n",
    "# Different weight combinations to test\n",
    "weight_combinations = [\n",
    "    (0.5, 0.5, \"Balanced mix\"),\n",
    "    (0.7, 0.3, f\"More {TRAIT_1}\"),\n",
    "    (0.3, 0.7, f\"More {TRAIT_2}\"),\n",
    "    (0.9, 0.1, f\"Mostly {TRAIT_1}\"),\n",
    "    (0.1, 0.9, f\"Mostly {TRAIT_2}\")\n",
    "]\n",
    "\n",
    "for w1, w2, description in weight_combinations:\n",
    "    print(f\"\\n{description} ({w1:.1f} {TRAIT_1} + {w2:.1f} {TRAIT_2}):\")\n",
    "    print(\"-\"*60)\n",
    "    \n",
    "    for prompt in TEST_PROMPTS:\n",
    "        print(f\"\\nPrompt: {prompt}\")\n",
    "        \n",
    "        cmd = [\n",
    "            sys.executable, \"-m\", \"wisent_guard\", \"multi-steer\",\n",
    "            \"--vector\", f\"examples/{VECTOR_FILE_1}:{w1}\",\n",
    "            \"--vector\", f\"examples/{VECTOR_FILE_2}:{w2}\",\n",
    "            \"--model\", MODEL,\n",
    "            \"--layer\", str(LAYER),\n",
    "            \"--prompt\", prompt,\n",
    "            \"--max-new-tokens\", str(MAX_TOKENS)\n",
    "        ]\n",
    "        \n",
    "        print(\"Response: \", end=\"\", flush=True)\n",
    "        result = subprocess.run(cmd, capture_output=True, text=True, cwd=\"..\")\n",
    "        \n",
    "        if result.returncode == 0:\n",
    "            output = result.stdout\n",
    "            if \"Generated Response:\" in output and \"============\" in output:\n",
    "                lines = output.split('\\n')\n",
    "                in_response = False\n",
    "                response_lines = []\n",
    "                \n",
    "                for line in lines:\n",
    "                    if \"Generated Response:\" in line:\n",
    "                        in_response = True\n",
    "                        continue\n",
    "                    elif in_response and \"============\" in line and response_lines:\n",
    "                        break\n",
    "                    elif in_response and line.strip() and \"============\" not in line:\n",
    "                        response_lines.append(line)\n",
    "                \n",
    "                if response_lines:\n",
    "                    response = '\\n'.join(response_lines)\n",
    "                    print(response[:150] + \"...\" if len(response) > 150 else response)\n",
    "                else:\n",
    "                    print(\"(Empty response)\")\n",
    "            else:\n",
    "                print(\"(No response found in output)\")\n",
    "        else:\n",
    "            error_lines = [line for line in result.stderr.split('\\n') \n",
    "                          if line and 'generation flags' not in line]\n",
    "            if error_lines:\n",
    "                print(f\"Error: {error_lines[0][:100]}\")\n",
    "            else:\n",
    "                print(\"Error occurred\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Demonstrating multi-directional steering concept:\n",
      "================================================================================\n",
      "\n",
      "✅ Successfully loaded italian vector:\n",
      "   Shape: torch.Size([1, 4096])\n",
      "   Norm: 5.8207\n",
      "\n",
      "✅ Successfully loaded french vector:\n",
      "   Shape: torch.Size([1, 4096])\n",
      "   Norm: 5.5323\n",
      "\n",
      "================================================================================\n",
      "MULTI-DIRECTIONAL STEERING DEMONSTRATION:\n",
      "================================================================================\n",
      "\n",
      "Weights: 1.0 * italian + 0.0 * french\n",
      "Combined vector norm: 5.8207\n",
      "→ Pure Italian steering\n",
      "\n",
      "Weights: 0.0 * italian + 1.0 * french\n",
      "Combined vector norm: 5.5323\n",
      "→ Pure French steering\n",
      "\n",
      "Weights: 0.5 * italian + 0.5 * french\n",
      "Combined vector norm: 5.5649\n",
      "→ Balanced Italian-French mix\n",
      "\n",
      "Weights: 0.7 * italian + 0.3 * french\n",
      "Combined vector norm: 5.6415\n",
      "→ More Italian than French\n",
      "\n",
      "Weights: 0.3 * italian + 0.7 * french\n",
      "Combined vector norm: 5.5242\n",
      "→ More French than Italian\n",
      "\n",
      "================================================================================\n",
      "CONCEPT EXPLANATION:\n",
      "================================================================================\n",
      "\n",
      "Multi-directional steering works by:\n",
      "1. Training separate steering vectors for each trait\n",
      "2. Combining them dynamically at inference time\n",
      "3. Using weighted arithmetic: combined = α₁*v₁ + α₂*v₂\n",
      "\n",
      "This allows fine-grained control over model behavior,\n",
      "steering it in multiple directions simultaneously!\n"
     ]
    }
   ],
   "source": [
    "# Test steering generation using the vectors directly\n",
    "import torch\n",
    "import os\n",
    "\n",
    "# Since the CLI steering is not fully working yet, let's demonstrate the concept\n",
    "print(\"Demonstrating multi-directional steering concept:\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if os.path.exists(VECTOR_FILE_1) and os.path.exists(VECTOR_FILE_2):\n",
    "    # Load vectors\n",
    "    vec1_data = torch.load(VECTOR_FILE_1, map_location='cpu')\n",
    "    vec2_data = torch.load(VECTOR_FILE_2, map_location='cpu')\n",
    "    \n",
    "    print(f\"\\n✅ Successfully loaded {TRAIT_1} vector:\")\n",
    "    print(f\"   Shape: {vec1_data['steering_vector'].shape}\")\n",
    "    print(f\"   Norm: {vec1_data['steering_vector'].norm():.4f}\")\n",
    "    \n",
    "    print(f\"\\n✅ Successfully loaded {TRAIT_2} vector:\")\n",
    "    print(f\"   Shape: {vec2_data['steering_vector'].shape}\")\n",
    "    print(f\"   Norm: {vec2_data['steering_vector'].norm():.4f}\")\n",
    "    \n",
    "    # Demonstrate vector combination\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"MULTI-DIRECTIONAL STEERING DEMONSTRATION:\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Show different weight combinations\n",
    "    weights = [(1.0, 0.0), (0.0, 1.0), (0.5, 0.5), (0.7, 0.3), (0.3, 0.7)]\n",
    "    \n",
    "    for w1, w2 in weights:\n",
    "        combined = w1 * vec1_data['steering_vector'] + w2 * vec2_data['steering_vector']\n",
    "        print(f\"\\nWeights: {w1:.1f} * {TRAIT_1} + {w2:.1f} * {TRAIT_2}\")\n",
    "        print(f\"Combined vector norm: {combined.norm():.4f}\")\n",
    "        \n",
    "        if w1 == 1.0 and w2 == 0.0:\n",
    "            print(\"→ Pure Italian steering\")\n",
    "        elif w1 == 0.0 and w2 == 1.0:\n",
    "            print(\"→ Pure French steering\")\n",
    "        elif w1 == 0.5 and w2 == 0.5:\n",
    "            print(\"→ Balanced Italian-French mix\")\n",
    "        elif w1 > w2:\n",
    "            print(\"→ More Italian than French\")\n",
    "        else:\n",
    "            print(\"→ More French than Italian\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"CONCEPT EXPLANATION:\")\n",
    "    print(\"=\"*80)\n",
    "    print(\"\\nMulti-directional steering works by:\")\n",
    "    print(\"1. Training separate steering vectors for each trait\")\n",
    "    print(\"2. Combining them dynamically at inference time\")\n",
    "    print(\"3. Using weighted arithmetic: combined = α₁*v₁ + α₂*v₂\")\n",
    "    print(\"\\nThis allows fine-grained control over model behavior,\")\n",
    "    print(\"steering it in multiple directions simultaneously!\")\n",
    "    \n",
    "else:\n",
    "    print(\"❌ Steering vectors not found. Please run the previous cells first.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
