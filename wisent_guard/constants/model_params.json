{
  "meta-llama/Llama-3.1-8B-Instruct": {
    "layer_evaluation": {
      "evaluation_timestamp": "2025-05-28T01:58:35.467903",
      "classifier_threshold": 0.5,
      "max_tokens": 50,
      "layers_evaluated": [
        0,
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18,
        19,
        20,
        21,
        22,
        23,
        24,
        25,
        26,
        27,
        28,
        29,
        30,
        31
      ],
      "total_layers_evaluated": 32,
      "best_layer": 30,
      "best_f1_score": 0.4285714285714285,
      "layer_performance": {
        "0": {
          "precision": 0.3333333333333333,
          "recall": 0.25,
          "f1": 0.28571428571428575,
          "accuracy": 0.75,
          "tp": 1,
          "fp": 2,
          "tn": 14,
          "fn": 3,
          "total_evaluated": 20,
          "total_harmful_predictions": 3,
          "avg_score": 0.4979145675897598
        },
        "1": {
          "precision": 0.125,
          "recall": 0.25,
          "f1": 0.16666666666666666,
          "accuracy": 0.5,
          "tp": 1,
          "fp": 7,
          "tn": 9,
          "fn": 3,
          "total_evaluated": 20,
          "total_harmful_predictions": 8,
          "avg_score": 0.49886334240436553
        },
        "2": {
          "precision": 0.2,
          "recall": 0.5,
          "f1": 0.28571428571428575,
          "accuracy": 0.5,
          "tp": 2,
          "fp": 8,
          "tn": 8,
          "fn": 2,
          "total_evaluated": 20,
          "total_harmful_predictions": 10,
          "avg_score": 0.49933365136384966
        },
        "3": {
          "precision": 0.1,
          "recall": 0.25,
          "f1": 0.14285714285714288,
          "accuracy": 0.4,
          "tp": 1,
          "fp": 9,
          "tn": 7,
          "fn": 3,
          "total_evaluated": 20,
          "total_harmful_predictions": 10,
          "avg_score": 0.4997073620557785
        },
        "4": {
          "precision": 0.14285714285714285,
          "recall": 0.25,
          "f1": 0.18181818181818182,
          "accuracy": 0.55,
          "tp": 1,
          "fp": 6,
          "tn": 10,
          "fn": 3,
          "total_evaluated": 20,
          "total_harmful_predictions": 7,
          "avg_score": 0.49681478589773176
        },
        "5": {
          "precision": 0.0,
          "recall": 0.0,
          "f1": 0,
          "accuracy": 0.45,
          "tp": 0,
          "fp": 7,
          "tn": 9,
          "fn": 4,
          "total_evaluated": 20,
          "total_harmful_predictions": 7,
          "avg_score": 0.4931625872850418
        },
        "6": {
          "precision": 0.25,
          "recall": 0.5,
          "f1": 0.3333333333333333,
          "accuracy": 0.6,
          "tp": 2,
          "fp": 6,
          "tn": 10,
          "fn": 2,
          "total_evaluated": 20,
          "total_harmful_predictions": 8,
          "avg_score": 0.498026505112648
        },
        "7": {
          "precision": 0.08333333333333333,
          "recall": 0.25,
          "f1": 0.125,
          "accuracy": 0.3,
          "tp": 1,
          "fp": 11,
          "tn": 5,
          "fn": 3,
          "total_evaluated": 20,
          "total_harmful_predictions": 12,
          "avg_score": 0.5081071734428406
        },
        "8": {
          "precision": 0.21428571428571427,
          "recall": 0.75,
          "f1": 0.3333333333333333,
          "accuracy": 0.4,
          "tp": 3,
          "fp": 11,
          "tn": 5,
          "fn": 1,
          "total_evaluated": 20,
          "total_harmful_predictions": 14,
          "avg_score": 0.5079762950539589
        },
        "9": {
          "precision": 0.08333333333333333,
          "recall": 0.25,
          "f1": 0.125,
          "accuracy": 0.3,
          "tp": 1,
          "fp": 11,
          "tn": 5,
          "fn": 3,
          "total_evaluated": 20,
          "total_harmful_predictions": 12,
          "avg_score": 0.5072920367121696
        },
        "10": {
          "precision": 0.125,
          "recall": 0.25,
          "f1": 0.16666666666666666,
          "accuracy": 0.5,
          "tp": 1,
          "fp": 7,
          "tn": 9,
          "fn": 3,
          "total_evaluated": 20,
          "total_harmful_predictions": 8,
          "avg_score": 0.47963978350162506
        },
        "11": {
          "precision": 0.16666666666666666,
          "recall": 0.25,
          "f1": 0.2,
          "accuracy": 0.6,
          "tp": 1,
          "fp": 5,
          "tn": 11,
          "fn": 3,
          "total_evaluated": 20,
          "total_harmful_predictions": 6,
          "avg_score": 0.4814096614718437
        },
        "12": {
          "precision": 0.0,
          "recall": 0.0,
          "f1": 0,
          "accuracy": 0.35,
          "tp": 0,
          "fp": 9,
          "tn": 7,
          "fn": 4,
          "total_evaluated": 20,
          "total_harmful_predictions": 9,
          "avg_score": 0.4835063353180885
        },
        "13": {
          "precision": 0.0,
          "recall": 0.0,
          "f1": 0,
          "accuracy": 0.5,
          "tp": 0,
          "fp": 6,
          "tn": 10,
          "fn": 4,
          "total_evaluated": 20,
          "total_harmful_predictions": 6,
          "avg_score": 0.4671509608626366
        },
        "14": {
          "precision": 0.0,
          "recall": 0.0,
          "f1": 0,
          "accuracy": 0.5,
          "tp": 0,
          "fp": 6,
          "tn": 10,
          "fn": 4,
          "total_evaluated": 20,
          "total_harmful_predictions": 6,
          "avg_score": 0.47818356454372407
        },
        "15": {
          "precision": 0.1111111111111111,
          "recall": 0.25,
          "f1": 0.15384615384615383,
          "accuracy": 0.45,
          "tp": 1,
          "fp": 8,
          "tn": 8,
          "fn": 3,
          "total_evaluated": 20,
          "total_harmful_predictions": 9,
          "avg_score": 0.48731897324323653
        },
        "16": {
          "precision": 0.16666666666666666,
          "recall": 0.5,
          "f1": 0.25,
          "accuracy": 0.4,
          "tp": 2,
          "fp": 10,
          "tn": 6,
          "fn": 2,
          "total_evaluated": 20,
          "total_harmful_predictions": 12,
          "avg_score": 0.4913590833544731
        },
        "17": {
          "precision": 0.125,
          "recall": 0.25,
          "f1": 0.16666666666666666,
          "accuracy": 0.5,
          "tp": 1,
          "fp": 7,
          "tn": 9,
          "fn": 3,
          "total_evaluated": 20,
          "total_harmful_predictions": 8,
          "avg_score": 0.48516138195991515
        },
        "18": {
          "precision": 0.2222222222222222,
          "recall": 0.5,
          "f1": 0.30769230769230765,
          "accuracy": 0.55,
          "tp": 2,
          "fp": 7,
          "tn": 9,
          "fn": 2,
          "total_evaluated": 20,
          "total_harmful_predictions": 9,
          "avg_score": 0.4783730641007423
        },
        "19": {
          "precision": 0.2,
          "recall": 0.5,
          "f1": 0.28571428571428575,
          "accuracy": 0.5,
          "tp": 2,
          "fp": 8,
          "tn": 8,
          "fn": 2,
          "total_evaluated": 20,
          "total_harmful_predictions": 10,
          "avg_score": 0.4855231523513794
        },
        "20": {
          "precision": 0.15384615384615385,
          "recall": 0.5,
          "f1": 0.23529411764705882,
          "accuracy": 0.35,
          "tp": 2,
          "fp": 11,
          "tn": 5,
          "fn": 2,
          "total_evaluated": 20,
          "total_harmful_predictions": 13,
          "avg_score": 0.4880842834711075
        },
        "21": {
          "precision": 0.18181818181818182,
          "recall": 0.5,
          "f1": 0.26666666666666666,
          "accuracy": 0.45,
          "tp": 2,
          "fp": 9,
          "tn": 7,
          "fn": 2,
          "total_evaluated": 20,
          "total_harmful_predictions": 11,
          "avg_score": 0.482251013815403
        },
        "22": {
          "precision": 0.18181818181818182,
          "recall": 0.5,
          "f1": 0.26666666666666666,
          "accuracy": 0.45,
          "tp": 2,
          "fp": 9,
          "tn": 7,
          "fn": 2,
          "total_evaluated": 20,
          "total_harmful_predictions": 11,
          "avg_score": 0.4801728680729866
        },
        "23": {
          "precision": 0.18181818181818182,
          "recall": 0.5,
          "f1": 0.26666666666666666,
          "accuracy": 0.45,
          "tp": 2,
          "fp": 9,
          "tn": 7,
          "fn": 2,
          "total_evaluated": 20,
          "total_harmful_predictions": 11,
          "avg_score": 0.4866103932261467
        },
        "24": {
          "precision": 0.09090909090909091,
          "recall": 0.25,
          "f1": 0.13333333333333333,
          "accuracy": 0.35,
          "tp": 1,
          "fp": 10,
          "tn": 6,
          "fn": 3,
          "total_evaluated": 20,
          "total_harmful_predictions": 11,
          "avg_score": 0.4931501343846321
        },
        "25": {
          "precision": 0.07692307692307693,
          "recall": 0.25,
          "f1": 0.11764705882352941,
          "accuracy": 0.25,
          "tp": 1,
          "fp": 12,
          "tn": 4,
          "fn": 3,
          "total_evaluated": 20,
          "total_harmful_predictions": 13,
          "avg_score": 0.49941529184579847
        },
        "26": {
          "precision": 0.2,
          "recall": 0.75,
          "f1": 0.31578947368421056,
          "accuracy": 0.35,
          "tp": 3,
          "fp": 12,
          "tn": 4,
          "fn": 1,
          "total_evaluated": 20,
          "total_harmful_predictions": 15,
          "avg_score": 0.5051795095205307
        },
        "27": {
          "precision": 0.15384615384615385,
          "recall": 0.5,
          "f1": 0.23529411764705882,
          "accuracy": 0.35,
          "tp": 2,
          "fp": 11,
          "tn": 5,
          "fn": 2,
          "total_evaluated": 20,
          "total_harmful_predictions": 13,
          "avg_score": 0.508191879093647
        },
        "28": {
          "precision": 0.15384615384615385,
          "recall": 0.5,
          "f1": 0.23529411764705882,
          "accuracy": 0.35,
          "tp": 2,
          "fp": 11,
          "tn": 5,
          "fn": 2,
          "total_evaluated": 20,
          "total_harmful_predictions": 13,
          "avg_score": 0.5101779595017433
        },
        "29": {
          "precision": 0.18181818181818182,
          "recall": 0.5,
          "f1": 0.26666666666666666,
          "accuracy": 0.45,
          "tp": 2,
          "fp": 9,
          "tn": 7,
          "fn": 2,
          "total_evaluated": 20,
          "total_harmful_predictions": 11,
          "avg_score": 0.47814554944634435
        },
        "30": {
          "precision": 0.3,
          "recall": 0.75,
          "f1": 0.4285714285714285,
          "accuracy": 0.6,
          "tp": 3,
          "fp": 7,
          "tn": 9,
          "fn": 1,
          "total_evaluated": 20,
          "total_harmful_predictions": 10,
          "avg_score": 0.485948845744133
        },
        "31": {
          "precision": 0.2,
          "recall": 0.5,
          "f1": 0.28571428571428575,
          "accuracy": 0.5,
          "tp": 2,
          "fp": 8,
          "tn": 8,
          "fn": 2,
          "total_evaluated": 20,
          "total_harmful_predictions": 10,
          "avg_score": 0.4693374402821064
        }
      }
    },
    "layer_evaluation_truthfulqa_human_scores": {
      "evaluation_timestamp": "2025-05-28T15:58:50.566675",
      "dataset": "truthfulqa_human_scores",
      "classifier_threshold": 0.5,
      "max_tokens": 100,
      "layers_evaluated": [
        0,
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18,
        19,
        20,
        21,
        22,
        23,
        24,
        25,
        26,
        27,
        28,
        29,
        30,
        31
      ],
      "total_layers_evaluated": 32,
      "best_layer": 7,
      "best_f1_score": 0.45454545454545453,
      "layer_performance": {
        "0": {
          "precision": 0.2,
          "recall": 0.8928571428571429,
          "f1": 0.32679738562091504,
          "accuracy": 0.3719512195121951,
          "tp": 25,
          "fp": 100,
          "tn": 36,
          "fn": 3,
          "total_evaluated": 164,
          "total_harmful_predictions": 125,
          "total_human_hallucinations": 28,
          "total_human_factual": 136,
          "avg_score": 0.5089090857200507
        },
        "1": {
          "precision": 0.21138211382113822,
          "recall": 0.9285714285714286,
          "f1": 0.34437086092715236,
          "accuracy": 0.39634146341463417,
          "tp": 26,
          "fp": 97,
          "tn": 39,
          "fn": 2,
          "total_evaluated": 164,
          "total_harmful_predictions": 123,
          "total_human_hallucinations": 28,
          "total_human_factual": 136,
          "avg_score": 0.5116732647506202
        },
        "2": {
          "precision": 0.20175438596491227,
          "recall": 0.8214285714285714,
          "f1": 0.323943661971831,
          "accuracy": 0.4146341463414634,
          "tp": 23,
          "fp": 91,
          "tn": 45,
          "fn": 5,
          "total_evaluated": 164,
          "total_harmful_predictions": 114,
          "total_human_hallucinations": 28,
          "total_human_factual": 136,
          "avg_score": 0.5133117228382971
        },
        "3": {
          "precision": 0.19083969465648856,
          "recall": 0.8928571428571429,
          "f1": 0.31446540880503143,
          "accuracy": 0.3353658536585366,
          "tp": 25,
          "fp": 106,
          "tn": 30,
          "fn": 3,
          "total_evaluated": 164,
          "total_harmful_predictions": 131,
          "total_human_hallucinations": 28,
          "total_human_factual": 136,
          "avg_score": 0.5254110833857117
        },
        "4": {
          "precision": 0.23,
          "recall": 0.8214285714285714,
          "f1": 0.359375,
          "accuracy": 0.5,
          "tp": 23,
          "fp": 77,
          "tn": 59,
          "fn": 5,
          "total_evaluated": 164,
          "total_harmful_predictions": 100,
          "total_human_hallucinations": 28,
          "total_human_factual": 136,
          "avg_score": 0.5116605354336704
        },
        "5": {
          "precision": 0.20202020202020202,
          "recall": 0.7142857142857143,
          "f1": 0.31496062992125984,
          "accuracy": 0.4695121951219512,
          "tp": 20,
          "fp": 79,
          "tn": 57,
          "fn": 8,
          "total_evaluated": 164,
          "total_harmful_predictions": 99,
          "total_human_hallucinations": 28,
          "total_human_factual": 136,
          "avg_score": 0.5071034322424632
        },
        "6": {
          "precision": 0.3023255813953488,
          "recall": 0.4642857142857143,
          "f1": 0.36619718309859156,
          "accuracy": 0.725609756097561,
          "tp": 13,
          "fp": 30,
          "tn": 106,
          "fn": 15,
          "total_evaluated": 164,
          "total_harmful_predictions": 43,
          "total_human_hallucinations": 28,
          "total_human_factual": 136,
          "avg_score": 0.4294104370311266
        },
        "7": {
          "precision": 0.39473684210526316,
          "recall": 0.5357142857142857,
          "f1": 0.45454545454545453,
          "accuracy": 0.7804878048780488,
          "tp": 15,
          "fp": 23,
          "tn": 113,
          "fn": 13,
          "total_evaluated": 164,
          "total_harmful_predictions": 38,
          "total_human_hallucinations": 28,
          "total_human_factual": 136,
          "avg_score": 0.43534037725227637
        },
        "8": {
          "precision": 0.29545454545454547,
          "recall": 0.4642857142857143,
          "f1": 0.36111111111111116,
          "accuracy": 0.7195121951219512,
          "tp": 13,
          "fp": 31,
          "tn": 105,
          "fn": 15,
          "total_evaluated": 164,
          "total_harmful_predictions": 44,
          "total_human_hallucinations": 28,
          "total_human_factual": 136,
          "avg_score": 0.4253605493548803
        },
        "9": {
          "precision": 0.2558139534883721,
          "recall": 0.39285714285714285,
          "f1": 0.3098591549295775,
          "accuracy": 0.7012195121951219,
          "tp": 11,
          "fp": 32,
          "tn": 104,
          "fn": 17,
          "total_evaluated": 164,
          "total_harmful_predictions": 43,
          "total_human_hallucinations": 28,
          "total_human_factual": 136,
          "avg_score": 0.39584032514291567
        },
        "10": {
          "precision": 0.3142857142857143,
          "recall": 0.39285714285714285,
          "f1": 0.34920634920634924,
          "accuracy": 0.75,
          "tp": 11,
          "fp": 24,
          "tn": 112,
          "fn": 17,
          "total_evaluated": 164,
          "total_harmful_predictions": 35,
          "total_human_hallucinations": 28,
          "total_human_factual": 136,
          "avg_score": 0.367463216094709
        },
        "11": {
          "precision": 0.37142857142857144,
          "recall": 0.4642857142857143,
          "f1": 0.41269841269841273,
          "accuracy": 0.774390243902439,
          "tp": 13,
          "fp": 22,
          "tn": 114,
          "fn": 15,
          "total_evaluated": 164,
          "total_harmful_predictions": 35,
          "total_human_hallucinations": 28,
          "total_human_factual": 136,
          "avg_score": 0.42535287811897876
        },
        "12": {
          "precision": 0.36363636363636365,
          "recall": 0.42857142857142855,
          "f1": 0.3934426229508197,
          "accuracy": 0.774390243902439,
          "tp": 12,
          "fp": 21,
          "tn": 115,
          "fn": 16,
          "total_evaluated": 164,
          "total_harmful_predictions": 33,
          "total_human_hallucinations": 28,
          "total_human_factual": 136,
          "avg_score": 0.3991248239649505
        },
        "13": {
          "precision": 0.25882352941176473,
          "recall": 0.7857142857142857,
          "f1": 0.3893805309734514,
          "accuracy": 0.5792682926829268,
          "tp": 22,
          "fp": 63,
          "tn": 73,
          "fn": 6,
          "total_evaluated": 164,
          "total_harmful_predictions": 85,
          "total_human_hallucinations": 28,
          "total_human_factual": 136,
          "avg_score": 0.46380989446600035
        },
        "14": {
          "precision": 0.2777777777777778,
          "recall": 0.5357142857142857,
          "f1": 0.36585365853658536,
          "accuracy": 0.6829268292682927,
          "tp": 15,
          "fp": 39,
          "tn": 97,
          "fn": 13,
          "total_evaluated": 164,
          "total_harmful_predictions": 54,
          "total_human_hallucinations": 28,
          "total_human_factual": 136,
          "avg_score": 0.45555905670654484
        },
        "15": {
          "precision": 0.2898550724637681,
          "recall": 0.7142857142857143,
          "f1": 0.41237113402061853,
          "accuracy": 0.6524390243902439,
          "tp": 20,
          "fp": 49,
          "tn": 87,
          "fn": 8,
          "total_evaluated": 164,
          "total_harmful_predictions": 69,
          "total_human_hallucinations": 28,
          "total_human_factual": 136,
          "avg_score": 0.4683444086212392
        },
        "16": {
          "precision": 0.2727272727272727,
          "recall": 0.5357142857142857,
          "f1": 0.3614457831325301,
          "accuracy": 0.676829268292683,
          "tp": 15,
          "fp": 40,
          "tn": 96,
          "fn": 13,
          "total_evaluated": 164,
          "total_harmful_predictions": 55,
          "total_human_hallucinations": 28,
          "total_human_factual": 136,
          "avg_score": 0.4424197693673394
        },
        "17": {
          "precision": 0.2653061224489796,
          "recall": 0.4642857142857143,
          "f1": 0.3376623376623377,
          "accuracy": 0.6890243902439024,
          "tp": 13,
          "fp": 36,
          "tn": 100,
          "fn": 15,
          "total_evaluated": 164,
          "total_harmful_predictions": 49,
          "total_human_hallucinations": 28,
          "total_human_factual": 136,
          "avg_score": 0.4175890497408989
        },
        "18": {
          "precision": 0.25925925925925924,
          "recall": 0.5,
          "f1": 0.3414634146341463,
          "accuracy": 0.6707317073170732,
          "tp": 14,
          "fp": 40,
          "tn": 96,
          "fn": 14,
          "total_evaluated": 164,
          "total_harmful_predictions": 54,
          "total_human_hallucinations": 28,
          "total_human_factual": 136,
          "avg_score": 0.42159631413339477
        },
        "19": {
          "precision": 0.22807017543859648,
          "recall": 0.4642857142857143,
          "f1": 0.3058823529411765,
          "accuracy": 0.6402439024390244,
          "tp": 13,
          "fp": 44,
          "tn": 92,
          "fn": 15,
          "total_evaluated": 164,
          "total_harmful_predictions": 57,
          "total_human_hallucinations": 28,
          "total_human_factual": 136,
          "avg_score": 0.43213421610615604
        },
        "20": {
          "precision": 0.2222222222222222,
          "recall": 0.5,
          "f1": 0.30769230769230765,
          "accuracy": 0.6158536585365854,
          "tp": 14,
          "fp": 49,
          "tn": 87,
          "fn": 14,
          "total_evaluated": 164,
          "total_harmful_predictions": 63,
          "total_human_hallucinations": 28,
          "total_human_factual": 136,
          "avg_score": 0.45821464428587294
        },
        "21": {
          "precision": 0.2153846153846154,
          "recall": 0.5,
          "f1": 0.3010752688172043,
          "accuracy": 0.6036585365853658,
          "tp": 14,
          "fp": 51,
          "tn": 85,
          "fn": 14,
          "total_evaluated": 164,
          "total_harmful_predictions": 65,
          "total_human_hallucinations": 28,
          "total_human_factual": 136,
          "avg_score": 0.4508614909108274
        },
        "22": {
          "precision": 0.24,
          "recall": 0.6428571428571429,
          "f1": 0.34951456310679613,
          "accuracy": 0.5914634146341463,
          "tp": 18,
          "fp": 57,
          "tn": 79,
          "fn": 10,
          "total_evaluated": 164,
          "total_harmful_predictions": 75,
          "total_human_hallucinations": 28,
          "total_human_factual": 136,
          "avg_score": 0.4893849674248841
        },
        "23": {
          "precision": 0.21518987341772153,
          "recall": 0.6071428571428571,
          "f1": 0.3177570093457944,
          "accuracy": 0.5548780487804879,
          "tp": 17,
          "fp": 62,
          "tn": 74,
          "fn": 11,
          "total_evaluated": 164,
          "total_harmful_predictions": 79,
          "total_human_hallucinations": 28,
          "total_human_factual": 136,
          "avg_score": 0.4969900511432348
        },
        "24": {
          "precision": 0.24193548387096775,
          "recall": 0.5357142857142857,
          "f1": 0.33333333333333337,
          "accuracy": 0.6341463414634146,
          "tp": 15,
          "fp": 47,
          "tn": 89,
          "fn": 13,
          "total_evaluated": 164,
          "total_harmful_predictions": 62,
          "total_human_hallucinations": 28,
          "total_human_factual": 136,
          "avg_score": 0.46148145164749244
        },
        "25": {
          "precision": 0.21212121212121213,
          "recall": 0.5,
          "f1": 0.2978723404255319,
          "accuracy": 0.5975609756097561,
          "tp": 14,
          "fp": 52,
          "tn": 84,
          "fn": 14,
          "total_evaluated": 164,
          "total_harmful_predictions": 66,
          "total_human_hallucinations": 28,
          "total_human_factual": 136,
          "avg_score": 0.4595175212385451
        },
        "26": {
          "precision": 0.2112676056338028,
          "recall": 0.5357142857142857,
          "f1": 0.303030303030303,
          "accuracy": 0.5792682926829268,
          "tp": 15,
          "fp": 56,
          "tn": 80,
          "fn": 13,
          "total_evaluated": 164,
          "total_harmful_predictions": 71,
          "total_human_hallucinations": 28,
          "total_human_factual": 136,
          "avg_score": 0.4739822773944314
        },
        "27": {
          "precision": 0.21052631578947367,
          "recall": 0.5714285714285714,
          "f1": 0.3076923076923077,
          "accuracy": 0.5609756097560976,
          "tp": 16,
          "fp": 60,
          "tn": 76,
          "fn": 12,
          "total_evaluated": 164,
          "total_harmful_predictions": 76,
          "total_human_hallucinations": 28,
          "total_human_factual": 136,
          "avg_score": 0.4904400542287565
        },
        "28": {
          "precision": 0.1875,
          "recall": 0.5357142857142857,
          "f1": 0.2777777777777778,
          "accuracy": 0.524390243902439,
          "tp": 15,
          "fp": 65,
          "tn": 71,
          "fn": 13,
          "total_evaluated": 164,
          "total_harmful_predictions": 80,
          "total_human_hallucinations": 28,
          "total_human_factual": 136,
          "avg_score": 0.4941693908285077
        },
        "29": {
          "precision": 0.21875,
          "recall": 0.5,
          "f1": 0.30434782608695654,
          "accuracy": 0.6097560975609756,
          "tp": 14,
          "fp": 50,
          "tn": 86,
          "fn": 14,
          "total_evaluated": 164,
          "total_harmful_predictions": 64,
          "total_human_hallucinations": 28,
          "total_human_factual": 136,
          "avg_score": 0.4515162127365063
        },
        "30": {
          "precision": 0.21666666666666667,
          "recall": 0.4642857142857143,
          "f1": 0.29545454545454547,
          "accuracy": 0.6219512195121951,
          "tp": 13,
          "fp": 47,
          "tn": 89,
          "fn": 15,
          "total_evaluated": 164,
          "total_harmful_predictions": 60,
          "total_human_hallucinations": 28,
          "total_human_factual": 136,
          "avg_score": 0.419634228027085
        },
        "31": {
          "precision": 0.17721518987341772,
          "recall": 0.5,
          "f1": 0.2616822429906542,
          "accuracy": 0.5182926829268293,
          "tp": 14,
          "fp": 65,
          "tn": 71,
          "fn": 14,
          "total_evaluated": 164,
          "total_harmful_predictions": 79,
          "total_human_hallucinations": 28,
          "total_human_factual": 136,
          "avg_score": 0.49029914227246146
        }
      }
    }
  }
}