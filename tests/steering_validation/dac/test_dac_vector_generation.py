#!/usr/bin/env python3
"""
Test DAC vector generation correctness by comparing our implementation
with reference data generated by the original DAC implementation.

This test loads the ITA and ENG datasets, generates DAC steering vectors
using our wisent-guard implementation, and compares with reference vectors
generated by the original DAC implementation.
"""

# Remove unused import: import json
import torch
import pytest
import sys
from pathlib import Path

# Add wisent-guard to path
WISENT_PATH = Path(__file__).parent.parent.parent.parent
sys.path.insert(0, str(WISENT_PATH))

# No longer using wisent-guard DAC classes - using original DAC approach directly

# Add current directory to path for local imports
sys.path.insert(0, str(Path(__file__).parent))

from const import (
    MODEL_NAME,
    ACTIVATIONS_A_PATH,
    ACTIVATIONS_B_PATH,
    DIFF_ACTIVATIONS_PATH,
    DATASET_A_NAME,
    DATASET_B_NAME,
    MAX_EXAMPLES,
    EXPECTED_VECTOR_SHAPE,
    DEVICE,
    MODEL_CONFIG,
)
from dac_model_utils import (
    DACModelWrapper,
    create_dac_vectors_with_wisent_guard,
    compute_dac_vector_similarity,
    load_dac_datasets_for_testing,
)

# Import aggressive_memory_cleanup
utils_path = Path(__file__).parent.parent / "utils.py"
sys.path.insert(0, str(Path(__file__).parent.parent))
from utils import aggressive_memory_cleanup


def load_reference_dac_vectors():
    """Load reference DAC vectors generated by the original implementation."""
    vectors = {}

    # Load mean activations for both datasets
    if ACTIVATIONS_A_PATH.exists():
        vectors["mean_a"] = torch.load(ACTIVATIONS_A_PATH, map_location="cpu", weights_only=False)
    else:
        pytest.skip(f"Reference mean activations A not found at {ACTIVATIONS_A_PATH}")

    if ACTIVATIONS_B_PATH.exists():
        vectors["mean_b"] = torch.load(ACTIVATIONS_B_PATH, map_location="cpu", weights_only=False)
    else:
        pytest.skip(f"Reference mean activations B not found at {ACTIVATIONS_B_PATH}")

    # Load difference vector (main steering vector)
    if DIFF_ACTIVATIONS_PATH.exists():
        vectors["diff"] = torch.load(DIFF_ACTIVATIONS_PATH, map_location="cpu", weights_only=False)
    else:
        pytest.skip(f"Reference difference vector not found at {DIFF_ACTIVATIONS_PATH}")

    return vectors


@pytest.mark.slow
class TestDACVectorGeneration:
    """Test suite for DAC vector generation validation."""

    @pytest.mark.slow
    @pytest.mark.heavy
    def test_compare_with_reference_vectors(self):
        """Compare our DAC implementation with reference vectors."""
        # Skip if no GPU available (DAC is resource-intensive)
        if not torch.cuda.is_available():
            pytest.skip("GPU not available for DAC vector generation")

        # Aggressive memory cleanup before starting
        aggressive_memory_cleanup()

        try:
            # Load reference vectors
            ref_vectors = load_reference_dac_vectors()
            ref_diff_vector = ref_vectors["diff"]

            # Create our DAC vectors using wisent-guard implementation
            print("🔧 Creating DAC vectors with wisent-guard implementation...")
            # Test with 8-bit quantization + bfloat16 (should be faster!)
            model_wrapper = DACModelWrapper(MODEL_NAME, device=DEVICE, use_nnsight=False, load_in_8bit=True)

            # Generate vectors using our implementation
            dac, training_stats = create_dac_vectors_with_wisent_guard(model_wrapper)

            # Get the steering vectors from our implementation
            our_vectors = dac.get_property_vectors()

            # Compare with reference using the new original DAC format
            if our_vectors:
                # Get the property (should be "ita_vs_eng" from our implementation)
                property_name = list(our_vectors.keys())[0]
                our_property = our_vectors[property_name]
                our_vectors_dict = our_property["vectors"]  # Dict[layer_idx, tensor] from our new format

                # Compare with reference
                similarity_results = compute_dac_vector_similarity(our_vectors_dict, ref_diff_vector)

                # Print detailed comparison
                print(f"\n🔍 DAC Vector Comparison Results:")
                print(f"   Property: {property_name}")
                print(f"   Reference shape: {ref_diff_vector.shape}")
                print(f"   Our vectors: {len(our_vectors_dict)} layers")

                overall_sim = similarity_results.get("overall", {})
                avg_cosine_sim = overall_sim.get("average_cosine_similarity", 0.0)
                layers_compared = overall_sim.get("layers_compared", 0)

                print(f"   Average cosine similarity: {avg_cosine_sim:.4f}")
                print(f"   Layers compared: {layers_compared}")

                # Detailed layer-by-layer results
                for layer_name, metrics in similarity_results.items():
                    if layer_name.startswith("layer_"):
                        cosine_sim = metrics["cosine_similarity"]
                        norm_ratio = metrics["norm_ratio"]
                        print(f"   {layer_name}: cosine={cosine_sim:.4f}, norm_ratio={norm_ratio:.4f}")

                # Count layers with good similarity
                good_layers = sum(
                    1
                    for layer_name, metrics in similarity_results.items()
                    if layer_name.startswith("layer_") and metrics["cosine_similarity"] > 0.2
                )

                print(f"   Layers with similarity > 0.2: {good_layers}/{layers_compared}")

                # More reasonable assertions for DAC validation
                # DAC vectors can have lower similarity due to dataset/tokenization differences
                assert avg_cosine_sim > 0.1, f"Very low average cosine similarity: {avg_cosine_sim}"
                assert layers_compared >= MODEL_CONFIG["n_layers"] // 2, f"Too few layers compared: {layers_compared}"
                assert good_layers >= 5, f"Too few layers with good similarity (>0.2): {good_layers}"

                # Check training stats
                assert "method" in training_stats
                assert training_stats["method"] == "DAC_original_approach"

                print("✅ DAC vector comparison completed successfully")

            else:
                pytest.fail("No vectors generated by our DAC implementation")

        finally:
            # Clean up GPU memory
            aggressive_memory_cleanup()
