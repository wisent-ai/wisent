#!/usr/bin/env python3
"""
Test DAC vector generation correctness by comparing our implementation
with reference data generated by the original DAC implementation.

This test loads the ITA and ENG datasets, generates DAC steering vectors
using our wisent-guard implementation, and compares with reference vectors
generated by the original DAC implementation.
"""

# Remove unused import: import json
import torch
import pytest
import sys
from pathlib import Path

# Add wisent-guard to path
WISENT_PATH = Path(__file__).parent.parent.parent.parent
sys.path.insert(0, str(WISENT_PATH))

from wisent_guard.core.steering_methods.dac_attention import DAC
from wisent_guard.core.aggregation import ControlVectorAggregationMethod

# Add current directory to path for local imports
sys.path.insert(0, str(Path(__file__).parent))

from const import (
    MODEL_NAME,
    ACTIVATIONS_A_PATH,
    ACTIVATIONS_B_PATH,
    DIFF_ACTIVATIONS_PATH,
    DATASET_A_NAME,
    DATASET_B_NAME,
    MAX_EXAMPLES,
    EXPECTED_VECTOR_SHAPE,
    DEVICE,
    MODEL_CONFIG,
)
from dac_model_utils import (
    DACModelWrapper,
    create_dac_vectors_with_wisent_guard,
    compute_dac_vector_similarity,
    load_dac_datasets_for_testing,
)

# Import aggressive_memory_cleanup
utils_path = Path(__file__).parent.parent / "utils.py"
sys.path.insert(0, str(Path(__file__).parent.parent))
from utils import aggressive_memory_cleanup


def load_reference_dac_vectors():
    """Load reference DAC vectors generated by the original implementation."""
    vectors = {}

    # Load mean activations for both datasets
    if ACTIVATIONS_A_PATH.exists():
        vectors["mean_a"] = torch.load(ACTIVATIONS_A_PATH, map_location="cpu", weights_only=False)
    else:
        pytest.skip(f"Reference mean activations A not found at {ACTIVATIONS_A_PATH}")

    if ACTIVATIONS_B_PATH.exists():
        vectors["mean_b"] = torch.load(ACTIVATIONS_B_PATH, map_location="cpu", weights_only=False)
    else:
        pytest.skip(f"Reference mean activations B not found at {ACTIVATIONS_B_PATH}")

    # Load difference vector (main steering vector)
    if DIFF_ACTIVATIONS_PATH.exists():
        vectors["diff"] = torch.load(DIFF_ACTIVATIONS_PATH, map_location="cpu", weights_only=False)
    else:
        pytest.skip(f"Reference difference vector not found at {DIFF_ACTIVATIONS_PATH}")

    return vectors


@pytest.mark.slow
class TestDACVectorGeneration:
    """Test suite for DAC vector generation validation."""

    @pytest.mark.slow
    @pytest.mark.heavy
    def test_compare_with_reference_vectors(self):
        """Compare our DAC implementation with reference vectors."""
        # Skip if no GPU available (DAC is resource-intensive)
        if not torch.cuda.is_available():
            pytest.skip("GPU not available for DAC vector generation")

        # Aggressive memory cleanup before starting
        aggressive_memory_cleanup()

        try:
            # Load reference vectors
            ref_vectors = load_reference_dac_vectors()
            ref_diff_vector = ref_vectors["diff"]

            # Create our DAC vectors using wisent-guard implementation
            print("🔧 Creating DAC vectors with wisent-guard implementation...")
            model_wrapper = DACModelWrapper(MODEL_NAME, device=DEVICE)

            # Generate vectors using our implementation
            dac, training_stats = create_dac_vectors_with_wisent_guard(model_wrapper)

            # Get the steering vectors from our implementation
            our_vectors = dac.get_property_vectors()

            # Compare with reference
            if our_vectors:
                # For now, compare the first property (should be the main ITA vs ENG comparison)
                property_name = list(our_vectors.keys())[0]
                our_property = our_vectors[property_name]
                our_vectors_dict = our_property.vectors  # Dict[layer_idx, tensor]

                # Compare with reference
                similarity_results = compute_dac_vector_similarity(our_vectors_dict, ref_diff_vector)

                # Print detailed comparison
                print(f"\n🔍 DAC Vector Comparison Results:")
                print(f"   Property: {property_name}")
                print(f"   Reference shape: {ref_diff_vector.shape}")
                print(f"   Our vectors: {len(our_vectors_dict)} layers")

                overall_sim = similarity_results.get("overall", {})
                avg_cosine_sim = overall_sim.get("average_cosine_similarity", 0.0)
                layers_compared = overall_sim.get("layers_compared", 0)

                print(f"   Average cosine similarity: {avg_cosine_sim:.4f}")
                print(f"   Layers compared: {layers_compared}")

                # Detailed layer-by-layer results
                for layer_name, metrics in similarity_results.items():
                    if layer_name.startswith("layer_"):
                        cosine_sim = metrics["cosine_similarity"]
                        norm_ratio = metrics["norm_ratio"]
                        print(f"   {layer_name}: cosine={cosine_sim:.4f}, norm_ratio={norm_ratio:.4f}")

                # Assertions for correctness
                assert avg_cosine_sim > 0.5, f"Very low average cosine similarity: {avg_cosine_sim}"
                assert layers_compared >= MODEL_CONFIG["n_layers"] // 2, f"Too few layers compared: {layers_compared}"

                # Check training stats
                assert "method" in training_stats
                assert training_stats["method"] == "DAC"

                print("✅ DAC vector comparison completed successfully")

            else:
                pytest.fail("No vectors generated by our DAC implementation")

        finally:
            # Clean up GPU memory
            aggressive_memory_cleanup()
