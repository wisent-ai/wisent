{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üöÄ Comprehensive Evaluation Framework for Wisent Guard\n",
    "\n",
    "This notebook provides an interactive interface for running comprehensive evaluations that properly separate:\n",
    "\n",
    "1. **üéØ Benchmark Performance**: How well the model solves mathematical problems\n",
    "2. **üîç Probe Performance**: How well probes detect correctness from model activations\n",
    "3. **‚öôÔ∏è Steering Optimization**: Grid search to find optimal steering configurations\n",
    "\n",
    "## Key Features:\n",
    "- **Interactive Configuration**: Easy parameter tuning with widgets\n",
    "- **Real-time Progress**: Live updates during evaluation\n",
    "- **Rich Visualizations**: Comprehensive plots and analysis\n",
    "- **Modular Design**: Clean separation of concerns\n",
    "- **Export Results**: Save results and generate reports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìã Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Wandb connection cleaned up\n",
      "‚úÖ All imports successful!\n",
      "üìç Working directory: /workspace/wisent-guard/comprehensive_evaluation\n",
      "üêç Python version: 3.10.12 (main, Nov 20 2023, 15:14:05) [GCC 11.4.0]\n",
      "üíæ HuggingFace cache: /workspace/.cache/huggingface\n",
      "üîó Wandb status: ‚úÖ Ready\n",
      "\n",
      "‚úÖ Logged into HuggingFace as: jfpio\n"
     ]
    }
   ],
   "source": [
    "# Core imports\n",
    "import sys\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set HuggingFace cache to permanent directory\n",
    "os.environ['HF_HOME'] = '/workspace/.cache/huggingface'\n",
    "os.environ['TRANSFORMERS_CACHE'] = '/workspace/.cache/huggingface/transformers'\n",
    "os.environ['HF_DATASETS_CACHE'] = '/workspace/.cache/huggingface/datasets'\n",
    "\n",
    "# Create cache directories if they don't exist\n",
    "os.makedirs('/workspace/.cache/huggingface/transformers', exist_ok=True)\n",
    "os.makedirs('/workspace/.cache/huggingface/datasets', exist_ok=True)\n",
    "\n",
    "# Add project root to path\n",
    "project_root = '/workspace/wisent-guard'\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "# Fix wandb connection issues\n",
    "def fix_wandb_connection():\n",
    "    \"\"\"Fix wandb connection issues by properly initializing or disabling it.\"\"\"\n",
    "    try:\n",
    "        import wandb\n",
    "        \n",
    "        # Check if wandb is already initialized\n",
    "        if wandb.run is not None:\n",
    "            print(\"‚ö†Ô∏è Cleaning up existing wandb run...\")\n",
    "            wandb.finish()\n",
    "        \n",
    "        # Clear any broken connections\n",
    "        import subprocess\n",
    "        import signal\n",
    "        try:\n",
    "            # Kill any hanging wandb processes\n",
    "            subprocess.run(['pkill', '-f', 'wandb'], capture_output=True)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        print(\"‚úÖ Wandb connection cleaned up\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Wandb cleanup warning: {e}\")\n",
    "        return False\n",
    "\n",
    "# Check HuggingFace authentication\n",
    "def check_hf_auth():\n",
    "    \"\"\"Check if user is logged into HuggingFace and show login instructions if needed.\"\"\"\n",
    "    try:\n",
    "        import subprocess\n",
    "        result = subprocess.run(['huggingface-cli', 'whoami'], capture_output=True, text=True)\n",
    "        if result.returncode == 0:\n",
    "            username = result.stdout.strip()\n",
    "            print(f\"‚úÖ Logged into HuggingFace as: {username}\")\n",
    "            return True\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è Not logged into HuggingFace!\")\n",
    "            print(\"üîê Please run: huggingface-cli login\")\n",
    "            print(\"   This is required to access datasets like AIME 2024/2025\")\n",
    "            return False\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Could not check HuggingFace authentication: {e}\")\n",
    "        print(\"üîê If you encounter dataset loading issues, try: huggingface-cli login\")\n",
    "        return False\n",
    "\n",
    "# Clean up wandb first\n",
    "wandb_ok = fix_wandb_connection()\n",
    "\n",
    "# Import comprehensive evaluation framework\n",
    "from wisent_guard.core.evaluation.comprehensive import (\n",
    "    ComprehensiveEvaluationConfig,\n",
    "    ComprehensiveEvaluationPipeline,\n",
    "    plot_evaluation_results,\n",
    "    create_results_dashboard,\n",
    "    generate_summary_report,\n",
    "    calculate_comprehensive_metrics,\n",
    "    generate_performance_summary\n",
    ")\n",
    "\n",
    "# Visualization and interactivity\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.express as px\n",
    "\n",
    "from IPython.display import display, HTML, Markdown\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interact_manual, fixed\n",
    "\n",
    "# Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "# Utilities\n",
    "from tqdm.notebook import tqdm\n",
    "import logging\n",
    "\n",
    "print(\"‚úÖ All imports successful!\")\n",
    "print(f\"üìç Working directory: {os.getcwd()}\")\n",
    "print(f\"üêç Python version: {sys.version}\")\n",
    "print(f\"üíæ HuggingFace cache: {os.environ['HF_HOME']}\")\n",
    "print(f\"üîó Wandb status: {'‚úÖ Ready' if wandb_ok else '‚ö†Ô∏è May have issues'}\")\n",
    "print()\n",
    "\n",
    "# Check authentication\n",
    "hf_authenticated = check_hf_auth()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è Interactive Configuration\n",
    "\n",
    "Use the widgets below to configure your evaluation. The system will automatically set reasonable defaults based on your model choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3851b18b89941f886fcb84c45cd61ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h3>ü§ñ Configuration</h3>'), Dropdown(description='Model:', options=(('DistilGPT2 (F‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ 19 math datasets available | Default: 100 samples (auto-adjusted for smaller datasets)\n",
      "üéõÔ∏è 7 steering methods available for hyperparameter search\n",
      "üéØ Probe and steering layers are fully configurable - enter arrays like [5, 6, 7, 8]\n",
      "üëÜ Configure above, then run next cell\n"
     ]
    }
   ],
   "source": [
    "# Create interactive configuration widgets\n",
    "\n",
    "# Import math tasks from our task configuration\n",
    "import sys\n",
    "sys.path.append('/workspace/wisent-guard')\n",
    "from wisent_guard.parameters.task_config import MATH_TASKS\n",
    "\n",
    "# Import steering methods\n",
    "from wisent_guard.core.steering_methods.caa import CAA\n",
    "from wisent_guard.core.steering_methods.hpr import HPR\n",
    "from wisent_guard.core.steering_methods.dac import DAC\n",
    "from wisent_guard.core.steering_methods.bipo import BiPO\n",
    "from wisent_guard.core.steering_methods.k_steering import KSteering\n",
    "from wisent_guard.core.steering_methods.control_vector_steering import ControlVectorSteering\n",
    "\n",
    "# Available steering methods\n",
    "STEERING_METHODS = {\n",
    "    'baseline': 'Baseline (No Steering)',\n",
    "    'caa': 'CAA (Contrastive Activation Addition)',\n",
    "    'hpr': 'HPR (Householder Pseudo-Rotation)', \n",
    "    'dac': 'DAC (Dynamic Activation Composition)',\n",
    "    'bipo': 'BiPO (Bi-directional Preference Optimization)',\n",
    "    'k_steering': 'K-Steering (Multi-directional)',\n",
    "    'control_vector': 'Control Vector Steering'\n",
    "}\n",
    "\n",
    "# Dataset size mapping - default 100 for math tasks with known exceptions\n",
    "DATASET_SIZES = {\n",
    "    'math500': 500,\n",
    "    'aime': 30, 'aime2024': 30, 'aime2025': 30,\n",
    "    'hmmt': 50, 'hmmt_feb_2025': 50,\n",
    "    **{task: 100 for task in MATH_TASKS}\n",
    "}\n",
    "\n",
    "# Create simple dataset options from math tasks\n",
    "math_options = [(task.replace('_', ' ').title(), task) for task in sorted(MATH_TASKS)]\n",
    "\n",
    "# Model configuration\n",
    "model_widget = widgets.Dropdown(\n",
    "    options=[\n",
    "        ('DistilGPT2 (Fast)', 'distilbert/distilgpt2'),\n",
    "        ('GPT2', 'gpt2'),\n",
    "        ('LLaMA 3.1 8B', '/workspace/models/llama31-8b-instruct-hf'),\n",
    "        ('Qwen 3 8B', 'Qwen/Qwen3-8B')\n",
    "    ],\n",
    "    value='distilbert/distilgpt2',\n",
    "    description='Model:'\n",
    ")\n",
    "\n",
    "# Function to detect model layers\n",
    "def detect_model_layers(model_name):\n",
    "    \"\"\"Detect number of layers in a model without loading it fully.\"\"\"\n",
    "    try:\n",
    "        from transformers import AutoConfig\n",
    "        config = AutoConfig.from_pretrained(model_name)\n",
    "        \n",
    "        # Different models store layer count differently\n",
    "        if hasattr(config, 'n_layer'):\n",
    "            return config.n_layer\n",
    "        elif hasattr(config, 'num_hidden_layers'):\n",
    "            return config.num_hidden_layers\n",
    "        elif hasattr(config, 'num_layers'):\n",
    "            return config.num_layers\n",
    "        else:\n",
    "            return \"Unknown\"\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "# Model info display\n",
    "model_info_widget = widgets.HTML(value=\"\")\n",
    "\n",
    "# Layer configuration widgets\n",
    "probe_layers_widget = widgets.Text(\n",
    "    value='[2, 3, 4, 5]',\n",
    "    description='Probe layers:',\n",
    "    placeholder='e.g., [2, 3, 4, 5]',\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "steering_layers_widget = widgets.Text(\n",
    "    value='[3, 4, 5]',\n",
    "    description='Steering layers:',\n",
    "    placeholder='e.g., [3, 4, 5]',\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "def parse_layer_list(layer_text):\n",
    "    \"\"\"Parse layer list from text input with validation.\"\"\"\n",
    "    try:\n",
    "        import ast\n",
    "        layers = ast.literal_eval(layer_text)\n",
    "        if isinstance(layers, list) and all(isinstance(x, int) and x >= 0 for x in layers):\n",
    "            return layers, None\n",
    "        else:\n",
    "            return None, \"Must be a list of non-negative integers\"\n",
    "    except:\n",
    "        return None, \"Invalid format. Use [1, 2, 3] format\"\n",
    "\n",
    "def update_model_info():\n",
    "    \"\"\"Update model information display.\"\"\"\n",
    "    model_name = model_widget.value\n",
    "    num_layers = detect_model_layers(model_name)\n",
    "    \n",
    "    if isinstance(num_layers, int):\n",
    "        layer_info = f\"<b>Model:</b> {model_name}<br><b>Layers:</b> {num_layers}\"\n",
    "        \n",
    "        # Suggest appropriate layers based on model size\n",
    "        if num_layers <= 6:  # DistilGPT2\n",
    "            suggested_probe_layers = [2, 3, 4, 5]\n",
    "            suggested_steering_layers = [3, 4, 5]\n",
    "        elif num_layers <= 12:  # GPT2\n",
    "            suggested_probe_layers = [4, 6, 8, 10]\n",
    "            suggested_steering_layers = [6, 8, 10]\n",
    "        else:  # Large models\n",
    "            step = max(1, num_layers // 8)\n",
    "            suggested_probe_layers = [i for i in range(step*2, num_layers, step*2)][:4]\n",
    "            suggested_steering_layers = [i for i in range(step*3, num_layers, step*2)][:3]\n",
    "        \n",
    "        layer_info += f\"<br><b>Suggested probe layers:</b> {suggested_probe_layers}\"\n",
    "        layer_info += f\"<br><b>Suggested steering layers:</b> {suggested_steering_layers}\"\n",
    "        \n",
    "        # Update widget defaults if they haven't been manually changed\n",
    "        current_probe_layers, _ = parse_layer_list(probe_layers_widget.value)\n",
    "        current_steering_layers, _ = parse_layer_list(steering_layers_widget.value)\n",
    "        \n",
    "        # Auto-update if using default values or if layers exceed model size\n",
    "        max_layer_probe = max(current_probe_layers) if current_probe_layers else 0\n",
    "        max_layer_steering = max(current_steering_layers) if current_steering_layers else 0\n",
    "        \n",
    "        if max_layer_probe >= num_layers or probe_layers_widget.value == '[2, 3, 4, 5]':\n",
    "            probe_layers_widget.value = str(suggested_probe_layers)\n",
    "        if max_layer_steering >= num_layers or steering_layers_widget.value == '[3, 4, 5]':\n",
    "            steering_layers_widget.value = str(suggested_steering_layers)\n",
    "            \n",
    "        layer_info += f\"<br><br><i>üí° Layer arrays are automatically updated when you change models</i>\"\n",
    "    else:\n",
    "        layer_info = f\"<b>Model:</b> {model_name}<br><b>Layers:</b> {num_layers}\"\n",
    "    \n",
    "    model_info_widget.value = layer_info\n",
    "\n",
    "# Set up model observer\n",
    "model_widget.observe(lambda x: update_model_info(), names='value')\n",
    "update_model_info()\n",
    "\n",
    "# Dataset configuration\n",
    "train_dataset_widget = widgets.Dropdown(options=math_options, value='math500', description='Train:')\n",
    "val_dataset_widget = widgets.Dropdown(options=math_options, value='aime2024', description='Val:')\n",
    "test_dataset_widget = widgets.Dropdown(options=math_options, value='aime2025', description='Test:')\n",
    "\n",
    "# Sample limits with automatic adjustment\n",
    "train_limit_widget = widgets.IntSlider(value=100, min=5, max=500, step=5, description='Train samples:')\n",
    "val_limit_widget = widgets.IntSlider(value=30, min=3, max=100, step=2, description='Val samples:')\n",
    "test_limit_widget = widgets.IntSlider(value=30, min=3, max=100, step=2, description='Test samples:')\n",
    "\n",
    "# Steering methods selection\n",
    "steering_methods_widget = widgets.SelectMultiple(\n",
    "    options=[(desc, key) for key, desc in STEERING_METHODS.items()],\n",
    "    value=['baseline'],\n",
    "    description='Steering Methods:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(height='120px')\n",
    ")\n",
    "\n",
    "# Simple update function\n",
    "def update_limits():\n",
    "    train_limit_widget.max = DATASET_SIZES.get(train_dataset_widget.value, 100)\n",
    "    val_limit_widget.max = DATASET_SIZES.get(val_dataset_widget.value, 100)\n",
    "    test_limit_widget.max = DATASET_SIZES.get(test_dataset_widget.value, 100)\n",
    "\n",
    "# Set up observers\n",
    "for widget in [train_dataset_widget, val_dataset_widget, test_dataset_widget]:\n",
    "    widget.observe(lambda x: update_limits(), names='value')\n",
    "\n",
    "update_limits()\n",
    "\n",
    "# Advanced options\n",
    "enable_wandb_widget = widgets.Checkbox(value=True, description='Enable W&B logging')\n",
    "experiment_name_widget = widgets.Text(value='math_eval', description='Experiment:')\n",
    "\n",
    "# Simple layout\n",
    "display(widgets.VBox([\n",
    "    widgets.HTML(\"<h3>ü§ñ Configuration</h3>\"),\n",
    "    model_widget,\n",
    "    model_info_widget,\n",
    "    widgets.HTML(\"<h4>üéØ Layer Configuration</h4>\"),\n",
    "    widgets.HTML(\"<i>Specify which layers to search during hyperparameter optimization:</i>\"),\n",
    "    probe_layers_widget,\n",
    "    steering_layers_widget,\n",
    "    widgets.HTML(\"<h4>üìä Math Datasets</h4>\"),\n",
    "    widgets.HBox([train_dataset_widget, val_dataset_widget, test_dataset_widget]),\n",
    "    widgets.HTML(\"<h4>üî¢ Sample Limits</h4>\"),\n",
    "    widgets.HBox([train_limit_widget, val_limit_widget, test_limit_widget]),\n",
    "    widgets.HTML(\"<h4>üéõÔ∏è Steering Methods</h4>\"),\n",
    "    widgets.HTML(\"<i>Select which steering methods to include in hyperparameter search:</i>\"),\n",
    "    steering_methods_widget,\n",
    "    widgets.HTML(\"<h4>‚öôÔ∏è Options</h4>\"),\n",
    "    widgets.HBox([enable_wandb_widget, experiment_name_widget])\n",
    "]))\n",
    "\n",
    "print(f\"‚úÖ {len(MATH_TASKS)} math datasets available | Default: 100 samples (auto-adjusted for smaller datasets)\")\n",
    "print(f\"üéõÔ∏è {len(STEERING_METHODS)} steering methods available for hyperparameter search\")\n",
    "print(\"üéØ Probe and steering layers are fully configurable - enter arrays like [5, 6, 7, 8]\")\n",
    "print(\"üëÜ Configure above, then run next cell\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üõ†Ô∏è Create Configuration\n",
    "\n",
    "Run this cell to create your evaluation configuration based on the widgets above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã CONFIGURATION SUMMARY\n",
      "==================================================\n",
      "ü§ñ Model: distilbert/distilgpt2\n",
      "üìä Datasets: math500 ‚Üí aime2024 ‚Üí aime2025\n",
      "üî¢ Samples: 100 + 30 + 30 = 160 total\n",
      "üéØ Probe layers: [2, 3, 4, 5]\n",
      "‚öôÔ∏è Steering layers: [3, 4, 5]\n",
      "üéõÔ∏è Steering methods: ['baseline']\n",
      "üß™ Total hyperparameter combinations: 36\n",
      "üìà Wandb enabled: True\n",
      "==================================================\n",
      "‚è±Ô∏è Estimated runtime: ~18.0 minutes\n",
      "\n",
      "‚úÖ Configuration created successfully!\n"
     ]
    }
   ],
   "source": [
    "# Create configuration from widget values\n",
    "\n",
    "# Parse layer arrays from text widgets\n",
    "def parse_layer_list(layer_text):\n",
    "    \"\"\"Parse layer list from text input with validation.\"\"\"\n",
    "    try:\n",
    "        import ast\n",
    "        layers = ast.literal_eval(layer_text)\n",
    "        if isinstance(layers, list) and all(isinstance(x, int) and x >= 0 for x in layers):\n",
    "            return layers, None\n",
    "        else:\n",
    "            return None, \"Must be a list of non-negative integers\"\n",
    "    except:\n",
    "        return None, \"Invalid format. Use [1, 2, 3] format\"\n",
    "\n",
    "# Parse probe layers\n",
    "probe_layers, probe_error = parse_layer_list(probe_layers_widget.value)\n",
    "if probe_error:\n",
    "    print(f\"‚ùå Probe layers error: {probe_error}\")\n",
    "    print(f\"Current value: {probe_layers_widget.value}\")\n",
    "    raise ValueError(f\"Invalid probe layers: {probe_error}\")\n",
    "\n",
    "# Parse steering layers\n",
    "steering_layers, steering_error = parse_layer_list(steering_layers_widget.value)\n",
    "if steering_error:\n",
    "    print(f\"‚ùå Steering layers error: {steering_error}\")\n",
    "    print(f\"Current value: {steering_layers_widget.value}\")\n",
    "    raise ValueError(f\"Invalid steering layers: {steering_error}\")\n",
    "\n",
    "config = ComprehensiveEvaluationConfig(\n",
    "    model_name=model_widget.value,\n",
    "    train_dataset=train_dataset_widget.value,\n",
    "    val_dataset=val_dataset_widget.value,\n",
    "    test_dataset=test_dataset_widget.value,\n",
    "    train_limit=train_limit_widget.value,\n",
    "    val_limit=val_limit_widget.value,\n",
    "    test_limit=test_limit_widget.value,\n",
    "    probe_layers=probe_layers,  # Use parsed layers\n",
    "    steering_layers=steering_layers,  # Use parsed layers\n",
    "    steering_methods=list(steering_methods_widget.value),  # Use selected steering methods\n",
    "    enable_wandb=enable_wandb_widget.value,\n",
    "    experiment_name=experiment_name_widget.value\n",
    ")\n",
    "\n",
    "# Display configuration summary\n",
    "print(\"üìã CONFIGURATION SUMMARY\")\n",
    "print(\"=\"*50)\n",
    "print(f\"ü§ñ Model: {config.model_name}\")\n",
    "print(f\"üìä Datasets: {config.train_dataset} ‚Üí {config.val_dataset} ‚Üí {config.test_dataset}\")\n",
    "print(f\"üî¢ Samples: {config.train_limit} + {config.val_limit} + {config.test_limit} = {config.train_limit + config.val_limit + config.test_limit} total\")\n",
    "print(f\"üéØ Probe layers: {config.probe_layers}\")\n",
    "print(f\"‚öôÔ∏è Steering layers: {config.steering_layers}\")\n",
    "print(f\"üéõÔ∏è Steering methods: {config.steering_methods}\")\n",
    "print(f\"üß™ Total hyperparameter combinations: {config.get_hyperparameter_search_space_size()}\")\n",
    "print(f\"üìà Wandb enabled: {config.enable_wandb}\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Estimate runtime\n",
    "estimated_minutes = config.get_hyperparameter_search_space_size() * 0.5  # Rough estimate\n",
    "print(f\"‚è±Ô∏è Estimated runtime: ~{estimated_minutes:.1f} minutes\")\n",
    "\n",
    "if config.get_hyperparameter_search_space_size() > 50:\n",
    "    print(\"‚ö†Ô∏è Large search space detected. Consider reducing sample sizes for faster testing.\")\n",
    "\n",
    "print(\"\\n‚úÖ Configuration created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ Run Comprehensive Evaluation\n",
    "\n",
    "This is the main evaluation cell. It will:\n",
    "\n",
    "1. **üéØ Train Probes**: Train correctness classifiers on all specified layers\n",
    "2. **‚öôÔ∏è Optimize Hyperparameters**: Grid search for best steering + probe combinations\n",
    "3. **üèÜ Final Evaluation**: Test optimized configuration on held-out test set\n",
    "\n",
    "**Note**: This may take several minutes depending on your configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjanwisent\u001b[0m (\u001b[33mwisent\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/wisent-guard/comprehensive_evaluation/wandb/run-20250724_145323-sq6z5gn1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/wisent/wisent-guard-comprehensive-evaluation/runs/sq6z5gn1' target=\"_blank\">math_eval_20250724_145322</a></strong> to <a href='https://wandb.ai/wisent/wisent-guard-comprehensive-evaluation' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/wisent/wisent-guard-comprehensive-evaluation' target=\"_blank\">https://wandb.ai/wisent/wisent-guard-comprehensive-evaluation</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/wisent/wisent-guard-comprehensive-evaluation/runs/sq6z5gn1' target=\"_blank\">https://wandb.ai/wisent/wisent-guard-comprehensive-evaluation/runs/sq6z5gn1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:wisent_guard.core.evaluation.comprehensive.pipeline:Wandb experiment initialized successfully\n",
      "INFO:wisent_guard.core.evaluation.comprehensive.pipeline:================================================================================\n",
      "INFO:wisent_guard.core.evaluation.comprehensive.pipeline:üöÄ STARTING COMPREHENSIVE EVALUATION PIPELINE\n",
      "INFO:wisent_guard.core.evaluation.comprehensive.pipeline:================================================================================\n",
      "INFO:wisent_guard.core.evaluation.comprehensive.pipeline:Train: math500\n",
      "INFO:wisent_guard.core.evaluation.comprehensive.pipeline:Validation: aime2024\n",
      "INFO:wisent_guard.core.evaluation.comprehensive.pipeline:Test: aime2025\n",
      "INFO:wisent_guard.core.evaluation.comprehensive.pipeline:Model: distilbert/distilgpt2\n",
      "INFO:wisent_guard.core.evaluation.comprehensive.data_utils:Loading model distilbert/distilgpt2 (ONCE)...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting comprehensive evaluation...\n",
      "This may take several minutes. Check the logs below for progress.\n",
      "\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43b4120372e74cd9829b63e8f4653d47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27cabf99d6ee4ce4bdda5997849fa06f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fb3714cd5d74d9ab0b73a6f3f1e25c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffa74a0b79c84219ab2bf21be6ec756d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab4a282cd8544c518931d8297cb67607",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/353M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed55fc11b4c94a8c982c88194655109e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:wisent_guard.core.evaluation.comprehensive.data_utils:‚úì Model loaded on cuda, GPU memory: 0.16 GB\n",
      "INFO:wisent_guard.core.evaluation.comprehensive.pipeline:\n",
      "üìä Loading datasets...\n",
      "INFO:wisent_guard.core.evaluation.comprehensive.data_utils:Loading 100 samples from math500...\n",
      "INFO:wisent_guard.core.evaluation.comprehensive.data_utils:Loaded 100 samples from math500 via Math500Task\n",
      "INFO:wisent_guard.core.evaluation.comprehensive.data_utils:Loading 30 samples from aime2024...\n",
      "INFO:wisent_guard.core.evaluation.comprehensive.data_utils:Loaded 30 samples from aime2024 via AIMETask\n",
      "INFO:wisent_guard.core.evaluation.comprehensive.data_utils:Loading 30 samples from aime2025...\n",
      "INFO:wisent_guard.core.evaluation.comprehensive.data_utils:Loaded 30 samples from aime2025 via AIMETask\n",
      "INFO:wisent_guard.core.evaluation.comprehensive.pipeline:\n",
      "üéØ Phase 1: Training Probes...\n",
      "INFO:wisent_guard.core.evaluation.comprehensive.pipeline:Training probes for layer 2...\n",
      "INFO:wisent_guard.core.evaluation.comprehensive.pipeline:  Layer 2, C=0.1: Acc=0.955, AUC=0.996\n",
      "INFO:wisent_guard.core.evaluation.comprehensive.pipeline:  Layer 2, C=1.0: Acc=0.955, AUC=0.996\n",
      "INFO:wisent_guard.core.evaluation.comprehensive.pipeline:  Layer 2, C=10.0: Acc=0.955, AUC=0.996\n",
      "INFO:wisent_guard.core.evaluation.comprehensive.pipeline:Training probes for layer 3...\n",
      "INFO:wisent_guard.core.evaluation.comprehensive.pipeline:  Layer 3, C=0.1: Acc=0.955, AUC=0.996\n",
      "INFO:wisent_guard.core.evaluation.comprehensive.pipeline:  Layer 3, C=1.0: Acc=0.955, AUC=0.996\n",
      "INFO:wisent_guard.core.evaluation.comprehensive.pipeline:  Layer 3, C=10.0: Acc=0.955, AUC=0.996\n",
      "INFO:wisent_guard.core.evaluation.comprehensive.pipeline:Training probes for layer 4...\n",
      "INFO:wisent_guard.core.evaluation.comprehensive.pipeline:  Layer 4, C=0.1: Acc=0.955, AUC=0.996\n",
      "INFO:wisent_guard.core.evaluation.comprehensive.pipeline:  Layer 4, C=1.0: Acc=0.955, AUC=0.996\n",
      "INFO:wisent_guard.core.evaluation.comprehensive.pipeline:  Layer 4, C=10.0: Acc=0.955, AUC=0.996\n",
      "INFO:wisent_guard.core.evaluation.comprehensive.pipeline:Training probes for layer 5...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Run evaluation with progress tracking\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 10\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_comprehensive_evaluation\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m80\u001b[39m)\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m‚úÖ Evaluation completed successfully!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/workspace/wisent-guard/wisent_guard/core/evaluation/comprehensive/pipeline.py:89\u001b[0m, in \u001b[0;36mComprehensiveEvaluationPipeline.run_comprehensive_evaluation\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;66;03m# Phase 1: Train Probes\u001b[39;00m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124müéØ Phase 1: Training Probes...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 89\u001b[0m probe_training_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_probes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_samples\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprobe_training_results\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m probe_training_results\n\u001b[1;32m     92\u001b[0m \u001b[38;5;66;03m# Phase 2: Validation - Optimize Steering Based on Benchmark Performance\u001b[39;00m\n",
      "File \u001b[0;32m/workspace/wisent-guard/wisent_guard/core/evaluation/comprehensive/pipeline.py:124\u001b[0m, in \u001b[0;36mComprehensiveEvaluationPipeline._train_probes\u001b[0;34m(self, train_samples)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining probes for layer \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    123\u001b[0m \u001b[38;5;66;03m# Create training data\u001b[39;00m\n\u001b[0;32m--> 124\u001b[0m X_train, y_train \u001b[38;5;241m=\u001b[39m \u001b[43mdata_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_probe_training_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    129\u001b[0m layer_results \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m C \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mprobe_c_values:\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;66;03m# Train probe\u001b[39;00m\n",
      "File \u001b[0;32m/workspace/wisent-guard/wisent_guard/core/evaluation/comprehensive/data_utils.py:173\u001b[0m, in \u001b[0;36mcreate_probe_training_data\u001b[0;34m(model, tokenizer, samples, layer, batch_size, max_length, device)\u001b[0m\n\u001b[1;32m    170\u001b[0m inputs \u001b[38;5;241m=\u001b[39m tokenizer(prompt, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m, truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, max_length\u001b[38;5;241m=\u001b[39mmax_length)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 173\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdo_sample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meos_token_id\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    180\u001b[0m generated \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mdecode(outputs[\u001b[38;5;241m0\u001b[39m][inputs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]:], skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[1;32m    182\u001b[0m \u001b[38;5;66;03m# Create examples with model's actual prediction\u001b[39;00m\n",
      "File \u001b[0;32m/workspace/venv/lib/python3.10/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspace/venv/lib/python3.10/site-packages/transformers/generation/utils.py:2625\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, custom_generate, **kwargs)\u001b[0m\n\u001b[1;32m   2617\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   2618\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   2619\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences,\n\u001b[1;32m   2620\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   2621\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   2622\u001b[0m     )\n\u001b[1;32m   2624\u001b[0m     \u001b[38;5;66;03m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[0;32m-> 2625\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2626\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2627\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2628\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2629\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2630\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2631\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2632\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2633\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2635\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SAMPLE, GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SEARCH):\n\u001b[1;32m   2636\u001b[0m     \u001b[38;5;66;03m# 11. interleave input_ids with `num_beams` additional sequences per batch\u001b[39;00m\n\u001b[1;32m   2637\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   2638\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   2639\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[1;32m   2640\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   2641\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   2642\u001b[0m     )\n",
      "File \u001b[0;32m/workspace/venv/lib/python3.10/site-packages/transformers/generation/utils.py:3609\u001b[0m, in \u001b[0;36mGenerationMixin._sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   3607\u001b[0m     is_prefill \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   3608\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 3609\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   3611\u001b[0m \u001b[38;5;66;03m# synced_gpus: don't waste resources running the code we don't need; kwargs must be updated before skipping\u001b[39;00m\n\u001b[1;32m   3612\u001b[0m model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_model_kwargs_for_generation(\n\u001b[1;32m   3613\u001b[0m     outputs,\n\u001b[1;32m   3614\u001b[0m     model_kwargs,\n\u001b[1;32m   3615\u001b[0m     is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   3616\u001b[0m )\n",
      "File \u001b[0;32m/workspace/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspace/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/workspace/venv/lib/python3.10/site-packages/transformers/models/gpt2/modeling_gpt2.py:1189\u001b[0m, in \u001b[0;36mGPT2LMHeadModel.forward\u001b[0;34m(self, input_ids, past_key_values, cache_position, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, use_cache, output_attentions, output_hidden_states, return_dict, logits_to_keep, **kwargs)\u001b[0m\n\u001b[1;32m   1169\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1170\u001b[0m \u001b[38;5;124;03minput_ids (`torch.LongTensor` of shape `(batch_size, input_ids_length)`):\u001b[39;00m\n\u001b[1;32m   1171\u001b[0m \u001b[38;5;124;03m    `input_ids_length` = `sequence_length` if `past_key_values` is `None` else\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1185\u001b[0m \u001b[38;5;124;03m    are ignored (masked), the loss is only computed for labels in `[0, ..., config.vocab_size]`\u001b[39;00m\n\u001b[1;32m   1186\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1189\u001b[0m transformer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1190\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1192\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1193\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1194\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1196\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1197\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1200\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1201\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1202\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1203\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1204\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1205\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m transformer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1207\u001b[0m \u001b[38;5;66;03m# Set device for model parallelism\u001b[39;00m\n",
      "File \u001b[0;32m/workspace/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspace/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/workspace/venv/lib/python3.10/site-packages/transformers/models/gpt2/modeling_gpt2.py:917\u001b[0m, in \u001b[0;36mGPT2Model.forward\u001b[0;34m(self, input_ids, past_key_values, cache_position, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, output_hidden_states, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states:\n\u001b[1;32m    915\u001b[0m     all_hidden_states \u001b[38;5;241m=\u001b[39m all_hidden_states \u001b[38;5;241m+\u001b[39m (hidden_states,)\n\u001b[0;32m--> 917\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    918\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    919\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgradient_checkpointing\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    920\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    921\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    922\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    923\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# as a positional argument for gradient checkpointing\u001b[39;49;00m\n\u001b[1;32m    924\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    925\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    926\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    927\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    928\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    930\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    932\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
      "File \u001b[0;32m/workspace/venv/lib/python3.10/site-packages/transformers/modeling_layers.py:83\u001b[0m, in \u001b[0;36mGradientCheckpointingLayer.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     80\u001b[0m         logger\u001b[38;5;241m.\u001b[39mwarning(message)\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(partial(\u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs), \u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m---> 83\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspace/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspace/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/workspace/venv/lib/python3.10/site-packages/transformers/utils/deprecation.py:172\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action\u001b[38;5;241m.\u001b[39mNOTIFY, Action\u001b[38;5;241m.\u001b[39mNOTIFY_ALWAYS) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[1;32m    170\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m--> 172\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspace/venv/lib/python3.10/site-packages/transformers/models/gpt2/modeling_gpt2.py:440\u001b[0m, in \u001b[0;36mGPT2Block.forward\u001b[0;34m(self, hidden_states, past_key_value, cache_position, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, **kwargs)\u001b[0m\n\u001b[1;32m    438\u001b[0m residual \u001b[38;5;241m=\u001b[39m hidden_states\n\u001b[1;32m    439\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln_2(hidden_states)\n\u001b[0;32m--> 440\u001b[0m feed_forward_hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmlp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    441\u001b[0m \u001b[38;5;66;03m# residual connection\u001b[39;00m\n\u001b[1;32m    442\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m feed_forward_hidden_states\n",
      "File \u001b[0;32m/workspace/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspace/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/workspace/venv/lib/python3.10/site-packages/transformers/models/gpt2/modeling_gpt2.py:366\u001b[0m, in \u001b[0;36mGPT2MLP.forward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states: Optional[\u001b[38;5;28mtuple\u001b[39m[torch\u001b[38;5;241m.\u001b[39mFloatTensor]]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mFloatTensor:\n\u001b[1;32m    365\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mc_fc(hidden_states)\n\u001b[0;32m--> 366\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mact\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    367\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mc_proj(hidden_states)\n\u001b[1;32m    368\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(hidden_states)\n",
      "File \u001b[0;32m/workspace/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspace/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <bound method _WandbInit._post_run_cell_hook of <wandb.sdk.wandb_init._WandbInit object at 0x78d4e046aa70>> (for post_run_cell), with arguments args (<ExecutionResult object at 78d4e04692d0, execution_count=8 error_before_exec=None error_in_exec= info=<ExecutionInfo object at 78d4e046a740, raw_cell=\"# Initialize pipeline\n",
      "pipeline = ComprehensiveEval..\" store_history=True silent=False shell_futures=True cell_id=vscode-notebook-cell://ssh-remote%2Brunpod/workspace/wisent-guard/comprehensive_evaluation/comprehensive_evaluation_notebook.ipynb#Y125sdnNjb2RlLXJlbW90ZQ%3D%3D> result=None>,),kwargs {}:\n"
     ]
    },
    {
     "ename": "BrokenPipeError",
     "evalue": "[Errno 32] Broken pipe",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBrokenPipeError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m/workspace/venv/lib/python3.10/site-packages/wandb/sdk/wandb_init.py:593\u001b[0m, in \u001b[0;36m_WandbInit._post_run_cell_hook\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    590\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    592\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresuming backend\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 593\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterface\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpublish_resume\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspace/venv/lib/python3.10/site-packages/wandb/sdk/interface/interface.py:787\u001b[0m, in \u001b[0;36mInterfaceBase.publish_resume\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    785\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpublish_resume\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    786\u001b[0m     resume \u001b[38;5;241m=\u001b[39m pb\u001b[38;5;241m.\u001b[39mResumeRequest()\n\u001b[0;32m--> 787\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_publish_resume\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresume\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspace/venv/lib/python3.10/site-packages/wandb/sdk/interface/interface_shared.py:294\u001b[0m, in \u001b[0;36mInterfaceShared._publish_resume\u001b[0;34m(self, resume)\u001b[0m\n\u001b[1;32m    292\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_publish_resume\u001b[39m(\u001b[38;5;28mself\u001b[39m, resume: pb\u001b[38;5;241m.\u001b[39mResumeRequest) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    293\u001b[0m     rec \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(resume\u001b[38;5;241m=\u001b[39mresume)\n\u001b[0;32m--> 294\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_publish\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrec\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspace/venv/lib/python3.10/site-packages/wandb/sdk/interface/interface_sock.py:39\u001b[0m, in \u001b[0;36mInterfaceSock._publish\u001b[0;34m(self, record, local)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_publish\u001b[39m(\u001b[38;5;28mself\u001b[39m, record: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpb.Record\u001b[39m\u001b[38;5;124m\"\u001b[39m, local: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign(record)\n\u001b[0;32m---> 39\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_record_publish\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecord\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspace/venv/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py:170\u001b[0m, in \u001b[0;36mSockClient.send_record_publish\u001b[0;34m(self, record)\u001b[0m\n\u001b[1;32m    168\u001b[0m server_req\u001b[38;5;241m.\u001b[39mrequest_id \u001b[38;5;241m=\u001b[39m record\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mmailbox_slot\n\u001b[1;32m    169\u001b[0m server_req\u001b[38;5;241m.\u001b[39mrecord_publish\u001b[38;5;241m.\u001b[39mCopyFrom(record)\n\u001b[0;32m--> 170\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_server_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mserver_req\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspace/venv/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py:150\u001b[0m, in \u001b[0;36mSockClient.send_server_request\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21msend_server_request\u001b[39m(\u001b[38;5;28mself\u001b[39m, msg: spb\u001b[38;5;241m.\u001b[39mServerRequest) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspace/venv/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py:147\u001b[0m, in \u001b[0;36mSockClient._send_message\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m    145\u001b[0m header \u001b[38;5;241m=\u001b[39m struct\u001b[38;5;241m.\u001b[39mpack(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<BI\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mord\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mW\u001b[39m\u001b[38;5;124m\"\u001b[39m), raw_size)\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m--> 147\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sendall_with_error_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mheader\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspace/venv/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py:126\u001b[0m, in \u001b[0;36mSockClient._sendall_with_error_handle\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    124\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 126\u001b[0m     sent \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;66;03m# sent equal to 0 indicates a closed socket\u001b[39;00m\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sent \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[0;31mBrokenPipeError\u001b[0m: [Errno 32] Broken pipe"
     ]
    }
   ],
   "source": [
    "# Initialize pipeline\n",
    "pipeline = ComprehensiveEvaluationPipeline(config)\n",
    "\n",
    "print(\"üöÄ Starting comprehensive evaluation...\")\n",
    "print(\"This may take several minutes. Check the logs below for progress.\")\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "\n",
    "# Run evaluation with progress tracking\n",
    "try:\n",
    "    results = pipeline.run_comprehensive_evaluation()\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"‚úÖ Evaluation completed successfully!\")\n",
    "    \n",
    "    # Store results for analysis\n",
    "    evaluation_results = results\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå Evaluation failed: {str(e)}\")\n",
    "    print(\"Check the logs above for more details.\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Results Analysis\n",
    "\n",
    "Now let's analyze the results with comprehensive metrics and visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate comprehensive metrics\n",
    "comprehensive_metrics = calculate_comprehensive_metrics(evaluation_results)\n",
    "\n",
    "# Generate performance summary\n",
    "performance_summary = generate_performance_summary(comprehensive_metrics)\n",
    "print(performance_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìà Interactive Visualizations\n",
    "\n",
    "Explore your results with interactive plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create interactive dashboard\n",
    "dashboard = create_results_dashboard(evaluation_results)\n",
    "dashboard.show()\n",
    "\n",
    "print(\"\\nüìä Interactive dashboard displayed above!\")\n",
    "print(\"üí° Hover over points and bars for detailed information.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Detailed Analysis: Benchmark Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract benchmark results\n",
    "if \"test_results\" in evaluation_results:\n",
    "    test_results = evaluation_results[\"test_results\"]\n",
    "    \n",
    "    base_benchmark = test_results.get(\"base_model_benchmark_results\", {})\n",
    "    steered_benchmark = test_results.get(\"steered_model_benchmark_results\", {})\n",
    "    \n",
    "    print(\"üéØ BENCHMARK PERFORMANCE ANALYSIS\")\n",
    "    print(\"=\"*40)\n",
    "    \n",
    "    print(f\"\\nüìä Base Model:\")\n",
    "    print(f\"  ‚úì Accuracy: {base_benchmark.get('accuracy', 0):.3f} ({base_benchmark.get('accuracy', 0)*100:.1f}%)\")\n",
    "    print(f\"  ‚úì Correct: {base_benchmark.get('correct', 0)}/{base_benchmark.get('total_samples', 0)}\")\n",
    "    \n",
    "    print(f\"\\nüéØ Steered Model:\")\n",
    "    print(f\"  ‚úì Accuracy: {steered_benchmark.get('accuracy', 0):.3f} ({steered_benchmark.get('accuracy', 0)*100:.1f}%)\")\n",
    "    print(f\"  ‚úì Correct: {steered_benchmark.get('correct', 0)}/{steered_benchmark.get('total_samples', 0)}\")\n",
    "    \n",
    "    improvement = steered_benchmark.get('accuracy', 0) - base_benchmark.get('accuracy', 0)\n",
    "    improvement_percent = (improvement / max(base_benchmark.get('accuracy', 0.001), 0.001)) * 100\n",
    "    \n",
    "    print(f\"\\nüìà Improvement:\")\n",
    "    print(f\"  {'‚úÖ' if improvement > 0 else '‚ùå'} {improvement:+.3f} absolute ({improvement_percent:+.1f}% relative)\")\n",
    "    \n",
    "    if improvement > 0.05:\n",
    "        print(\"  üéâ Significant improvement! Steering is working well.\")\n",
    "    elif improvement > 0.01:\n",
    "        print(\"  üëç Moderate improvement. Consider tuning hyperparameters.\")\n",
    "    elif improvement > -0.01:\n",
    "        print(\"  ‚ö™ Minimal change. Steering may not be effective for this configuration.\")\n",
    "    else:\n",
    "        print(\"  ‚ö†Ô∏è Performance decreased. Check steering implementation.\")\n",
    "else:\n",
    "    print(\"‚ùå No test results found in evaluation data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîç Detailed Analysis: Probe Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract probe results\n",
    "if \"test_results\" in evaluation_results:\n",
    "    base_probe = test_results.get(\"base_model_probe_results\", {})\n",
    "    steered_probe = test_results.get(\"steered_model_probe_results\", {})\n",
    "    \n",
    "    print(\"üîç PROBE PERFORMANCE ANALYSIS\")\n",
    "    print(\"=\"*40)\n",
    "    \n",
    "    print(f\"\\nüìä Base Model Probe:\")\n",
    "    print(f\"  ‚úì AUC: {base_probe.get('auc', 0.5):.3f}\")\n",
    "    print(f\"  ‚úì Accuracy: {base_probe.get('accuracy', 0.5):.3f}\")\n",
    "    print(f\"  ‚úì Precision: {base_probe.get('precision', 0.5):.3f}\")\n",
    "    print(f\"  ‚úì Recall: {base_probe.get('recall', 0.5):.3f}\")\n",
    "    print(f\"  ‚úì F1-Score: {base_probe.get('f1', 0.5):.3f}\")\n",
    "    \n",
    "    print(f\"\\nüéØ Steered Model Probe:\")\n",
    "    print(f\"  ‚úì AUC: {steered_probe.get('auc', 0.5):.3f}\")\n",
    "    print(f\"  ‚úì Accuracy: {steered_probe.get('accuracy', 0.5):.3f}\")\n",
    "    print(f\"  ‚úì Precision: {steered_probe.get('precision', 0.5):.3f}\")\n",
    "    print(f\"  ‚úì Recall: {steered_probe.get('recall', 0.5):.3f}\")\n",
    "    print(f\"  ‚úì F1-Score: {steered_probe.get('f1', 0.5):.3f}\")\n",
    "    \n",
    "    auc_improvement = steered_probe.get('auc', 0.5) - base_probe.get('auc', 0.5)\n",
    "    \n",
    "    print(f\"\\nüìà AUC Improvement:\")\n",
    "    print(f\"  {'‚úÖ' if auc_improvement > 0 else '‚ùå'} {auc_improvement:+.3f}\")\n",
    "    \n",
    "    # Interpret probe performance\n",
    "    best_auc = max(base_probe.get('auc', 0.5), steered_probe.get('auc', 0.5))\n",
    "    \n",
    "    if best_auc > 0.9:\n",
    "        print(\"  üéâ Excellent probe performance! Activations strongly predict correctness.\")\n",
    "    elif best_auc > 0.8:\n",
    "        print(\"  üëç Good probe performance. Activations are informative.\")\n",
    "    elif best_auc > 0.7:\n",
    "        print(\"  ‚ö™ Moderate probe performance. Some signal present.\")\n",
    "    elif best_auc > 0.6:\n",
    "        print(\"  ‚ö†Ô∏è Weak probe performance. Limited interpretability.\")\n",
    "    else:\n",
    "        print(\"  ‚ùå Poor probe performance. Activations may not encode correctness.\")\n",
    "else:\n",
    "    print(\"‚ùå No test results found in evaluation data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è Hyperparameter Optimization Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze hyperparameter optimization results\n",
    "if \"steering_optimization_results\" in evaluation_results:\n",
    "    opt_results = evaluation_results[\"steering_optimization_results\"]\n",
    "    all_configs = opt_results.get(\"all_configs\", [])\n",
    "    best_config = opt_results.get(\"best_config\", {})\n",
    "    \n",
    "    print(\"‚öôÔ∏è HYPERPARAMETER OPTIMIZATION ANALYSIS\")\n",
    "    print(\"=\"*45)\n",
    "    \n",
    "    print(f\"\\nüìä Search Statistics:\")\n",
    "    print(f\"  ‚úì Configurations tested: {len(all_configs)}\")\n",
    "    print(f\"  ‚úì Best combined score: {opt_results.get('best_combined_score', 0):.3f}\")\n",
    "    \n",
    "    if best_config:\n",
    "        steering_config = best_config.get(\"steering_config\", {})\n",
    "        probe_config = best_config.get(\"best_probe_config\", {})\n",
    "        \n",
    "        print(f\"\\nüèÜ Best Configuration:\")\n",
    "        print(f\"  ‚úì Steering method: {steering_config.get('method', 'N/A')}\")\n",
    "        print(f\"  ‚úì Steering layer: {steering_config.get('layer', 'N/A')}\")\n",
    "        print(f\"  ‚úì Steering strength: {steering_config.get('strength', 'N/A')}\")\n",
    "        print(f\"  ‚úì Probe layer: {probe_config.get('layer', 'N/A')}\")\n",
    "        print(f\"  ‚úì Probe C value: {probe_config.get('C', 'N/A')}\")\n",
    "        \n",
    "        benchmark_metrics = best_config.get(\"benchmark_metrics\", {})\n",
    "        probe_metrics = best_config.get(\"probe_metrics\", {})\n",
    "        \n",
    "        print(f\"\\nüìà Best Configuration Performance:\")\n",
    "        print(f\"  ‚úì Benchmark accuracy: {benchmark_metrics.get('accuracy', 0):.3f}\")\n",
    "        print(f\"  ‚úì Probe AUC: {probe_metrics.get('auc', 0.5):.3f}\")\n",
    "        print(f\"  ‚úì Combined score: {best_config.get('combined_score', 0):.3f}\")\n",
    "    \n",
    "    # Analyze score distribution\n",
    "    if all_configs:\n",
    "        scores = [config.get(\"combined_score\", 0) for config in all_configs]\n",
    "        benchmark_scores = [config.get(\"benchmark_metrics\", {}).get(\"accuracy\", 0) for config in all_configs]\n",
    "        probe_scores = [config.get(\"probe_metrics\", {}).get(\"auc\", 0.5) for config in all_configs]\n",
    "        \n",
    "        print(f\"\\nüìä Score Distribution:\")\n",
    "        print(f\"  ‚úì Combined score: {np.mean(scores):.3f} ¬± {np.std(scores):.3f}\")\n",
    "        print(f\"  ‚úì Benchmark score: {np.mean(benchmark_scores):.3f} ¬± {np.std(benchmark_scores):.3f}\")\n",
    "        print(f\"  ‚úì Probe score: {np.mean(probe_scores):.3f} ¬± {np.std(probe_scores):.3f}\")\n",
    "        \n",
    "        # Check if optimization was effective\n",
    "        score_range = max(scores) - min(scores)\n",
    "        if score_range > 0.1:\n",
    "            print(\"  üéØ Good optimization! Significant variation in scores.\")\n",
    "        elif score_range > 0.05:\n",
    "            print(\"  üëç Moderate optimization. Some configurations better than others.\")\n",
    "        else:\n",
    "            print(\"  ‚ö™ Limited optimization benefit. Most configurations perform similarly.\")\n",
    "else:\n",
    "    print(\"‚ùå No optimization results found in evaluation data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Training Performance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze probe training performance by layer\n",
    "if \"probe_training_results\" in evaluation_results:\n",
    "    training_results = evaluation_results[\"probe_training_results\"]\n",
    "    \n",
    "    print(\"üìä PROBE TRAINING ANALYSIS\")\n",
    "    print(\"=\"*35)\n",
    "    \n",
    "    # Create summary table\n",
    "    training_data = []\n",
    "    \n",
    "    for layer_key, layer_results in training_results.items():\n",
    "        layer_num = int(layer_key.split('_')[1])\n",
    "        \n",
    "        best_auc = 0\n",
    "        best_config = None\n",
    "        \n",
    "        for c_key, metrics in layer_results.items():\n",
    "            if isinstance(metrics, dict) and \"auc\" in metrics:\n",
    "                if metrics[\"auc\"] > best_auc:\n",
    "                    best_auc = metrics[\"auc\"]\n",
    "                    best_config = c_key\n",
    "        \n",
    "        training_data.append({\n",
    "            'Layer': layer_num,\n",
    "            'Best AUC': best_auc,\n",
    "            'Best C': best_config.replace('C_', '') if best_config else 'N/A'\n",
    "        })\n",
    "    \n",
    "    # Display as formatted table\n",
    "    df_training = pd.DataFrame(training_data).sort_values('Layer')\n",
    "    \n",
    "    print(f\"\\n{'Layer':<8} {'Best AUC':<10} {'Best C':<10}\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    for _, row in df_training.iterrows():\n",
    "        print(f\"{row['Layer']:<8} {row['Best AUC']:<10.3f} {row['Best C']:<10}\")\n",
    "    \n",
    "    # Find best performing layer\n",
    "    best_layer_row = df_training.loc[df_training['Best AUC'].idxmax()]\n",
    "    worst_layer_row = df_training.loc[df_training['Best AUC'].idxmin()]\n",
    "    \n",
    "    print(f\"\\nüèÜ Best performing layer: {best_layer_row['Layer']} (AUC: {best_layer_row['Best AUC']:.3f})\")\n",
    "    print(f\"‚ö†Ô∏è Worst performing layer: {worst_layer_row['Layer']} (AUC: {worst_layer_row['Best AUC']:.3f})\")\n",
    "    \n",
    "    # Layer performance insights\n",
    "    auc_std = df_training['Best AUC'].std()\n",
    "    if auc_std > 0.1:\n",
    "        print(\"\\nüí° High variation across layers - layer choice matters!\")\n",
    "    elif auc_std > 0.05:\n",
    "        print(\"\\nüí° Moderate variation - some layers work better than others.\")\n",
    "    else:\n",
    "        print(\"\\nüí° Consistent performance across layers.\")\n",
    "        \n",
    "else:\n",
    "    print(\"‚ùå No training results found in evaluation data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìà Static Visualizations\n",
    "\n",
    "Create comprehensive static plots for reports and publications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive static visualization\n",
    "fig = plot_evaluation_results(evaluation_results)\n",
    "plt.show()\n",
    "\n",
    "print(\"üìä Comprehensive evaluation plots displayed above.\")\n",
    "print(\"üíæ Plots are saved automatically in the results directory.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üíæ Export Results\n",
    "\n",
    "Save your results in various formats for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results Export and Storage Options\n",
    "print(\"üìä RESULTS STORAGE SUMMARY\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Check if wandb is enabled and results were logged\n",
    "if config.enable_wandb:\n",
    "    print(\"‚úÖ Weights & Biases logging is ENABLED\")\n",
    "    print(\"üìà All evaluation results have been automatically logged to wandb including:\")\n",
    "    print(\"   ‚Ä¢ Configuration parameters\")\n",
    "    print(\"   ‚Ä¢ Probe training metrics\")\n",
    "    print(\"   ‚Ä¢ Hyperparameter optimization results\") \n",
    "    print(\"   ‚Ä¢ Final test performance\")\n",
    "    print(\"   ‚Ä¢ Comprehensive metrics and visualizations\")\n",
    "    print()\n",
    "    print(\"üîó Access your results on the wandb dashboard:\")\n",
    "    print(\"   https://wandb.ai/\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Weights & Biases logging is DISABLED\")\n",
    "    print(\"üíæ Creating local backup files...\")\n",
    "    \n",
    "    # Create results directory in outputs/ (excluded from git)\n",
    "    results_dir = Path(\"outputs/notebook_results\")\n",
    "    results_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    \n",
    "    # 1. Save raw results as JSON\n",
    "    json_file = results_dir / f\"evaluation_results_{timestamp}.json\"\n",
    "    with open(json_file, 'w') as f:\n",
    "        # Remove non-serializable objects\n",
    "        import copy\n",
    "        results_copy = copy.deepcopy(evaluation_results)\n",
    "        \n",
    "        def remove_non_serializable(obj):\n",
    "            if isinstance(obj, dict):\n",
    "                return {k: remove_non_serializable(v) for k, v in obj.items() if k != 'probe'}\n",
    "            elif isinstance(obj, list):\n",
    "                return [remove_non_serializable(item) for item in obj]\n",
    "            else:\n",
    "                return obj\n",
    "        \n",
    "        clean_results = remove_non_serializable(results_copy)\n",
    "        json.dump(clean_results, f, indent=2, default=str)\n",
    "    \n",
    "    print(f\"‚úÖ Raw results saved to: {json_file}\")\n",
    "    \n",
    "    # 2. Save comprehensive metrics as CSV\n",
    "    csv_file = results_dir / f\"comprehensive_metrics_{timestamp}.csv\"\n",
    "    metrics_df = pd.DataFrame([comprehensive_metrics])\n",
    "    metrics_df.to_csv(csv_file, index=False)\n",
    "    \n",
    "    print(f\"‚úÖ Comprehensive metrics saved to: {csv_file}\")\n",
    "    \n",
    "    # 3. Generate HTML report\n",
    "    html_report = generate_summary_report(evaluation_results, config.to_dict())\n",
    "    html_file = results_dir / f\"evaluation_report_{timestamp}.html\"\n",
    "    with open(html_file, 'w') as f:\n",
    "        f.write(html_report)\n",
    "    \n",
    "    print(f\"‚úÖ HTML report saved to: {html_file}\")\n",
    "    \n",
    "    # 4. Save configuration\n",
    "    config_file = results_dir / f\"configuration_{timestamp}.json\"\n",
    "    with open(config_file, 'w') as f:\n",
    "        json.dump(config.to_dict(), f, indent=2)\n",
    "    \n",
    "    print(f\"‚úÖ Configuration saved to: {config_file}\")\n",
    "    \n",
    "    print(f\"\\nüìÅ All results saved in: {results_dir.absolute()}\")\n",
    "\n",
    "print(\"\\nüí° Recommendation:\")\n",
    "if config.enable_wandb:\n",
    "    print(\"   Use wandb dashboard for comprehensive result analysis and comparison.\")\n",
    "    print(\"   Results are automatically versioned and shareable via wandb.\")\n",
    "else:\n",
    "    print(\"   Enable wandb logging for better experiment tracking and result management.\")\n",
    "    print(\"   Set enable_wandb=True in the configuration for future runs.\")\n",
    "\n",
    "print(\"\\nüéâ Evaluation complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîç Optional: Detailed Data Exploration\n",
    "\n",
    "Use this section to explore specific aspects of your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive data exploration\n",
    "@interact\n",
    "def explore_results(\n",
    "    section=widgets.Dropdown(\n",
    "        options=['Configuration', 'Training Results', 'Optimization Results', 'Test Results'],\n",
    "        value='Configuration'\n",
    "    )\n",
    "):\n",
    "    if section == 'Configuration':\n",
    "        display(Markdown(\"### üìã Configuration Details\"))\n",
    "        # Fix UnboundLocalError by accessing config from global scope\n",
    "        if 'config' in globals():\n",
    "            config_df = pd.DataFrame(list(config.to_dict().items()), columns=['Parameter', 'Value'])\n",
    "            display(config_df)\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è Configuration not available. Please run the configuration cell first.\")\n",
    "        \n",
    "    elif section == 'Training Results':\n",
    "        display(Markdown(\"### üéØ Probe Training Results\"))\n",
    "        if \"probe_training_results\" in evaluation_results:\n",
    "            training_data = []\n",
    "            for layer_key, layer_results in evaluation_results[\"probe_training_results\"].items():\n",
    "                layer_num = int(layer_key.split('_')[1])\n",
    "                for c_key, metrics in layer_results.items():\n",
    "                    if isinstance(metrics, dict) and \"auc\" in metrics:\n",
    "                        training_data.append({\n",
    "                            'Layer': layer_num,\n",
    "                            'C': float(c_key.replace('C_', '')),\n",
    "                            'Accuracy': metrics.get('accuracy', 0),\n",
    "                            'AUC': metrics.get('auc', 0.5),\n",
    "                            'Precision': metrics.get('precision', 0),\n",
    "                            'Recall': metrics.get('recall', 0),\n",
    "                            'F1': metrics.get('f1', 0)\n",
    "                        })\n",
    "            if training_data:\n",
    "                training_df = pd.DataFrame(training_data)\n",
    "                display(training_df.round(3))\n",
    "        else:\n",
    "            print(\"No training results available.\")\n",
    "            \n",
    "    elif section == 'Optimization Results':\n",
    "        display(Markdown(\"### ‚öôÔ∏è Hyperparameter Optimization Results\"))\n",
    "        if \"steering_optimization_results\" in evaluation_results:\n",
    "            opt_results = evaluation_results[\"steering_optimization_results\"]\n",
    "            all_configs = opt_results.get(\"all_configs\", [])\n",
    "            \n",
    "            if all_configs:\n",
    "                opt_data = []\n",
    "                for i, config_item in enumerate(all_configs):\n",
    "                    steering_config = config_item.get(\"steering_config\", {})\n",
    "                    probe_config = config_item.get(\"best_probe_config\", {})\n",
    "                    \n",
    "                    opt_data.append({\n",
    "                        'Config': i + 1,\n",
    "                        'Steering Method': steering_config.get('method', 'N/A'),\n",
    "                        'Steering Layer': steering_config.get('layer', 'N/A'),\n",
    "                        'Steering Strength': steering_config.get('strength', 'N/A'),\n",
    "                        'Probe Layer': probe_config.get('layer', 'N/A'),\n",
    "                        'Probe C': probe_config.get('C', 'N/A'),\n",
    "                        'Benchmark Accuracy': config_item.get('benchmark_metrics', {}).get('accuracy', 0),\n",
    "                        'Probe AUC': config_item.get('probe_metrics', {}).get('auc', 0.5),\n",
    "                        'Combined Score': config_item.get('combined_score', 0)\n",
    "                    })\n",
    "                \n",
    "                opt_df = pd.DataFrame(opt_data)\n",
    "                display(opt_df.round(3))\n",
    "        else:\n",
    "            print(\"No optimization results available.\")\n",
    "            \n",
    "    elif section == 'Test Results':\n",
    "        display(Markdown(\"### üèÜ Final Test Results\"))\n",
    "        if \"test_results\" in evaluation_results:\n",
    "            test_results = evaluation_results[\"test_results\"]\n",
    "            \n",
    "            # Create summary table\n",
    "            summary_data = {\n",
    "                'Metric': [\n",
    "                    'Base Benchmark Accuracy',\n",
    "                    'Steered Benchmark Accuracy', \n",
    "                    'Base Probe AUC',\n",
    "                    'Steered Probe AUC',\n",
    "                    'Validation Combined Score'\n",
    "                ],\n",
    "                'Value': [\n",
    "                    test_results.get('base_model_benchmark_results', {}).get('accuracy', 0),\n",
    "                    test_results.get('steered_model_benchmark_results', {}).get('accuracy', 0),\n",
    "                    test_results.get('base_model_probe_results', {}).get('auc', 0.5),\n",
    "                    test_results.get('steered_model_probe_results', {}).get('auc', 0.5),\n",
    "                    test_results.get('validation_combined_score', 0)\n",
    "                ]\n",
    "            }\n",
    "            \n",
    "            summary_df = pd.DataFrame(summary_data)\n",
    "            display(summary_df.round(3))\n",
    "        else:\n",
    "            print(\"No test results available.\")\n",
    "\n",
    "print(\"üîç Use the dropdown above to explore different sections of your results.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéâ Conclusion\n",
    "\n",
    "Congratulations! You've successfully run a comprehensive evaluation that separates:\n",
    "\n",
    "1. **üéØ Benchmark Performance**: How well your model solves problems\n",
    "2. **üîç Probe Performance**: How well we can detect when the model is wrong\n",
    "3. **‚öôÔ∏è Optimization**: Finding the best configurations through proper validation\n",
    "\n",
    "### Next Steps:\n",
    "- üìä Analyze the results above to understand your model's behavior\n",
    "- üîß Try different configurations to see how they affect performance\n",
    "- üìà Use the exported results for further analysis or reporting\n",
    "- üöÄ Scale up to larger models and datasets when ready\n",
    "\n",
    "### Key Insights:\n",
    "- The framework properly separates model capability from interpretability\n",
    "- Hyperparameter optimization validates on actual performance, not just probe metrics\n",
    "- Results are saved and visualized for easy interpretation\n",
    "\n",
    "Happy experimenting! üß™‚ú®"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
