[
  "20_newsgroups",
  "aclue",
  "advanced",
  "aexams",
  "afrimgsm",
  "afrimmlu",
  "afrixnli",
  "ag",
  "ag_news",
  "agieval",
  "alghafa_copa_ar",
  "alghafa_piqa_ar",
  "ai2_arc",
  "aime",
  "aime2024",
  "aime2025",
  "anagrams1",
  "anagrams2",
  "apps",
  "arabculture",
  "arabic",
  "arabic_leaderboard_complete",
  "arabic_leaderboard_light",
  "arabicmmlu",
  "argument",
  "argument_topic",
  "asdiv",
  "asdiv_cot_llama",
  "ask_gec",
  "ask_gec_p0",
  "ask_gec_p1",
  "ask_gec_p2",
  "ask_gec_p3",
  "ask_gec_p4",
  "assin",
  "assin_entailment",
  "atis",
  "babi",
  "babilong",
  "bangla_mmlu",
  "banking77",
  "basque_bench",
  "basque_glue",
  "basqueglue",
  "bbq",
  "bec2016eu",
  "belebele",
  "benchmarks",
  "bertaqa",
  "bhs",
  "bhtc",
  "bigbench",
  "blimp",
  "blimp_nl",
  "boolq",
  "boolq_seq2seq",
  "c4",
  "cabbq",
  "cabreu",
  "careqa",
  "catalan_bench",
  "catalanqa",
  "catcola",
  "cb",
  "ceval",
  "chain",
  "chartqa",
  "claim",
  "click",
  "cmmlu",
  "cnn",
  "cocoteros",
  "code2text",
  "code_x_glue",
  "codexglue",
  "codexglue_code2text",
  "coedit",
  "cola",
  "commonsense",
  "commonsense_qa",
  "conala",
  "concode",
  "copa",
  "copal_id",
  "coqa",
  "coqcat",
  "csatqa",
  "cycle",
  "cycle_letters",
  "darijahellaswag",
  "darijammlu",
  "dbpedia",
  "discrim_eval",
  "doc",
  "doc_vqa",
  "drop",
  "ds1000",
  "egyhellaswag",
  "egymmlu",
  "epec",
  "eq",
  "eq_bench",
  "eq_bench_ca",
  "eq_bench_es",
  "esbbq",
  "escola",
  "ethics",
  "ethos",
  "evalita_llm",
  "evalita_sp",
  "fda",
  "financial",
  "financial_tweets",
  "flan",
  "fld",
  "flores",
  "freebase",
  "french_bench",
  "galcola",
  "galician_bench",
  "glianorex",
  "glue",
  "global_mmlu",
  "gpt3",
  "gpqa",
  "groundcocoa",
  "gsm",
  "gsm8k",
  "gsm8k_platinum",
  "gsm_plus",
  "haerae",
  "headqa",
  "hellaswag",
  "hendrycks_ethics",
  "hendrycks_math",
  "histoires_morales",
  "hle",
  "hmmt",
  "hmmt_feb_2025",
  "hrm8k",
  "humaneval",
  "humaneval_infilling",
  "humanevalpack",
  "icelandic_winogrande",
  "ifeval",
  "include",
  "include",
  "iwslt2017",
  "iwslt2017_ar_en",
  "iwslt2017_en_ar",
  "ja",
  "japanese_leaderboard",
  "jsonschema_bench",
  "jsonschema_bench_easy",
  "jsonschema_bench_medium",
  "jsonschema_bench_hard",
  "kmmlu",
  "kmmlu_hard",
  "kobest",
  "law",
  "leaderboard",
  "ledgar",
  "libra",
  "librusec_history",
  "librusec_mhqa",
  "lingoly",
  "livecodebench",
  "livemathbench_cnmo_en",
  "livemathbench_cnmo_zh",
  "llama",
  "llama3",
  "lm_syneval",
  "logieval",
  "logiqa",
  "logiqa2",
  "long_context_multiq",
  "longbench",
  "longbenchv2",
  "math",
  "math500",
  "mathqa",
  "matreshka_names",
  "matreshka_yes_no",
  "mbpp",
  "mc_taco",
  "medical",
  "mediqa_qa2019",
  "medmcqa",
  "medqa",
  "medtext",
  "mela",
  "meqsum",
  "mercury",
  "metabench",
  "mimic_repsum",
  "nq_open",
  "mediqa_qa2019",
  "medtext",
  "mts_dialog",
  "olaph",
  "siqa",
  "squad_completion",
  "swde",
  "wmt2016",
  "mimic_repsum",
  "minerva_math",
  "mmmlu",
  "mmlusr",
  "mnli",
  "model_written_evals",
  "moral_stories",
  "mrpc",
  "mts_dialog",
  "multiblimp",
  "multilingual",
  "multimedqa",
  "multiple",
  "multiple_choice",
  "multirc",
  "mutual",
  "ncb",
  "noreval",
  "norrewrite_instruct",
  "norsummarize_instruct",
  "norquad",
  "noticia",
  "nq_open",
  "okapi_arc_multilingual",
  "okapi_hellaswag_multilingual",
  "okapi_mmlu_multilingual",
  "okapi_truthfulqa_multilingual",
  "olaph",
  "olaph_perplexity",
  "openbookqa",
  "openllm",
  "option",
  "option_order_robustness_agieval_aqua_rat",
  "option_order_robustness_agieval_logiqa_en",
  "option_order_robustness_agieval_lsat_ar",
  "option_order_robustness_agieval_lsat_lr",
  "option_order_robustness_agieval_lsat_rc",
  "option_order_robustness_agieval_sat_en",
  "option_order_robustness_agieval_sat_math",
  "paloma",
  "parafraseja",
  "parafrases",
  "passkey",
  "passkey_with_librusec",
  "paws",
  "paws_de",
  "paws_en",
  "paws_es",
  "paws_fr",
  "paws_ja",
  "paws_ko",
  "paws_x",
  "paws_zh",
  "penn_treebank",
  "phrases",
  "piqa",
  "polymath_en_high",
  "polymath_en_medium",
  "polymath_zh_high",
  "polymath_zh_medium",
  "portuguese_bench",
  "prost",
  "ptb",
  "pubmedqa",
  "pythia",
  "qa4mre",
  "qasper",
  "qnli",
  "qnlieu",
  "qqp",
  "quac",
  "race",
  "random",
  "realtoxicityprompts",
  "record",
  "reversed",
  "rte",
  "ruler",
  "score",
  "score_non_greedy_robustness_mmlu_pro",
  "score_option_order_robustness_mmlu_pro",
  "score_prompt_robustness_mmlu_pro",
  "sciq",
  "self",
  "sglue",
  "simple_cooccurrence_bias",
  "siqa",
  "siqa_ca",
  "social_iqa",
  "spanish_bench",
  "squad2",
  "squad_completion",
  "squadv2",
  "sst2",
  "storycloze",
  "stsb",
  "summarization",
  "super",
  "super_glue",
  "super_glue_lm_eval_v1",
  "super_glue_lm_eval_v1_seq2seq",
  "super_glue_t5_prompt",
  "superglue",
  "supergpqa",
  "swag",
  "swde",
  "sycophancy",
  "sycophancy_on_nlp_survey",
  "sycophancy_on_philpapers2020",
  "sycophancy_on_political_typology_quiz",
  "t0",
  "tag",
  "teca",
  "tinybenchmarks",
  "tinyarc",
  "tinygsm8k",
  "tinyhellaswag",
  "tinymmlu",
  "tinytruthfulqa",
  "tinywinogrande",
  "tmlu",
  "tmmluplus",
  "toxigen",
  "translation",
  "gpt3_translation_benchmarks",
  "triviaqa",
  "turblimp_core",
  "unfair",
  "unitxt",
  "unscramble",
  "vaxx",
  "webqs",
  "wic",
  "wiceu",
  "wikitext",
  "wikitext103",
  "winogender",
  "winogrande",
  "wmdp",
  "wmt14",
  "wmt14_en_fr",
  "wmt14_fr_en",
  "wmt16",
  "wmt16_de_en",
  "wmt16_en_de",
  "wmt16_en_ro",
  "wmt16_ro_en",
  "wmt2016",
  "wnli",
  "wsc",
  "wsc273",
  "xcopa",
  "xlsum",
  "xnli",
  "xquad",
  "xstorycloze",
  "xsum",
  "xwinograd",
  "yahoo",
  "zhoblimp",
  "mmlu_llama",
  "mmlu_pro_llama",
  "mmlu_cot_llama",
  "mmlu_it_llama",
  "mmlu_fr_llama",
  "mmlu_pt_llama",
  "mmlu_th_llama",
  "mmlu_hi_llama",
  "mmlu_es_llama",
  "mmlu_de_llama",
  "arc_challenge_llama",
  "gsm8k_llama",
  "logiqa",
  "logiqa2_zh",
  "logiqa2_NLI",
  "logieval",
  "mathqa",
  "mbpp",
  "mc_taco",
  "mediqa_qa2019",
  "mediqa_qa2019_perplexity",
  "medmcqa",
  "medqa_4options",
  "medtext",
  "medtext_perplexity",
  "meqsum",
  "mimic_repsum",
  "mimic_repsum_perplexity",
  "moral_stories",
  "mts_dialog",
  "mts_dialog_perplexity",
  "mutual",
  "mutual_plus",
  "ask_gec",
  "noticia",
  "nq_open"
]
