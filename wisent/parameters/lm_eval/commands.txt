lm_eval --tasks list | grep <benchmark name>

python -m wisent.tests.test_table.inspect_benchmark <benchmark name>

python -m wisent.examples.scripts.test_one_benchmark <benchmark name>

python -m wisent.tests.test_table.inspect_hf_dataset codeparrot/apps

lm_eval --model hf --model_args pretrained=EleutherAI/gpt-neo-125M --tasks <benchmark name> --device cuda:0 --batch_size 4 --limit 20

python -m wisent.core.main generate-vector-from-task \
--task 20_newsgroups \
--trait-label correctness \
--output ./data/steering_vectors/hellaswag_correctness_vector.json \
--model meta-llama/Llama-3.2-1B-Instruct \
--num-pairs 50 \
--layers 8 \
--keep-intermediate \
--token-aggregation average \
--prompt-strategy chat_template \
--method caa \
--normalize \
--verbose \
--timing \
--device cuda

lm_eval --model hf --model_args pretrained=EleutherAI/gpt-neo-125M --tasks boolq --device cuda:0 --batch_size 2 --limit 2

lm_eval --model steered \
    --model_args pretrained=EleutherAI/gpt-neo-125M,steer_path=steer_config.pt \
    --tasks boolq \
    --device cuda:0 \
    --batch_size 2 \
    --limit 2


python -m wisent.comparison.main \
    --model meta-llama/Llama-3.2-1B \
    --tasks boolq,cb \
    --methods caa \
    --scales 0.5,1.0,1.5 \
    --layers 8 \
    --device cuda:0 \
    --batch-size 1 \
    --max-batch-size 8 \
    --output-dir wisent/comparison/comparison_results \
    --train-ratio 0.4 \
    --limit 10 \
    --num-pairs 10 \
    --extraction-strategy mc_completion,completion_mean



python -m wisent.comparison.main \
      --model EleutherAI/gpt-neo-125M \
      --tasks boolq \
      --methods caa \
      --scales 0.5 \
      --layers 6 \
      --device cuda:0 \
      --batch-size 1 \
      --max-batch-size 1 \
      --output-dir wisent/comparison/comparison_results \
      --train-ratio 0.4 \
      --limit 10 \
      --num-pairs 10


./run_on_aws.sh --model google/gemma-2-2b --instance-type g6e.xlarge "python -m wisent.comparison.main --model google/gemma-2-2b --tasks boolq,cb --methods fgaa      
--scales 0.5,1.0,1.5,3.0 --layers 12 --device cuda:0 --batch-size 1 --max-batch-size 1 --output-dir /home/ubuntu/output --train-ratio 0.4 --limit 10 --num-pairs 10"  
/home/bc/Desktop/python/wisent/wisent/comparison/comparison_results       

aws ec2 describe-instances --filters "Name=tag:Name,Values=wisent-run-script" "Name=instance-state-name,Values=running" --query 'Reservations[*].Instances[*].[InstanceId,LaunchTime]' --output table