lm_eval --tasks list | grep <benchmark name>

python -m wisent.tests.test_table.inspect_benchmark <benchmark name>

python -m wisent.examples.scripts.test_one_benchmark <benchmark name>

python -m wisent.tests.test_table.inspect_hf_dataset codeparrot/apps

lm_eval --model hf --model_args pretrained=EleutherAI/gpt-neo-125M --tasks <benchmark name> --device cuda:0 --batch_size 4 --limit 20

python -m wisent.core.main generate-vector-from-task \
--task 20_newsgroups \
--trait-label correctness \
--output ./data/steering_vectors/hellaswag_correctness_vector.json \
--model meta-llama/Llama-3.2-1B-Instruct \
--num-pairs 50 \
--layers 8 \
--keep-intermediate \
--token-aggregation average \
--prompt-strategy chat_template \
--method caa \
--normalize \
--verbose \
--timing \
--device cuda

lm_eval --model hf --model_args pretrained=EleutherAI/gpt-neo-125M --tasks boolq --device cuda:0 --batch_size 2 --limit 2

lm_eval --model steered \
    --model_args pretrained=EleutherAI/gpt-neo-125M,steer_path=steer_config.pt \
    --tasks boolq \
    --device cuda:0 \
    --batch_size 2 \
    --limit 2


python -m wisent.comparison.main \
    --model EleutherAI/pythia-410m \
    --tasks boolq, cb \
    --methods caa \
    --num-pairs 200 \
    --scales 0.5,1.0,1.5, 3.0 \
    --layers 12 \
    --device cuda:0 \
    --batch-size 1 \
    --max-batch-size 8 \
    --limit 500 \
    --output-dir wisent/comparison/comparison_results \
    --train-ratio 0.4 \
    --token-aggregation average \
    --promp-strategy direct-completion



python -m wisent.comparison.main \
      --model google/gemma-2-2b \
      --tasks boolq,cb \
      --methods fgaa \
      --scales 0.5,1.0,1.5,3.0 \
      --layers 12 \
      --device cuda:0 \
      --batch-size 1 \
      --max-batch-size 1 \
      --output-dir wisent/comparison/comparison_results \
      --train-ratio 0.4 \
      --token-aggregation average \
      --prompt-strategy direct_completion \
      --dtype bfloat16 \
      --limit 10 \
      --num-pairs 10 \
      --load-in-8bits


  ./run_on_aws.sh --model google/gemma-2-2b --instance-type g6e.xlarge \                                                                                                
      "python -m wisent.comparison.main \                                                                                                                               
          --model google/gemma-2-2b \                                                                                                                                   
          --tasks boolq,cb \                                                                                                                                            
          --methods fgaa \                                                                                                                                              
          --scales 0.5,1.0,1.5,3.0 \                                                                                                                                    
          --layers 12 \                                                                                                                                                 
          --device cuda:0 \                                                                                                                                             
          --batch-size 1 \                                                                                                                                              
          --max-batch-size 1 \                                                                                                                                          
          --output-dir /home/ubuntu/output \                                                                                                                            
          --train-ratio 0.4 \                                                                                                                                                                                                                                                                                      
          --limit 10 \                                                                                                                                                  
          --num-pairs 10" \                                                                                                                                             
      /home/bc/Desktop/python/wisent/wisent/comparison/comparison_results


./run_on_aws.sh --model google/gemma-2-2b --instance-type g6e.xlarge "python -m wisent.comparison.main --model google/gemma-2-2b --tasks boolq,cb --methods fgaa      
--scales 0.5,1.0,1.5,3.0 --layers 12 --device cuda:0 --batch-size 1 --max-batch-size 1 --output-dir /home/ubuntu/output --train-ratio 0.4 --limit 10 --num-pairs 10"  
/home/bc/Desktop/python/wisent/wisent/comparison/comparison_results       

aws ec2 describe-instances --filters "Name=tag:Name,Values=wisent-run-script" "Name=instance-state-name,Values=running" --query 'Reservations[*].Instances[*].[InstanceId,LaunchTime]' --output table