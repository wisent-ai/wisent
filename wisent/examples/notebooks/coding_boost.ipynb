{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coding Boost: How to use Wisent to Make Your Models Better At Coding\n",
    "\n",
    "Here, we use LiveCodeBench to compute steering vectors and change activations of a simple model to steer it in a direction of generating better code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration:\n",
      "  Model: meta-llama/Llama-3.2-1B-Instruct\n",
      "  Task: livecodebench\n",
      "  Steering Layer: 8\n",
      "  Trait Label: coding_ability\n",
      "  Num Pairs: 50\n",
      "  Steering Strength: 1.5\n",
      "  Output: ./coding_boost_outputs\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "# =============================================================================\n",
    "# CONFIGURATION - Modify these parameters as needed\n",
    "# =============================================================================\n",
    "\n",
    "# Model Configuration\n",
    "MODEL = \"meta-llama/Llama-3.2-1B-Instruct\"  # HuggingFace model ID\n",
    "\n",
    "# Task Configuration\n",
    "TASK = \"livecodebench\"             # Coding benchmark for contrastive pairs\n",
    "\n",
    "# Steering Configuration\n",
    "LAYER = 8                          # Primary layer for steering (middle layers work best)\n",
    "LAYERS_MULTI = \"6,8,10\"            # Multiple layers for multi-layer steering\n",
    "TRAIT_LABEL = \"coding_ability\"     # Label for the steering vector\n",
    "TOKEN_AGGREGATION = \"average\"      # How to aggregate token activations\n",
    "NUM_PAIRS = 50                     # Number of contrastive pairs to use\n",
    "NORMALIZE = True                   # Normalize steering vectors\n",
    "\n",
    "# Steering Strength\n",
    "STEERING_STRENGTH = 1.5            # Default steering strength (0.5-2.0 typical)\n",
    "STRENGTHS_TO_TEST = [0.5, 1.0, 1.5, 2.0]  # Strengths for comparison\n",
    "\n",
    "# Generation Configuration\n",
    "MAX_NEW_TOKENS = 512               # Max tokens for code generation\n",
    "TEMPERATURE = 0.2                  # Lower = more deterministic\n",
    "NUM_TEST_QUESTIONS = 10            # Number of problems to evaluate\n",
    "\n",
    "# Output Configuration\n",
    "OUTPUT_DIR = \"./coding_boost_outputs\"\n",
    "\n",
    "# =============================================================================\n",
    "# Setup - Create output directories\n",
    "# =============================================================================\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "os.makedirs(f\"{OUTPUT_DIR}/pairs\", exist_ok=True)\n",
    "os.makedirs(f\"{OUTPUT_DIR}/vectors\", exist_ok=True)\n",
    "os.makedirs(f\"{OUTPUT_DIR}/responses\", exist_ok=True)\n",
    "\n",
    "print(\"Configuration:\")\n",
    "print(f\"  Model: {MODEL}\")\n",
    "print(f\"  Task: {TASK}\")\n",
    "print(f\"  Steering Layer: {LAYER}\")\n",
    "print(f\"  Trait Label: {TRAIT_LABEL}\")\n",
    "print(f\"  Num Pairs: {NUM_PAIRS}\")\n",
    "print(f\"  Steering Strength: {STEERING_STRENGTH}\")\n",
    "print(f\"  Output: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LiveCodeBench provides pre-computed code solutions with pass/fail labels. We extract:\n",
    "- **Positive (correct)**: Code solutions that pass all test cases\n",
    "- **Negative (incorrect)**: Code solutions that fail test cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m  .................  .:--++*##%%%%##**+=-:.  .................  \n",
      "  ..             .:=*%@@@@@@@%%%%%%%@@@@@@%*=:.             ..  \n",
      "  .           .-*%@@@%#+=-::.........:-=+#%@@@%*=.           .  \n",
      "  .         -*%@@@#=:.                    .:=*%@@@*-.        .  \n",
      "  .      .-#@@@*=.                            .-*@@@#-.      .  \n",
      "  .     :#@@@*:                                  :+%@@#-     .  \n",
      "  .   .+@@@*:                                      :+@@@+.   .  \n",
      "  .  .*@@@@%*=:.                                     -%@@#:  .  \n",
      "  . .#@@#=*%@@@%*-:.                                  .#@@%: .  \n",
      "  ..*@@%.  .-+#@@@@#+-:.                               .*@@%..  \n",
      "  .=@@@-       :-+#@@@@%*=:.                            .%@@*.  \n",
      "  :#@@+           .:-+#@@@@%#+=:.                        -@@@-  \n",
      "  =@@@:                .-=*%@@@@%#+=:..                  .#@@+  \n",
      "  +@@@*=:.                 .:-+*%@@@@%#*=-:..             *@@+  \n",
      "  +@@@@@@#+-..                  .:-=*#@@@@@%#*+--..       +@@+  \n",
      "  +@@#-+%@@@%:                        .:-=*#%@@@@@%#*+=-:.*@@+  \n",
      "  =@@%. .=@@@:                             ..:-=+#%%@@@@@%@@@+  \n",
      "  :%@@=  :@@@-                                    ..::-=+#@@@=  \n",
      "  .+@@%. .#@@*                                           +@@#:  \n",
      "  ..%@@*. =@@@:                                         =@@@-.  \n",
      "  . :%@@*..#@@#.                         .:..          =@@@= .  \n",
      "  .  :%@@*.:%@@*.                       :#@@%#*+=-::..+@@@=  .  \n",
      "  .   :#@@%-:%@@#:                    .+@@@#%%@@@@@@%%@@%-   .  \n",
      "  .    .+@@@*=#@@%-                 .=%@@%=...::-=#@@@@*.    .  \n",
      "  .      :*@@@#%@@@*:             .=%@@@+.     .:*%@@#-      .  \n",
      "  .        :+%@@@@@@@*-.       :=*@@@%+.    .-+%@@@*-.       .  \n",
      "  .          .=*%@@@@@@#+:.:-+#@@@%*-. .:-+#%@@@#+:          .  \n",
      "  .             .-+#%@@@@@@@@@@@@#*+**#@@@@@%*=:.            .  \n",
      "  ..............   ..-=+*#%%%@@@@@@@@%%#*=-:.   ..............  \n",
      "   ...................  ....:::::::::.... ...................   \u001b[0m\n",
      "\u001b[1m\u001b[32mWisent CLI\u001b[0m ‚Äì Steering vectors & activation tooling\n",
      "\n",
      "\n",
      "üìä Generating contrastive pairs from task: livecodebench\n",
      "   Limit: 100 pairs\n",
      "\n",
      "üîÑ Loading task 'livecodebench'...\n",
      "   ‚ÑπÔ∏è  Task not found in lm-eval, trying custom tasks...\n",
      "   üî® Building contrastive pairs...\n",
      "Using the latest cached version of the dataset since livecodebench/code_generation_lite couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'release_latest' at /Users/lukaszbartoszcze/.cache/huggingface/datasets/livecodebench___code_generation_lite/release_latest/0.0.0/4c038560f391c4c05fdf7fd7ae61ae0e6dbd8672f8fe5b95597b78a8dc40a417 (last modified on Sun Oct 26 12:04:14 2025).\n",
      "Using the latest cached version of the dataset since livecodebench/code_generation_lite couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'release_latest' at /Users/lukaszbartoszcze/.cache/huggingface/datasets/livecodebench___code_generation_lite/release_latest/0.0.0/4c038560f391c4c05fdf7fd7ae61ae0e6dbd8672f8fe5b95597b78a8dc40a417 (last modified on Sun Oct 26 12:04:14 2025).\n",
      "Using the latest cached version of the dataset since livecodebench/code_generation_lite couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'release_latest' at /Users/lukaszbartoszcze/.cache/huggingface/datasets/livecodebench___code_generation_lite/release_latest/0.0.0/4c038560f391c4c05fdf7fd7ae61ae0e6dbd8672f8fe5b95597b78a8dc40a417 (last modified on Sun Oct 26 12:04:14 2025).\n",
      "Using the latest cached version of the dataset since livecodebench/code_generation_lite couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'release_latest' at /Users/lukaszbartoszcze/.cache/huggingface/datasets/livecodebench___code_generation_lite/release_latest/0.0.0/4c038560f391c4c05fdf7fd7ae61ae0e6dbd8672f8fe5b95597b78a8dc40a417 (last modified on Sun Oct 26 12:04:14 2025).\n",
      "Using the latest cached version of the dataset since livecodebench/code_generation_lite couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'release_latest' at /Users/lukaszbartoszcze/.cache/huggingface/datasets/livecodebench___code_generation_lite/release_latest/0.0.0/4c038560f391c4c05fdf7fd7ae61ae0e6dbd8672f8fe5b95597b78a8dc40a417 (last modified on Sun Oct 26 12:04:14 2025).\n",
      "Using the latest cached version of the dataset since livecodebench/code_generation_lite couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'release_latest' at /Users/lukaszbartoszcze/.cache/huggingface/datasets/livecodebench___code_generation_lite/release_latest/0.0.0/4c038560f391c4c05fdf7fd7ae61ae0e6dbd8672f8fe5b95597b78a8dc40a417 (last modified on Sun Oct 26 12:04:14 2025).\n",
      "Using the latest cached version of the dataset since livecodebench/code_generation_lite couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'release_latest' at /Users/lukaszbartoszcze/.cache/huggingface/datasets/livecodebench___code_generation_lite/release_latest/0.0.0/4c038560f391c4c05fdf7fd7ae61ae0e6dbd8672f8fe5b95597b78a8dc40a417 (last modified on Sun Oct 26 12:04:14 2025).\n",
      "Using the latest cached version of the dataset since livecodebench/code_generation_lite couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'release_latest' at /Users/lukaszbartoszcze/.cache/huggingface/datasets/livecodebench___code_generation_lite/release_latest/0.0.0/4c038560f391c4c05fdf7fd7ae61ae0e6dbd8672f8fe5b95597b78a8dc40a417 (last modified on Sun Oct 26 12:04:14 2025).\n",
      "Using the latest cached version of the dataset since livecodebench/code_generation_lite couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'release_latest' at /Users/lukaszbartoszcze/.cache/huggingface/datasets/livecodebench___code_generation_lite/release_latest/0.0.0/4c038560f391c4c05fdf7fd7ae61ae0e6dbd8672f8fe5b95597b78a8dc40a417 (last modified on Sun Oct 26 12:04:14 2025).\n",
      "Using the latest cached version of the dataset since livecodebench/code_generation_lite couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'release_latest' at /Users/lukaszbartoszcze/.cache/huggingface/datasets/livecodebench___code_generation_lite/release_latest/0.0.0/4c038560f391c4c05fdf7fd7ae61ae0e6dbd8672f8fe5b95597b78a8dc40a417 (last modified on Sun Oct 26 12:04:14 2025).\n",
      "No negative examples found for problem 9\n",
      "No negative example found for problem 9\n",
      "Using the latest cached version of the dataset since livecodebench/code_generation_lite couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'release_latest' at /Users/lukaszbartoszcze/.cache/huggingface/datasets/livecodebench___code_generation_lite/release_latest/0.0.0/4c038560f391c4c05fdf7fd7ae61ae0e6dbd8672f8fe5b95597b78a8dc40a417 (last modified on Sun Oct 26 12:04:14 2025).\n",
      "Using the latest cached version of the dataset since livecodebench/code_generation_lite couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'release_latest' at /Users/lukaszbartoszcze/.cache/huggingface/datasets/livecodebench___code_generation_lite/release_latest/0.0.0/4c038560f391c4c05fdf7fd7ae61ae0e6dbd8672f8fe5b95597b78a8dc40a417 (last modified on Sun Oct 26 12:04:14 2025).\n",
      "Using the latest cached version of the dataset since livecodebench/code_generation_lite couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'release_latest' at /Users/lukaszbartoszcze/.cache/huggingface/datasets/livecodebench___code_generation_lite/release_latest/0.0.0/4c038560f391c4c05fdf7fd7ae61ae0e6dbd8672f8fe5b95597b78a8dc40a417 (last modified on Sun Oct 26 12:04:14 2025).\n",
      "Using the latest cached version of the dataset since livecodebench/code_generation_lite couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'release_latest' at /Users/lukaszbartoszcze/.cache/huggingface/datasets/livecodebench___code_generation_lite/release_latest/0.0.0/4c038560f391c4c05fdf7fd7ae61ae0e6dbd8672f8fe5b95597b78a8dc40a417 (last modified on Sun Oct 26 12:04:14 2025).\n",
      "Using the latest cached version of the dataset since livecodebench/code_generation_lite couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'release_latest' at /Users/lukaszbartoszcze/.cache/huggingface/datasets/livecodebench___code_generation_lite/release_latest/0.0.0/4c038560f391c4c05fdf7fd7ae61ae0e6dbd8672f8fe5b95597b78a8dc40a417 (last modified on Sun Oct 26 12:04:14 2025).\n"
     ]
    }
   ],
   "source": [
    "# Extract contrastive pairs from LiveCodeBench\n",
    "!python -m wisent.core.main generate-pairs-from-task \\\n",
    "    livecodebench \\\n",
    "    --output {OUTPUT_DIR}/pairs/livecodebench_pairs.json \\\n",
    "    --limit 100 \\\n",
    "    --verbose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine the extracted pairs\n",
    "with open(f\"{OUTPUT_DIR}/pairs/livecodebench_pairs.json\", 'r') as f:\n",
    "    pairs_data = json.load(f)\n",
    "\n",
    "print(f\"Extracted {pairs_data['num_pairs']} contrastive pairs from {pairs_data['task_name']}\")\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "\n",
    "# Show a few examples\n",
    "for i, pair in enumerate(pairs_data['pairs'][:2]):\n",
    "    print(f\"\\nExample {i+1}:\")\n",
    "    print(f\"Problem (truncated): {pair['prompt'][:200]}...\")\n",
    "    print(f\"\\nCorrect Code (truncated):\")\n",
    "    print(pair['positive_response']['model_response'][:300])\n",
    "    print(f\"\\nIncorrect Code (truncated):\")\n",
    "    print(pair['negative_response']['model_response'][:300])\n",
    "    print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `generate-vector-from-task` command runs the complete pipeline:\n",
    "1. Extract contrastive pairs\n",
    "2. Collect activations from the model\n",
    "3. Create steering vectors using CAA (Contrastive Activation Addition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate steering vector using configuration parameters\n",
    "!python -m wisent.core.main generate-vector-from-task \\\n",
    "    --task {TASK} \\\n",
    "    --trait-label {TRAIT_LABEL} \\\n",
    "    --model {MODEL} \\\n",
    "    --num-pairs {NUM_PAIRS} \\\n",
    "    --layers {LAYER} \\\n",
    "    --token-aggregation {TOKEN_AGGREGATION} \\\n",
    "    --output {OUTPUT_DIR}/vectors/coding_vector.pt \\\n",
    "    --keep-intermediate \\\n",
    "    --intermediate-dir {OUTPUT_DIR}/vectors \\\n",
    "    --normalize \\\n",
    "    --verbose \\\n",
    "    --timing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine the generated steering vector\n",
    "import torch\n",
    "\n",
    "vector_data = torch.load(f\"{OUTPUT_DIR}/vectors/coding_vector.pt\")\n",
    "\n",
    "print(\"Steering Vector Info:\")\n",
    "print(f\"  Model: {vector_data.get('model', 'N/A')}\")\n",
    "print(f\"  Trait: {vector_data.get('trait_label', 'N/A')}\")\n",
    "print(f\"  Method: {vector_data.get('method', 'N/A')}\")\n",
    "print(f\"  Layer: {vector_data.get('layer', 'N/A')}\")\n",
    "\n",
    "if 'steering_vector' in vector_data:\n",
    "    sv = vector_data['steering_vector']\n",
    "    print(f\"  Vector shape: {sv.shape}\")\n",
    "    print(f\"  Vector norm: {torch.norm(sv).item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For optimal steering, we can create vectors for multiple layers and combine them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate steering vectors for multiple layers using LAYERS_MULTI config\n",
    "!python -m wisent.core.main generate-vector-from-task \\\n",
    "    --task {TASK} \\\n",
    "    --trait-label {TRAIT_LABEL} \\\n",
    "    --model {MODEL} \\\n",
    "    --num-pairs {NUM_PAIRS} \\\n",
    "    --layers {LAYERS_MULTI} \\\n",
    "    --token-aggregation {TOKEN_AGGREGATION} \\\n",
    "    --output {OUTPUT_DIR}/vectors/coding_multi_layer.pt \\\n",
    "    --normalize \\\n",
    "    --verbose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the `multi-steer` command to apply the coding steering vector during generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a test prompt dynamically from LiveCodeBench\n",
    "from wisent.core.tasks import LiveCodeBenchTask\n",
    "\n",
    "# Load LiveCodeBench data\n",
    "lcb_task = LiveCodeBenchTask()\n",
    "lcb_data = lcb_task.load_data(limit=10)\n",
    "\n",
    "# Get the first problem as our test prompt\n",
    "test_problem = lcb_data[0]\n",
    "TEST_PROMPT = f\"Question: {test_problem['question_content']}\\n\\nWrite a solution:\"\n",
    "\n",
    "print(f\"Loaded problem: {test_problem.get('question_title', 'Unknown')}\")\n",
    "print(f\"Prompt preview: {TEST_PROMPT[:300]}...\")\n",
    "\n",
    "# Apply steering using configuration parameters\n",
    "!python -m wisent.core.main multi-steer \\\n",
    "    --vector {OUTPUT_DIR}/vectors/coding_vector.pt:{STEERING_STRENGTH} \\\n",
    "    --model {MODEL} \\\n",
    "    --layer {LAYER} \\\n",
    "    --prompt \"{TEST_PROMPT}\" \\\n",
    "    --max-new-tokens {MAX_NEW_TOKENS} \\\n",
    "    --verbose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate solutions for LiveCodeBench problems to evaluate steering effectiveness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate baseline responses (without steering) using configuration\n",
    "!python -m wisent.core.main generate-responses \\\n",
    "    {MODEL} \\\n",
    "    --task {TASK} \\\n",
    "    --output {OUTPUT_DIR}/responses/baseline_responses.json \\\n",
    "    --num-questions {NUM_TEST_QUESTIONS} \\\n",
    "    --max-new-tokens {MAX_NEW_TOKENS} \\\n",
    "    --temperature {TEMPERATURE} \\\n",
    "    --verbose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate steered responses using configuration\n",
    "!python -m wisent.core.main generate-responses \\\n",
    "    {MODEL} \\\n",
    "    --task {TASK} \\\n",
    "    --output {OUTPUT_DIR}/responses/steered_responses.json \\\n",
    "    --num-questions {NUM_TEST_QUESTIONS} \\\n",
    "    --max-new-tokens {MAX_NEW_TOKENS} \\\n",
    "    --temperature {TEMPERATURE} \\\n",
    "    --use-steering \\\n",
    "    --verbose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare baseline vs steered responses\n",
    "with open(f\"{OUTPUT_DIR}/responses/baseline_responses.json\", 'r') as f:\n",
    "    baseline = json.load(f)\n",
    "\n",
    "with open(f\"{OUTPUT_DIR}/responses/steered_responses.json\", 'r') as f:\n",
    "    steered = json.load(f)\n",
    "\n",
    "print(\"Response Comparison:\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for i in range(min(3, len(baseline['responses']))):\n",
    "    base_resp = baseline['responses'][i]\n",
    "    steer_resp = steered['responses'][i]\n",
    "    \n",
    "    print(f\"\\nProblem {i+1}:\")\n",
    "    print(f\"Prompt: {base_resp['prompt'][:100]}...\")\n",
    "    print(f\"\\n--- Baseline Response ---\")\n",
    "    print(base_resp.get('generated_response', 'N/A')[:400])\n",
    "    print(f\"\\n--- Steered Response ---\")\n",
    "    print(steer_resp.get('generated_response', 'N/A')[:400])\n",
    "    print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `evaluate-responses` command can execute generated code in Docker to verify correctness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate baseline responses\n",
    "!python -m wisent.core.main evaluate-responses \\\n",
    "    --input {OUTPUT_DIR}/responses/baseline_responses.json \\\n",
    "    --output {OUTPUT_DIR}/responses/baseline_evaluation.json \\\n",
    "    --task livecodebench \\\n",
    "    --verbose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate steered responses\n",
    "!python -m wisent.core.main evaluate-responses \\\n",
    "    --input {OUTPUT_DIR}/responses/steered_responses.json \\\n",
    "    --output {OUTPUT_DIR}/responses/steered_evaluation.json \\\n",
    "    --task livecodebench \\\n",
    "    --verbose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare evaluation results\n",
    "def load_eval_results(path):\n",
    "    try:\n",
    "        with open(path, 'r') as f:\n",
    "            return json.load(f)\n",
    "    except FileNotFoundError:\n",
    "        return None\n",
    "\n",
    "baseline_eval = load_eval_results(f\"{OUTPUT_DIR}/responses/baseline_evaluation.json\")\n",
    "steered_eval = load_eval_results(f\"{OUTPUT_DIR}/responses/steered_evaluation.json\")\n",
    "\n",
    "print(\"Evaluation Results Comparison:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if baseline_eval:\n",
    "    metrics = baseline_eval.get('aggregated_metrics', {})\n",
    "    print(f\"\\nBaseline Model:\")\n",
    "    print(f\"  Pass Rate: {metrics.get('pass_rate', 0):.2%}\")\n",
    "    print(f\"  Total Passed: {metrics.get('total_passed', 0)}\")\n",
    "    print(f\"  Total Problems: {metrics.get('total_problems', 0)}\")\n",
    "\n",
    "if steered_eval:\n",
    "    metrics = steered_eval.get('aggregated_metrics', {})\n",
    "    print(f\"\\nSteered Model:\")\n",
    "    print(f\"  Pass Rate: {metrics.get('pass_rate', 0):.2%}\")\n",
    "    print(f\"  Total Passed: {metrics.get('total_passed', 0)}\")\n",
    "    print(f\"  Total Problems: {metrics.get('total_problems', 0)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
