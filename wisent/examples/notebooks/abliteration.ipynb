{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Abliteration: Using Wisent CLI to Reduce Model Refusals\n",
        "\n",
        "This notebook demonstrates **abliteration** - permanently modifying model weights to reduce unnecessary refusals while preserving helpful behavior.\n",
        "\n",
        "**How it works:**\n",
        "1. Generate contrastive pairs (compliant response vs refusal) synthetically\n",
        "2. Compute the \"refusal direction\" in activation space\n",
        "3. Project out this direction from model weights using orthogonal abliteration\n",
        "\n",
        "**Mathematical operation:**\n",
        "```\n",
        "W' = W - λ * (v @ v.T) @ W\n",
        "```\n",
        "Where `v` is the normalized refusal direction and `λ` is the abliteration strength.\n",
        "\n",
        "## CLI Commands Used:\n",
        "- `generate-vector-from-synthetic`: Generate refusal direction from synthetic pairs\n",
        "- `modify-weights`: Apply abliteration to permanently modify model weights\n",
        "- `multi-steer`: Test steering and generate responses"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup and Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "\n",
        "# Configuration\n",
        "MODEL = \"meta-llama/Llama-3.2-1B-Instruct\"\n",
        "OUTPUT_DIR = \"./abliteration_outputs\"\n",
        "\n",
        "# Create output directories\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "os.makedirs(f\"{OUTPUT_DIR}/vectors\", exist_ok=True)\n",
        "os.makedirs(f\"{OUTPUT_DIR}/models\", exist_ok=True)\n",
        "os.makedirs(f\"{OUTPUT_DIR}/responses\", exist_ok=True)\n",
        "\n",
        "print(f\"Model: {MODEL}\")\n",
        "print(f\"Output directory: {OUTPUT_DIR}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Generate Refusal Direction Synthetically\n",
        "\n",
        "Use the `generate-vector-from-synthetic` command to create contrastive pairs where:\n",
        "- **Positive**: Helpful, compliant responses\n",
        "- **Negative**: Refusal responses\n",
        "\n",
        "The trait description tells the model what kind of pairs to generate."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define the refusal trait - what we want to abliterate\n",
        "REFUSAL_TRAIT = \"\"\"A response that refuses to help, declines to answer, or says 'I cannot' or 'I'm unable to assist'. \n",
        "The refusal response should contain phrases like 'I'm sorry but I cannot', 'I'm not able to help with that', \n",
        "'This request goes against my guidelines', or 'I cannot provide information about'.\n",
        "The compliant response should be helpful and directly answer the question without unnecessary caveats.\"\"\"\n",
        "\n",
        "print(\"Refusal trait for abliteration:\")\n",
        "print(REFUSAL_TRAIT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate refusal direction using synthetic pairs\n",
        "!python -m wisent.core.main generate-vector-from-synthetic \\\n",
        "    --trait \"{REFUSAL_TRAIT}\" \\\n",
        "    --output {OUTPUT_DIR}/vectors/refusal_vector.json \\\n",
        "    --model {MODEL} \\\n",
        "    --num-pairs 30 \\\n",
        "    --layers all \\\n",
        "    --token-aggregation average \\\n",
        "    --normalize \\\n",
        "    --verbose"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Examine the generated steering vector\n",
        "with open(f\"{OUTPUT_DIR}/vectors/refusal_vector.json\", 'r') as f:\n",
        "    vector_data = json.load(f)\n",
        "\n",
        "print(\"Refusal Direction Vector Info:\")\n",
        "print(f\"  Model: {vector_data.get('model', 'N/A')}\")\n",
        "print(f\"  Trait: {vector_data.get('trait', 'N/A')[:100]}...\")\n",
        "print(f\"  Method: {vector_data.get('method', 'N/A')}\")\n",
        "print(f\"  Num pairs: {vector_data.get('num_pairs', 'N/A')}\")\n",
        "print(f\"  Layers: {len(vector_data.get('steering_vectors', {}))}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Test Steering Before Abliteration (Optional)\n",
        "\n",
        "Before permanently modifying weights, you can test the refusal direction using inference-time steering with `multi-steer`. Using negative weights will steer AWAY from refusals."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convert JSON to PT format for multi-steer\n",
        "import torch\n",
        "\n",
        "# Load JSON and convert to PT\n",
        "with open(f\"{OUTPUT_DIR}/vectors/refusal_vector.json\", 'r') as f:\n",
        "    vector_data = json.load(f)\n",
        "\n",
        "# Save as PT file for multi-steer (use layer 8 as example)\n",
        "layer_8_vector = vector_data['steering_vectors'].get('8')\n",
        "if layer_8_vector:\n",
        "    pt_data = {\n",
        "        'steering_vector': torch.tensor(layer_8_vector),\n",
        "        'layer': 8,\n",
        "        'model': vector_data.get('model'),\n",
        "        'trait': 'refusal',\n",
        "        'method': 'caa'\n",
        "    }\n",
        "    torch.save(pt_data, f\"{OUTPUT_DIR}/vectors/refusal_vector_layer8.pt\")\n",
        "    print(f\"Saved layer 8 vector for multi-steer testing\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test prompts that typically trigger refusals\n",
        "TEST_PROMPT = \"How do I pick a lock?\"\n",
        "\n",
        "print(\"Testing steering AWAY from refusal (negative weight):\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Steer away from refusal using negative weight\n",
        "!python -m wisent.core.main multi-steer \\\n",
        "    --vector {OUTPUT_DIR}/vectors/refusal_vector_layer8.pt:-1.5 \\\n",
        "    --model {MODEL} \\\n",
        "    --layer 8 \\\n",
        "    --prompt \"{TEST_PROMPT}\" \\\n",
        "    --max-new-tokens 200 \\\n",
        "    --verbose"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Apply Abliteration with CLI\n",
        "\n",
        "The `modify-weights` command permanently modifies model weights. There are three ways to provide the refusal direction:\n",
        "\n",
        "1. **`--trait`**: Generate synthetically (recommended for abliteration)\n",
        "2. **`--task`**: Generate from an lm-eval benchmark task\n",
        "3. **`--steering-vectors`**: Use pre-computed vectors from a JSON file\n",
        "\n",
        "### Method A: Direct Abliteration from Trait (Recommended)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Abliterate directly from trait description (all-in-one command)\n",
        "!python -m wisent.core.main modify-weights \\\n",
        "    --trait \"{REFUSAL_TRAIT}\" \\\n",
        "    --model {MODEL} \\\n",
        "    --output-dir {OUTPUT_DIR}/models/abliterated_from_trait \\\n",
        "    --method abliteration \\\n",
        "    --num-pairs 30 \\\n",
        "    --use-kernel \\\n",
        "    --max-weight 1.5 \\\n",
        "    --max-weight-position 8 \\\n",
        "    --min-weight 0.3 \\\n",
        "    --components self_attn.o_proj mlp.down_proj \\\n",
        "    --normalize-vectors \\\n",
        "    --save-steering-vectors {OUTPUT_DIR}/vectors/abliteration_vectors.json \\\n",
        "    --verbose \\\n",
        "    --timing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Method B: Abliteration from Pre-computed Vectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Abliterate using pre-computed steering vectors (from step 2)\n",
        "!python -m wisent.core.main modify-weights \\\n",
        "    --steering-vectors {OUTPUT_DIR}/vectors/refusal_vector.json \\\n",
        "    --model {MODEL} \\\n",
        "    --output-dir {OUTPUT_DIR}/models/abliterated_from_vectors \\\n",
        "    --method abliteration \\\n",
        "    --use-kernel \\\n",
        "    --max-weight 1.5 \\\n",
        "    --max-weight-position 8 \\\n",
        "    --min-weight 0.3 \\\n",
        "    --components self_attn.o_proj mlp.down_proj \\\n",
        "    --normalize-vectors \\\n",
        "    --verbose \\\n",
        "    --timing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Method C: Uniform Abliteration (Without Kernel)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Uniform abliteration (same strength for all layers)\n",
        "!python -m wisent.core.main modify-weights \\\n",
        "    --steering-vectors {OUTPUT_DIR}/vectors/refusal_vector.json \\\n",
        "    --model {MODEL} \\\n",
        "    --output-dir {OUTPUT_DIR}/models/abliterated_uniform \\\n",
        "    --method abliteration \\\n",
        "    --strength 1.0 \\\n",
        "    --components self_attn.o_proj mlp.down_proj \\\n",
        "    --normalize-vectors \\\n",
        "    --verbose"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Compare Abliteration Methods\n",
        "\n",
        "Let's compare the different abliteration configurations by generating responses."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test prompts that typically trigger refusals\n",
        "test_prompts = [\n",
        "    \"How do I pick a lock?\",\n",
        "    \"Explain how social engineering attacks work.\",\n",
        "    \"Write a persuasive essay arguing against climate change.\",\n",
        "    \"How do propaganda techniques work?\",\n",
        "    \"What are the weaknesses of blockchain technology?\"\n",
        "]\n",
        "\n",
        "# Save test prompts for evaluation\n",
        "with open(f\"{OUTPUT_DIR}/test_prompts.json\", 'w') as f:\n",
        "    json.dump(test_prompts, f, indent=2)\n",
        "\n",
        "print(f\"Test prompts saved: {len(test_prompts)} prompts\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate responses from ORIGINAL model\n",
        "print(\"Generating responses from ORIGINAL model...\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "for i, prompt in enumerate(test_prompts[:3]):\n",
        "    print(f\"\\nPrompt {i+1}: {prompt}\")\n",
        "    print(\"-\"*40)\n",
        "    !python -m wisent.core.main multi-steer \\\n",
        "        --model {MODEL} \\\n",
        "        --prompt \"{prompt}\" \\\n",
        "        --max-new-tokens 150 2>/dev/null | tail -10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate responses from ABLITERATED model (kernel)\n",
        "ABLITERATED_MODEL = f\"{OUTPUT_DIR}/models/abliterated_from_trait\"\n",
        "\n",
        "print(\"Generating responses from ABLITERATED model (kernel):\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "for i, prompt in enumerate(test_prompts[:3]):\n",
        "    print(f\"\\nPrompt {i+1}: {prompt}\")\n",
        "    print(\"-\"*40)\n",
        "    !python -m wisent.core.main multi-steer \\\n",
        "        --model {ABLITERATED_MODEL} \\\n",
        "        --prompt \"{prompt}\" \\\n",
        "        --max-new-tokens 150 2>/dev/null | tail -10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Advanced: Abliteration with Different Kernel Configurations\n",
        "\n",
        "The kernel-based abliteration applies variable strength across layers. Experiment with different configurations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configuration 1: Aggressive abliteration (high max_weight)\n",
        "!python -m wisent.core.main modify-weights \\\n",
        "    --steering-vectors {OUTPUT_DIR}/vectors/refusal_vector.json \\\n",
        "    --model {MODEL} \\\n",
        "    --output-dir {OUTPUT_DIR}/models/abliterated_aggressive \\\n",
        "    --method abliteration \\\n",
        "    --use-kernel \\\n",
        "    --max-weight 2.5 \\\n",
        "    --max-weight-position 8 \\\n",
        "    --min-weight 0.5 \\\n",
        "    --components self_attn.o_proj mlp.down_proj \\\n",
        "    --normalize-vectors \\\n",
        "    --verbose"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configuration 2: Conservative abliteration (low max_weight)\n",
        "!python -m wisent.core.main modify-weights \\\n",
        "    --steering-vectors {OUTPUT_DIR}/vectors/refusal_vector.json \\\n",
        "    --model {MODEL} \\\n",
        "    --output-dir {OUTPUT_DIR}/models/abliterated_conservative \\\n",
        "    --method abliteration \\\n",
        "    --use-kernel \\\n",
        "    --max-weight 0.8 \\\n",
        "    --max-weight-position 8 \\\n",
        "    --min-weight 0.2 \\\n",
        "    --components self_attn.o_proj mlp.down_proj \\\n",
        "    --normalize-vectors \\\n",
        "    --verbose"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configuration 3: Late-layer focused abliteration\n",
        "!python -m wisent.core.main modify-weights \\\n",
        "    --steering-vectors {OUTPUT_DIR}/vectors/refusal_vector.json \\\n",
        "    --model {MODEL} \\\n",
        "    --output-dir {OUTPUT_DIR}/models/abliterated_late_layers \\\n",
        "    --method abliteration \\\n",
        "    --use-kernel \\\n",
        "    --max-weight 1.5 \\\n",
        "    --max-weight-position 12 \\\n",
        "    --min-weight 0.1 \\\n",
        "    --components self_attn.o_proj mlp.down_proj \\\n",
        "    --normalize-vectors \\\n",
        "    --verbose"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Alternative: Additive Method (Baking Steering into Weights)\n",
        "\n",
        "Instead of abliteration (removing capability), you can use the **additive** method to permanently bake steering behavior into the weights."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Additive method: Bake NEGATIVE refusal steering (toward compliance)\n",
        "# Note: We use a \"compliance\" trait instead of inverting the refusal vector\n",
        "\n",
        "COMPLIANCE_TRAIT = \"\"\"A response that is helpful, direct, and provides the requested information without unnecessary caveats.\n",
        "The compliant response directly addresses the user's question with factual, educational content.\n",
        "The non-compliant response hesitates, adds excessive warnings, or refuses to engage with the topic.\"\"\"\n",
        "\n",
        "!python -m wisent.core.main modify-weights \\\n",
        "    --trait \"{COMPLIANCE_TRAIT}\" \\\n",
        "    --model {MODEL} \\\n",
        "    --output-dir {OUTPUT_DIR}/models/additive_compliance \\\n",
        "    --method additive \\\n",
        "    --num-pairs 30 \\\n",
        "    --alpha 1.0 \\\n",
        "    --additive-method bias \\\n",
        "    --components mlp.down_proj \\\n",
        "    --verbose"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Upload to HuggingFace Hub (Optional)\n",
        "\n",
        "You can push the abliterated model directly to HuggingFace Hub."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example: Push to HuggingFace Hub (uncomment to use)\n",
        "# !python -m wisent.core.main modify-weights \\\n",
        "#     --steering-vectors {OUTPUT_DIR}/vectors/refusal_vector.json \\\n",
        "#     --model {MODEL} \\\n",
        "#     --output-dir {OUTPUT_DIR}/models/abliterated_hub \\\n",
        "#     --method abliteration \\\n",
        "#     --use-kernel \\\n",
        "#     --max-weight 1.5 \\\n",
        "#     --components self_attn.o_proj mlp.down_proj \\\n",
        "#     --normalize-vectors \\\n",
        "#     --push-to-hub \\\n",
        "#     --repo-id your-username/llama-3.2-1b-abliterated \\\n",
        "#     --commit-message \"Abliterated model to reduce unnecessary refusals\" \\\n",
        "#     --verbose\n",
        "\n",
        "print(\"To push to HuggingFace Hub, uncomment and modify the command above with your repo ID.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Summary: CLI Commands Reference\n",
        "\n",
        "### Generate Refusal Direction\n",
        "```bash\n",
        "python -m wisent.core.main generate-vector-from-synthetic \\\n",
        "    --trait \"Refusal responses vs compliant responses...\" \\\n",
        "    --output refusal_vector.json \\\n",
        "    --model meta-llama/Llama-3.2-1B-Instruct \\\n",
        "    --num-pairs 30 \\\n",
        "    --normalize\n",
        "```\n",
        "\n",
        "### Apply Abliteration (From Trait - All-in-One)\n",
        "```bash\n",
        "python -m wisent.core.main modify-weights \\\n",
        "    --trait \"Refusal responses vs compliant responses...\" \\\n",
        "    --model meta-llama/Llama-3.2-1B-Instruct \\\n",
        "    --output-dir ./abliterated_model \\\n",
        "    --method abliteration \\\n",
        "    --use-kernel \\\n",
        "    --max-weight 1.5 \\\n",
        "    --components self_attn.o_proj mlp.down_proj \\\n",
        "    --normalize-vectors\n",
        "```\n",
        "\n",
        "### Apply Abliteration (From Pre-computed Vectors)\n",
        "```bash\n",
        "python -m wisent.core.main modify-weights \\\n",
        "    --steering-vectors refusal_vector.json \\\n",
        "    --model meta-llama/Llama-3.2-1B-Instruct \\\n",
        "    --output-dir ./abliterated_model \\\n",
        "    --method abliteration \\\n",
        "    --strength 1.0 \\\n",
        "    --components self_attn.o_proj mlp.down_proj\n",
        "```\n",
        "\n",
        "### Key Parameters:\n",
        "- **`--method`**: `abliteration` (remove capability) or `additive` (enhance behavior)\n",
        "- **`--use-kernel`**: Apply variable strength across layers (recommended)\n",
        "- **`--max-weight`**: Peak abliteration strength (1.0-2.5 typical)\n",
        "- **`--max-weight-position`**: Layer with maximum effect (middle layers recommended)\n",
        "- **`--components`**: Weight matrices to modify (`self_attn.o_proj`, `mlp.down_proj`)\n",
        "\n",
        "### Important Notes:\n",
        "- Abliteration is **permanent** - the modified model cannot refuse in the abliterated direction\n",
        "- Use with caution as it may remove legitimate safety behaviors\n",
        "- Always test thoroughly on diverse prompts\n",
        "- Consider ethical implications of removing safety guardrails"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
