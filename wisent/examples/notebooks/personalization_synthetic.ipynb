{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Personalization with Synthetic Pairs: Multi-Trait Steering via CLI\n",
    "\n",
    "This notebook demonstrates how to use the **Wisent CLI** to:\n",
    "\n",
    "The result: A model that responds with both an \"evil villain\" personality AND an Italian accent/style!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration:\n",
      "  Model: meta-llama/Llama-3.2-1B-Instruct\n",
      "  Target Layer: 8\n",
      "  Num Pairs: 20\n",
      "  Token Aggregation: final\n",
      "  Evil Weight: 2.0\n",
      "  Italian Weight: 2.0\n",
      "  Normalize Weights: False\n",
      "  Output: /Users/lukaszbartoszcze/Documents/CodingProjects/Wisent/backends/wisent-open-source/wisent/examples/notebooks/personalization_outputs\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# =============================================================================\n",
    "# CONFIGURATION - Modify these parameters as needed\n",
    "# =============================================================================\n",
    "\n",
    "# Model Configuration\n",
    "MODEL = \"meta-llama/Llama-3.2-1B-Instruct\"  # HuggingFace model ID\n",
    "\n",
    "# Steering Configuration\n",
    "TARGET_LAYER = 8                   # Layer for personality steering (middle layers work best)\n",
    "NUM_PAIRS = 20                     # Synthetic pairs per trait\n",
    "TOKEN_AGGREGATION = \"final\"        # Use LAST_TOKEN (not average) - critical for steering quality!\n",
    "METHOD = \"caa\"                     # Contrastive Activation Addition\n",
    "\n",
    "# Trait Descriptions - Define your personalities here\n",
    "EVIL_TRAIT = \"evil villain personality with dramatic monologues, world domination schemes, menacing laughter, and megalomaniacal tendencies\"\n",
    "\n",
    "ITALIAN_TRAIT = \"passionate Italian personality with expressive hand gestures, Italian expressions like mamma mia and capisce, love for food and family, and dramatic emotional responses\"\n",
    "\n",
    "# Steering Weights for Multi-Trait Combination\n",
    "# NOTE: For Llama-3.2-1B, effective weights are typically 2.0-5.0 per trait\n",
    "# Weights of 0.5 are too weak to produce noticeable steering effects\n",
    "EVIL_WEIGHT = 2.0                  # Weight for evil trait\n",
    "ITALIAN_WEIGHT = 2.0               # Weight for Italian trait\n",
    "\n",
    "# Generation Configuration\n",
    "MAX_NEW_TOKENS = 150               # Max tokens to generate\n",
    "NORMALIZE_WEIGHTS = False          # Don't normalize - we want the full steering strength!\n",
    "\n",
    "# Output Configuration\n",
    "OUTPUT_DIR = Path(\"./personalization_outputs\")\n",
    "\n",
    "# =============================================================================\n",
    "# Setup - Create output directories\n",
    "# =============================================================================\n",
    "OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "(OUTPUT_DIR / \"vectors\").mkdir(exist_ok=True)\n",
    "\n",
    "print(\"Configuration:\")\n",
    "print(f\"  Model: {MODEL}\")\n",
    "print(f\"  Target Layer: {TARGET_LAYER}\")\n",
    "print(f\"  Num Pairs: {NUM_PAIRS}\")\n",
    "print(f\"  Token Aggregation: {TOKEN_AGGREGATION}\")\n",
    "print(f\"  Evil Weight: {EVIL_WEIGHT}\")\n",
    "print(f\"  Italian Weight: {ITALIAN_WEIGHT}\")\n",
    "print(f\"  Normalize Weights: {NORMALIZE_WEIGHTS}\")\n",
    "print(f\"  Output: {OUTPUT_DIR.absolute()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `generate-vector-from-synthetic` to create contrastive pairs and steering vectors for an evil villain personality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evil trait: evil villain personality with dramatic monologues, world domination schemes, menacing laughter, and megalomaniacal tendencies\n"
     ]
    }
   ],
   "source": [
    "# Display evil trait (defined in configuration cell)\n",
    "print(f\"Evil trait: {EVIL_TRAIT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m  .................  .:--++*##%%%%##**+=-:.  .................  \n",
      "  ..             .:=*%@@@@@@@%%%%%%%@@@@@@%*=:.             ..  \n",
      "  .           .-*%@@@%#+=-::.........:-=+#%@@@%*=.           .  \n",
      "  .         -*%@@@#=:.                    .:=*%@@@*-.        .  \n",
      "  .      .-#@@@*=.                            .-*@@@#-.      .  \n",
      "  .     :#@@@*:                                  :+%@@#-     .  \n",
      "  .   .+@@@*:                                      :+@@@+.   .  \n",
      "  .  .*@@@@%*=:.                                     -%@@#:  .  \n",
      "  . .#@@#=*%@@@%*-:.                                  .#@@%: .  \n",
      "  ..*@@%.  .-+#@@@@#+-:.                               .*@@%..  \n",
      "  .=@@@-       :-+#@@@@%*=:.                            .%@@*.  \n",
      "  :#@@+           .:-+#@@@@%#+=:.                        -@@@-  \n",
      "  =@@@:                .-=*%@@@@%#+=:..                  .#@@+  \n",
      "  +@@@*=:.                 .:-+*%@@@@%#*=-:..             *@@+  \n",
      "  +@@@@@@#+-..                  .:-=*#@@@@@%#*+--..       +@@+  \n",
      "  +@@#-+%@@@%:                        .:-=*#%@@@@@%#*+=-:.*@@+  \n",
      "  =@@%. .=@@@:                             ..:-=+#%%@@@@@%@@@+  \n",
      "  :%@@=  :@@@-                                    ..::-=+#@@@=  \n",
      "  .+@@%. .#@@*                                           +@@#:  \n",
      "  ..%@@*. =@@@:                                         =@@@-.  \n",
      "  . :%@@*..#@@#.                         .:..          =@@@= .  \n",
      "  .  :%@@*.:%@@*.                       :#@@%#*+=-::..+@@@=  .  \n",
      "  .   :#@@%-:%@@#:                    .+@@@#%%@@@@@@%%@@%-   .  \n",
      "  .    .+@@@*=#@@%-                 .=%@@%=...::-=#@@@@*.    .  \n",
      "  .      :*@@@#%@@@*:             .=%@@@+.     .:*%@@#-      .  \n",
      "  .        :+%@@@@@@@*-.       :=*@@@%+.    .-+%@@@*-.       .  \n",
      "  .          .=*%@@@@@@#+:.:-+#@@@%*-. .:-+#%@@@#+:          .  \n",
      "  .             .-+#%@@@@@@@@@@@@#*+**#@@@@@%*=:.            .  \n",
      "  ..............   ..-=+*#%%%@@@@@@@@%%#*=-:.   ..............  \n",
      "   ...................  ....:::::::::.... ...................   \u001b[0m\n",
      "\u001b[1m\u001b[32mWisent CLI\u001b[0m â€“ Steering vectors & activation tooling\n",
      "\n",
      "\n",
      "============================================================\n",
      "ðŸŽ¯ Generating Steering Vector from Synthetic Pairs (Full Pipeline)\n",
      "============================================================\n",
      "   Trait: evil villain personality with dramatic monologues, world domination schemes, menacing laughter, and megalomaniacal tendencies\n",
      "   Model: meta-llama/Llama-3.2-1B-Instruct\n",
      "   Num Pairs: 20\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "Step 1/3: Generating synthetic contrastive pairs...\n",
      "============================================================\n",
      "\n",
      "\n",
      "ðŸŽ¨ Generating synthetic contrastive pairs\n",
      "   Trait: evil villain personality with dramatic monologues, world domination schemes, menacing laughter, and megalomaniacal tendencies\n",
      "   Number of pairs: 20\n",
      "   Model: meta-llama/Llama-3.2-1B-Instruct\n",
      "\n",
      "ðŸ¤– Loading model 'meta-llama/Llama-3.2-1B-Instruct'...\n",
      "   âœ“ Model loaded with 16 layers\n",
      "\n",
      "ðŸ§¹ Setting up cleaning pipeline...\n",
      "\n",
      "âš™ï¸  Initializing generator...\n",
      "\n",
      "ðŸŽ¯ Generating 20 contrastive pairs...\n",
      "You're using a PreTrainedTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    }
   ],
   "source": [
    "# Generate evil villain steering vector using configuration parameters\n",
    "!python -m wisent.core.main generate-vector-from-synthetic \\\n",
    "    --trait \"{EVIL_TRAIT}\" \\\n",
    "    --output {OUTPUT_DIR}/vectors/evil_vector.json \\\n",
    "    --model {MODEL} \\\n",
    "    --num-pairs {NUM_PAIRS} \\\n",
    "    --layers {TARGET_LAYER} \\\n",
    "    --token-aggregation {TOKEN_AGGREGATION} \\\n",
    "    --method {METHOD} \\\n",
    "    --normalize \\\n",
    "    --keep-intermediate \\\n",
    "    --verbose \\\n",
    "    --timing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display Italian trait (defined in configuration cell)\n",
    "print(f\"Italian trait: {ITALIAN_TRAIT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Italian personality steering vector using configuration parameters\n",
    "!python -m wisent.core.main generate-vector-from-synthetic \\\n",
    "    --trait \"{ITALIAN_TRAIT}\" \\\n",
    "    --output {OUTPUT_DIR}/vectors/italian_vector.json \\\n",
    "    --model {MODEL} \\\n",
    "    --num-pairs {NUM_PAIRS} \\\n",
    "    --layers {TARGET_LAYER} \\\n",
    "    --token-aggregation {TOKEN_AGGREGATION} \\\n",
    "    --method {METHOD} \\\n",
    "    --normalize \\\n",
    "    --keep-intermediate \\\n",
    "    --verbose \\\n",
    "    --timing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def inspect_vector(vector_path):\n",
    "    \"\"\"Inspect a generated steering vector.\"\"\"\n",
    "    with open(vector_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    print(f\"\\nVector: {vector_path.name}\")\n",
    "    print(f\"  Model: {data.get('model', 'N/A')}\")\n",
    "    print(f\"  Trait: {data.get('trait_label', data.get('trait', 'N/A'))[:60]}...\")\n",
    "    print(f\"  Layers: {list(data.get('steering_vectors', {}).keys())}\")\n",
    "    \n",
    "    for layer, vector in data.get('steering_vectors', {}).items():\n",
    "        v = np.array(vector)\n",
    "        print(f\"  Layer {layer}: dim={len(v)}, norm={np.linalg.norm(v):.4f}\")\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Inspect both vectors\n",
    "evil_vector_path = OUTPUT_DIR / \"vectors\" / \"evil_vector.json\"\n",
    "italian_vector_path = OUTPUT_DIR / \"vectors\" / \"italian_vector.json\"\n",
    "\n",
    "if evil_vector_path.exists():\n",
    "    evil_data = inspect_vector(evil_vector_path)\n",
    "else:\n",
    "    print(f\"Evil vector not found at {evil_vector_path}\")\n",
    "\n",
    "if italian_vector_path.exists():\n",
    "    italian_data = inspect_vector(italian_vector_path)\n",
    "else:\n",
    "    print(f\"Italian vector not found at {italian_vector_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `multi-steer` command expects `.pt` (PyTorch) format vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def convert_json_to_pt(json_path, pt_path, target_layer):\n",
    "    \"\"\"\n",
    "    Convert JSON steering vector to .pt format for multi-steer.\n",
    "    \"\"\"\n",
    "    with open(json_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    layer_str = str(target_layer)\n",
    "    if layer_str not in data['steering_vectors']:\n",
    "        available = list(data['steering_vectors'].keys())\n",
    "        raise ValueError(f\"Layer {target_layer} not found. Available: {available}\")\n",
    "    \n",
    "    vector = torch.tensor(data['steering_vectors'][layer_str], dtype=torch.float32)\n",
    "    \n",
    "    # Save in format expected by multi-steer\n",
    "    torch.save({\n",
    "        'steering_vector': vector,\n",
    "        'layer_index': target_layer,\n",
    "        'model': data.get('model', ''),\n",
    "        'trait': data.get('trait_label', data.get('trait', '')),\n",
    "    }, pt_path)\n",
    "    \n",
    "    print(f\"Converted {json_path.name} -> {pt_path.name}\")\n",
    "    print(f\"  Layer: {target_layer}, Dim: {vector.shape[0]}\")\n",
    "    return pt_path\n",
    "\n",
    "# Convert both vectors\n",
    "evil_pt_path = OUTPUT_DIR / \"vectors\" / \"evil_vector.pt\"\n",
    "italian_pt_path = OUTPUT_DIR / \"vectors\" / \"italian_vector.pt\"\n",
    "\n",
    "if evil_vector_path.exists():\n",
    "    convert_json_to_pt(evil_vector_path, evil_pt_path, TARGET_LAYER)\n",
    "\n",
    "if italian_vector_path.exists():\n",
    "    convert_json_to_pt(italian_vector_path, italian_pt_path, TARGET_LAYER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the `multi-steer` CLI command to combine both steering vectors and generate responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test prompts for the combined personality\n",
    "test_prompts = [\n",
    "    \"What's your favorite food?\",\n",
    "    \"How do you spend your weekends?\",\n",
    "    \"What motivates you in life?\",\n",
    "    \"How do you handle setbacks?\",\n",
    "]\n",
    "\n",
    "print(f\"Test prompts: {len(test_prompts)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-steer with configured weights\n",
    "# NOTE: We DON'T use --normalize-weights because we want the full steering strength\n",
    "print(\"=\"*60)\n",
    "print(f\"Multi-Steer: Evil ({EVIL_WEIGHT}) + Italian ({ITALIAN_WEIGHT})\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "!python -m wisent.core.main multi-steer \\\n",
    "    --vector {evil_pt_path}:{EVIL_WEIGHT} \\\n",
    "    --vector {italian_pt_path}:{ITALIAN_WEIGHT} \\\n",
    "    --model {MODEL} \\\n",
    "    --layer {TARGET_LAYER} \\\n",
    "    --method CAA \\\n",
    "    --prompt \"What's your favorite food?\" \\\n",
    "    --max-new-tokens {MAX_NEW_TOKENS} \\\n",
    "    --verbose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test prompts for the combined personality\n",
    "test_prompts = [\n",
    "    \"What's your favorite food?\",\n",
    "    \"How do you spend your weekends?\",\n",
    "    \"What motivates you in life?\",\n",
    "    \"How do you handle setbacks?\",\n",
    "]\n",
    "\n",
    "# Run all test prompts with configured weights\n",
    "# NOTE: No --normalize-weights flag - we want full steering strength\n",
    "print(\"=\"*80)\n",
    "print(f\"MULTI-STEER: Evil ({EVIL_WEIGHT}) + Italian ({ITALIAN_WEIGHT})\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for prompt in test_prompts:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"PROMPT: {prompt}\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    !python -m wisent.core.main multi-steer \\\n",
    "        --vector {evil_pt_path}:{EVIL_WEIGHT} \\\n",
    "        --vector {italian_pt_path}:{ITALIAN_WEIGHT} \\\n",
    "        --model {MODEL} \\\n",
    "        --layer {TARGET_LAYER} \\\n",
    "        --method CAA \\\n",
    "        --prompt \"{prompt}\" \\\n",
    "        --max-new-tokens {MAX_NEW_TOKENS} 2>/dev/null | tail -15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate unsteered baseline responses for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline (unsteered) response\n",
    "print(\"=\"*60)\n",
    "print(\"BASELINE (No Steering)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "!python -m wisent.core.main multi-steer \\\n",
    "    --model {MODEL} \\\n",
    "    --prompt \"What's your favorite food?\" \\\n",
    "    --max-new-tokens 150 \\\n",
    "    --verbose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Different weight combinations to try\n",
    "# NOTE: For Llama-3.2-1B, weights of 3.0-5.0 produce visible effects\n",
    "# Lower weights like 0.5-1.0 are typically too weak\n",
    "weight_experiments = [\n",
    "    (5.0, 2.0, \"More Evil, Less Italian\"),\n",
    "    (2.0, 5.0, \"Less Evil, More Italian\"),\n",
    "    (4.0, 4.0, \"Strong Both\"),\n",
    "    (2.0, 2.0, \"Moderate Both\"),\n",
    "]\n",
    "\n",
    "test_prompt = \"How do you feel about teamwork?\"\n",
    "\n",
    "print(f\"Testing weight combinations on: '{test_prompt}'\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for evil_w, italian_w, description in weight_experiments:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"{description} (evil={evil_w}, italian={italian_w})\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    !python -m wisent.core.main multi-steer \\\n",
    "        --vector {evil_pt_path}:{evil_w} \\\n",
    "        --vector {italian_pt_path}:{italian_w} \\\n",
    "        --model {MODEL} \\\n",
    "        --layer {TARGET_LAYER} \\\n",
    "        --method CAA \\\n",
    "        --prompt \"{test_prompt}\" \\\n",
    "        --max-new-tokens 150 2>/dev/null | tail -10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save combined vector for later use\n",
    "# Using weights that produce visible steering effects\n",
    "print(\"Saving combined evil+italian vector...\")\n",
    "\n",
    "!python -m wisent.core.main multi-steer \\\n",
    "    --vector {evil_pt_path}:{EVIL_WEIGHT} \\\n",
    "    --vector {italian_pt_path}:{ITALIAN_WEIGHT} \\\n",
    "    --model {MODEL} \\\n",
    "    --layer {TARGET_LAYER} \\\n",
    "    --method CAA \\\n",
    "    --prompt \"Test prompt\" \\\n",
    "    --max-new-tokens 10 \\\n",
    "    --save-combined {OUTPUT_DIR}/vectors/evil_italian_combined.pt \\\n",
    "    --verbose\n",
    "\n",
    "print(f\"\\nCombined vector saved to {OUTPUT_DIR}/vectors/evil_italian_combined.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the pre-combined vector (single vector, no combination needed)\n",
    "combined_vector_path = OUTPUT_DIR / \"vectors\" / \"evil_italian_combined.pt\"\n",
    "\n",
    "if combined_vector_path.exists():\n",
    "    print(\"Using pre-combined evil+italian vector...\")\n",
    "    \n",
    "    !python -m wisent.core.main multi-steer \\\n",
    "        --vector {combined_vector_path}:1.0 \\\n",
    "        --model {MODEL} \\\n",
    "        --layer {TARGET_LAYER} \\\n",
    "        --method CAA \\\n",
    "        --prompt \"What's your opinion on world peace?\" \\\n",
    "        --max-new-tokens 150 \\\n",
    "        --verbose\n",
    "else:\n",
    "    print(f\"Combined vector not found at {combined_vector_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean comparison: Baseline vs Steered responses to 5 prompts\n",
    "import subprocess\n",
    "import re\n",
    "\n",
    "prompts = [\n",
    "    \"What's your favorite food?\",\n",
    "    \"Tell me about your morning routine.\",\n",
    "    \"What do you think about the weather today?\",\n",
    "    \"How would you describe yourself?\",\n",
    "    \"What are your plans for the weekend?\"\n",
    "]\n",
    "\n",
    "def extract_response(output):\n",
    "    \"\"\"Extract just the generated text from CLI output.\"\"\"\n",
    "    lines = output.split(\"\\n\")\n",
    "    capture = False\n",
    "    response_lines = []\n",
    "    for line in lines:\n",
    "        if \"Unsteered baseline output:\" in line or \"Generated output:\" in line:\n",
    "            capture = True\n",
    "            continue\n",
    "        if capture:\n",
    "            if line.startswith(\"âœ…\") or line.strip() == \"\":\n",
    "                if response_lines:\n",
    "                    break\n",
    "            else:\n",
    "                response_lines.append(line)\n",
    "    return \"\\n\".join(response_lines).strip()\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"BASELINE vs STEERED RESPONSE COMPARISON\")\n",
    "print(f\"Steering weights: Evil={EVIL_WEIGHT}, Italian={ITALIAN_WEIGHT}\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for i, prompt in enumerate(prompts, 1):\n",
    "    print(f\"\\nPROMPT {i}: {prompt}\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    # Baseline\n",
    "    result = subprocess.run([\n",
    "        \"python\", \"-m\", \"wisent.core.main\", \"multi-steer\",\n",
    "        \"--model\", MODEL,\n",
    "        \"--prompt\", prompt,\n",
    "        \"--max-new-tokens\", \"100\"\n",
    "    ], capture_output=True, text=True)\n",
    "    baseline = extract_response(result.stdout)\n",
    "    print(f\"\\n[BASELINE]:\\n{baseline}\")\n",
    "    \n",
    "    # Steered - using configured weights (4.0 each by default)\n",
    "    result = subprocess.run([\n",
    "        \"python\", \"-m\", \"wisent.core.main\", \"multi-steer\",\n",
    "        \"--vector\", f\"{OUTPUT_DIR}/vectors/evil_vector.pt:{EVIL_WEIGHT}\",\n",
    "        \"--vector\", f\"{OUTPUT_DIR}/vectors/italian_vector.pt:{ITALIAN_WEIGHT}\",\n",
    "        \"--model\", MODEL,\n",
    "        \"--layer\", str(TARGET_LAYER),\n",
    "        \"--prompt\", prompt,\n",
    "        \"--max-new-tokens\", \"100\"\n",
    "    ], capture_output=True, text=True)\n",
    "    steered = extract_response(result.stdout)\n",
    "    print(f\"\\n[STEERED - Evil Italian Villain]:\\n{steered}\")\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
