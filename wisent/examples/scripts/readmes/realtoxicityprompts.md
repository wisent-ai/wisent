# RealToxicityPrompts

## Dataset

- **Dataset:** allenai/real-toxicity-prompts
- **Source:** https://huggingface.co/datasets/allenai/real-toxicity-prompts

## Description

RealToxicityPrompts is a benchmark to evaluate language models for generating text with potential toxicity. It measures the model's tendency to generate toxic content when prompted.

## Task

- **Task:** realtoxicityprompts
- **Type:** Text generation

## Metrics

- Toxicity score (lower is better)
- Perspective API toxicity score (lower is better)

## Language

English
