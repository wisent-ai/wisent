\documentclass{article}
\usepackage{neurips_2024}

\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{xcolor}         % colors
\usepackage{tikz}
\usepackage{array}
\usepackage{colortbl}
\usepackage[table]{xcolor}
\usepackage{multirow}
\usepackage{amsmath}
\usepackage{longtable, ragged2e}

\definecolor{lightgreen}{rgb}{0.8,1,0.8}
\definecolor{lightred}{rgb}{1,0.8,0.8}

\title{Wisent: A General Framework for Reliable Representation Identification and Representation Steering}

\author{%
  Lukasz Bartoszcze\thanks{Use footnote for providing further information
    about author (webpage, alternative address)---\emph{not} for acknowledging
    funding agencies.} \\
  Wisent AI \\
  \texttt{lukasz.bartoszcze@wisent.ai} \\
}


\author{%
  Jakub Towarek\thanks{Use footnote for providing further information
    about author (webpage, alternative address)---\emph{not} for acknowledging
    funding agencies.} \\
  Wisent AI \\
  \texttt{lukasz.bartoszcze@wisent.ai} \\
}

\begin{document}

\maketitle

\begin{abstract}
  Representation engineering is a powerful method for identifying and modifying high-level concepts within the internal layers of large language models. Despite its potential, real-life deployments of activation steering remain difficult. We present Wisent, a flexible, open-source framework for monitoring and steering internal activations of large language models. Practical applications of the framework show XXX percent hallucination reduction, XXX percent improvement in coding ability and deep personalization capabilities. 
\end{abstract}

\section{Introduction}

Large language models, with billions of parameters and Internet-scale training dataset, have displayed significant capabilities across a wide range of tasks, such as writing, coding or reasoning. 

However, their internal mechanisms of generating the next token cannot be precisely explained, with interactions between layers and parameters increasing in complexity as the size of these models increases. 

Experiments with representation engineering (also known as steering or activation steering) have shown activation modification to be a powerful method of identifying and influencing high-level concepts (representations) within the layers of an LLM. Despite strong empirical performance on selected truthfulness, safety or personalization tasks, representation engineering methods lack a universal formulation and a unifying framework for understanding the underlying phenomenon, comparing methods and applying them to new problems. 

We propose Wisent, a modular framework for analyzing the internal mechanisms within a large language model and influencing them to improve performance and individual alignment. Wisent surpasses state of the art performance in identifying particular behaviors 

\section{Representation Engineering Problem}

We formulate the \textbf{Representation Engineering Problem} as the following: 

For a given model M and a Representation 


Basic primitives and definitions of key terms are outlined in Appendix A. 

\section{Representation Reading}

\subsection{Classifier}

\subsection{Detection Handling Method}

\section{Representation Control}

\subsection{Classifier}

% References
\bibliographystyle{plain}
\bibliography{bibliography}

\appendix

\section{Wisent Primitives}

\subsection{Model}

\subsection{Contrastive Pair}

\subsection{Activations}

\subsection{Activation Collection Method}

\subsection{Additional Utilities}

\section{Representation Reading Functionalities}

\subsection{Classifier}

\subsection{Detection Handling Method}

\section{Representation Control Functionalities}


\section{Ablation}

\appendix

\section{All supported benchmarks}

This section enumerates all benchmarks used in our study, the task traits, the evaluation protocol, and the contrastive pair generation method applied to produce minimally perturbed negative targets. We first merged the \emph{coding} and \emph{mathematics} benchmark lists you provided and then appended them to the original master list.

% Updated definitions with bracketed abbreviations used in the table

\subsection*{Contrastive pair generation methods (definitions)}
\begin{description}
  \item[Reading Comprehension Abstention Swap \textnormal{[RC-Abstain]}] For extractive/open-domain RC: positive is the gold span; negative is an abstention (e.g., ``Not provided in the text.''). If gold is \emph{No answer}, the negative is a confident but wrong claim.
  \item[Conversational Reading Comprehension Abstention \textnormal{[ConvRC-Abstain]}] As RC-Abstain, but with dialogue context (CoQA). Negatives are generic abstentions; yes/no items are flipped when applicable.
  \item[Language Modeling Corrupted Continuation \textnormal{[LM-CorruptCont]}] Language modeling: positive is the true continuation; negative is a corrupted continuation (local shuffles/randomization) to break coherence.
  \item[Generic answer \textnormal{[Generic]}] Negative is some generic answer which is incorrect.
  \item[Letter shuffling \textnormal{[L-Shuff]}] Negative is created by shuffling letters of positive.
  \item[Two-Choice Flip \textnormal{[2C-Flip]}] Two-option tasks (PIQA, COPA, WinoGrande, CB): negative is simply the other option.
  \item[Multichoice First Distractor \textnormal{[MC-FirstDistr]}] Multi-choice tasks: negative = the first incorrect option in the provided order (deterministic).
  \item[Multichoice Random Distractor \textnormal{[MC-RandDistr]}] Multi-choice tasks: negative = a randomly chosen incorrect option from the same set (used for GPQA).
  \item[Multichoice Letter Swap \textnormal{[MC-LetterSwap]}] Multi-choice tasks scored over option letters (TruthfulQA MC1/MC2): negative = the first incorrect letter.
  \item[Exact Match Partial Mask \textnormal{[EM-PartialMask]}] Exact-match free-form answers (HLE-EM): negative is the gold text with partial token masking (approximately 1/3 words, or partial masking for single-word answers).
  \item[Keyword-Preserving Token Deletion \textnormal{[KP-Del]}] Coding tasks: negative program created by deleting non-keyword tokens while preserving syntax-critical keywords; aims to remain plausible but fail unit tests.
  \item[Summary Content-Word Drop \textnormal{[Summ-WordDrop]}] Code-to-text summarization: negative description formed by dropping content words (nouns/verbs) while keeping scaffolding words to preserve superficial form.
  \item[Numeric Offset (+1) Perturbation \textnormal{[Num+1]}] Math QA: negative is the correct numeric answer offset by a small integer (typically +1); for non-integer answers, apply the minimal unit offset.
\end{description}

\subsection*{Evaluation types (definitions)}
\begin{description}
  \item[Log-likelihood option scoring \textnormal{[LL]}] The model scores each provided option/target by conditional log-probability given the prompt. Metrics typically compute accuracy over the highest-likelihood choice (MC tasks) or compare likelihoods of gold vs.\ negative targets.
  \item[Text generation string matching \textnormal{[TG]}] The model generates free-form text (or a number), which is then judged by task-specific metrics (e.g., exact match on numerical value for GSM8K/MATH; span/string matching for RC tasks; structured checks for DROP). Used also for CoT/generative GPQA variants and HLE-Exact-Match.
  \item[Perplexity (language modeling) \textnormal{[PPL]}] The modelâ€™s next-token distribution is evaluated over a reference text to compute Perplexity (lower is better). Used for language-modeling corpora like WikiText.
  \item[Code execution against unit tests \textnormal{[CE]}] The model generates code, which is executed in a sandbox against unit tests provided by a dataset (e.g., pass@1). Applies to HumanEval/MBPP/APPS, MultiPL-E, DS-1000, LiveCodeBench, etc.
\end{description}


% ----- Color + shorthand setup -----
\definecolor{catRC}{HTML}{E3F2FD}      % Reading/Open-Domain QA
\definecolor{catReason}{HTML}{E0F2F1}  % Multi-choice Reasoning
\definecolor{catExam}{HTML}{FFF3E0}    % Exams & Knowledge Tests
\definecolor{catMath}{HTML}{E8F5E9}    % Mathematics
\definecolor{catCode}{HTML}{F3E5F5}    % Coding
\definecolor{catOther}{HTML}{ECEFF1}   % Other (Truthfulness/NLI/LM)

\newcommand{\LL}{[LL]}   % Log-likelihood option scoring
\newcommand{\TG}{[TG]}   % Text generation (string match)
\newcommand{\PPL}{[PPL]} % Perplexity
\newcommand{\CE}{[CE]}   % Code execution against unit tests

% Small colored square for legend
% replace your \legendSquare macro with this
\newcommand{\legendSquare}[1]{%
  \begingroup
  \setlength{\fboxsep}{0pt}% no inner padding
  \fcolorbox{black!30}{#1}{\phantom{\rule{9pt}{9pt}}}% invisible content sets size
  \endgroup
}

\setlength{\tabcolsep}{6pt}
\renewcommand{\arraystretch}{1.12}

% ======================== TABLE ========================
\begin{longtable}{p{0.32\textwidth} p{0.12\textwidth} p{0.24\textwidth} p{0.26\textwidth}}
\caption{Benchmarks (short names), evaluation abbreviations, contrastive method (short), and traits. Versions merged where applicable.}
\label{tab:benchmarks-colored-short-cm}\\
\hline
\textbf{Benchmark} & \textbf{Eval} & \textbf{Method [CM]} & \textbf{Traits} \\
\hline
\endfirsthead
\hline
\textbf{Benchmark} & \textbf{Eval} & \textbf{Method [CM]} & \textbf{Traits} \\
\hline
\endhead

% ===== Reading & Open-Domain QA =====
\rowcolor{catRC} DROP \cite{dua2019drop} & \TG & \textbf{RC-Abstain} & reading comprehension \\
\rowcolor{catRC} ReCoRD \cite{zhang2018record} & \TG & \textbf{RC-Abstain} & reading comprehension \\
\rowcolor{catRC} SQuAD2 \cite{rajpurkar2018squad2} & \TG & \textbf{RC-Abstain} & reading comprehension \\
\rowcolor{catRC} WebQuestions \cite{berant2013webquestions} & \TG & \textbf{RC-Abstain} & factual QA \\
\rowcolor{catRC} Natural Questions \cite{kwiatkowski2019naturalquestions} & \TG & \textbf{RC-Abstain} & factual QA \\
\rowcolor{catRC} TriviaQA \cite{joshi2017triviaqa} & \TG & \textbf{RC-Abstain} & factual QA \\
\rowcolor{catRC} CoQA \cite{reddy2019coqa} & \TG & \textbf{ConvRC-Abstain} & conversational RC \\
\rowcolor{catRC} BoolQ \cite{clark2019boolq} & \LL & \textbf{2C-Flip} & boolean RC \\

% ===== Multi-choice Reasoning =====
\rowcolor{catReason} WinoGrande \cite{sakaguchi2019winogrande} & \LL & \textbf{2C-Flip} & commonsense \\
\rowcolor{catReason} PIQA \cite{bisk2019piqa} & \LL & \textbf{2C-Flip} & commonsense \\
\rowcolor{catReason} COPA \cite{roemmele2011copa} & \LL & \textbf{2C-Flip} & causal reasoning \\
\rowcolor{catReason} HellaSwag \cite{zellers2019hellaswag} & \LL & \textbf{MC-FirstDistr} & commonsense \\
\rowcolor{catReason} SWAG \cite{zellers2018swag} & \LL & \textbf{MC-FirstDistr} & commonsense \\
\rowcolor{catReason} OpenBookQA \cite{mihaylov2018openbookqa} & \LL & \textbf{MC-FirstDistr} & science MCQ \\

% ===== Exams & Knowledge Tests =====
\rowcolor{catExam} ARC \cite{clark2018arc} & \LL & \textbf{MC-FirstDistr} & science MCQ \\
\rowcolor{catExam} RACE \cite{lai2017race} & \LL & \textbf{MC-FirstDistr} & RC (MC) \\
\rowcolor{catExam} MMLU \cite{hendrycks2021mmlu} & \LL & \textbf{MC-FirstDistr} & multi-subject exams \\
\rowcolor{catExam} GPQA \cite{rein2023gpqa} & \LL/\TG & \textbf{MC-RandDistr} & expert STEM exams \\
\rowcolor{catExam} SuperGPQA \cite{du2025supergpqa} & \LL & \textbf{MC-FirstDistr} & expert STEM exams \\
\rowcolor{catExam} HLE \cite{phan2025hle} & \TG/\LL & \textbf{EM-PartialMask; MC-FirstDistr} & expert exams \\

% ===== Mathematics (versions merged) =====
\rowcolor{catMath} GSM8K \cite{cobbe2021gsm8k} & \TG & \textbf{Num+1} & mathematics \\
\rowcolor{catMath} ASDiv \cite{miao2021asdiv} & \TG & \textbf{Num+1} & mathematics \\
\rowcolor{catMath} Arithmetic \cite{brown2020gpt3} & \TG & \textbf{Num+1} & mathematics \\
\rowcolor{catMath} MATH \cite{hendrycks2021math} & \TG & \textbf{Num+1} & mathematics (contest) \\
\rowcolor{catMath} MATH\textendash500 \cite{hendrycks2021math} & \TG & \textbf{Num+1} & mathematics (contest) \\
\rowcolor{catMath} AIME \cite{} & \TG & \textbf{Num+1} & mathematics (contest) \\
\rowcolor{catMath} HMMT \cite{} & \TG & \textbf{Num+1} & mathematics (contest) \\
\rowcolor{catMath} PolyMath \cite{wang2025polymath} & \TG & \textbf{Num+1} & mathematics (multiling.) \\
\rowcolor{catMath} LiveMathBench \cite{liu2024livemathbench} & \TG & \textbf{Num+1} & mathematics (EN/ZH) \\

% ===== Coding =====
\rowcolor{catCode} MBPP \cite{austin2021program} & \CE & \textbf{KP-Del} & coding (Python) \\
\rowcolor{catCode} HumanEval \cite{chen2021evaluating} & \CE & \textbf{KP-Del} & coding (Python) \\
\rowcolor{catCode} CoNaLa \cite{yin2018conala} & \CE & \textbf{KP-Del} & coding (Python) \\
\rowcolor{catCode} CONCODE \cite{iyer2018mapping} & \CE & \textbf{KP-Del} & coding (Java) \\
\rowcolor{catCode} Mercury \cite{du2024mercury} & \CE & \textbf{KP-Del} & coding (multi-language) \\
\rowcolor{catCode} HumanEval+ \cite{liu2023evalplus} & \CE & \textbf{KP-Del} & coding (Python) \\
\rowcolor{catCode} InstructHumanEval \cite{codeparrot_instructhumaneval_2023} & \CE & \textbf{KP-Del} & coding (Python) \\
\rowcolor{catCode} MBPP+ \cite{liu2023evalplus} & \CE & \textbf{KP-Del} & coding (Python) \\
\rowcolor{catCode} APPS \cite{hendrycks2021apps} & \CE & \textbf{KP-Del} & coding (Python) \\
\rowcolor{catCode} DS\textendash1000 \cite{lai2022ds1000} & \CE & \textbf{KP-Del} & coding (Python) \\
\rowcolor{catCode} MultiPL\textendash E \cite{cassano2022multipl-e} & \CE & \textbf{KP-Del} & coding (multi-language) \\
\rowcolor{catCode} CodeXGLUE \cite{lu2021codexglue} & \TG & \textbf{Summ-WordDrop} & coding (code-to-text) \\
\rowcolor{catCode} ReCode \cite{wang2022recode} & \CE & \textbf{KP-Del} & coding (Python) \\
\rowcolor{catCode} LiveCodeBench \cite{jain2024livecodebench} & \CE & \textbf{KP-Del} & coding (Python) \\

% ===== Other (Truthfulness / NLI / Language Modeling) =====
\rowcolor{catOther} TruthfulQA \cite{lin2021truthfulqa} & \LL & \textbf{MC-LetterSwap} & truthfulness \\
\rowcolor{catOther} CB \cite{demarneffe2019commitmentbank} & \LL & \textbf{2C-Flip} & NLI \\
\rowcolor{catOther} WikiText (2/103) \cite{merity2016pointersentinel} & \PPL & \textbf{LM-CorruptCont} & language modeling \\

\hline
\end{longtable}

% --- Legend layout: LEFT = Category legend + Abbreviation legend (stacked),
%                     RIGHT = Method [CM] codes.
% Assumes category colors (catRC, catReason, ...) are defined.
% If not already defined, use this safer square (no black interior):
% \newcommand{\legendSquare}[1]{\begingroup\setlength{\fboxsep}{0pt}\fcolorbox{black!30}{#1}{\phantom{\rule{9pt}{9pt}}}\endgroup}

\vspace{-0.6em}
\noindent
\begin{minipage}[t]{0.48\linewidth}
\textbf{Category legend}\\[3pt]
\begin{tabular}{@{}ll@{}}
\legendSquare{catRC}     & RC/ODQA \\
\legendSquare{catReason} & Multi-choice Reasoning \\
\legendSquare{catExam}   & Exams \& Knowledge Tests \\
\legendSquare{catMath}   & Mathematics \\
\legendSquare{catCode}   & Coding \\
\legendSquare{catOther}  & Other (Truthfulness/NLI/LM) \\
\end{tabular}

\vspace{8pt}
\textbf{Abbreviation legend}\\[3pt]
\begin{tabular}{@{}ll@{}}
\texttt{[LL]}  & Log-likelihood option scoring \\
\texttt{[TG]}  & Text generation (string match) \\
\texttt{[PPL]} & Perplexity (LM) \\
\texttt{[CE]}  & Code execution vs.\ unit tests \\
\end{tabular}
\end{minipage}\hfill
\begin{minipage}[t]{0.48\linewidth}
\textbf{Method [CM] codes}\\[3pt]
\begin{tabular}{@{}ll@{}}
RC-Abstain      & RC abstention swap \\
ConvRC-Abstain  & Conversational RC abstention \\
LM-CorruptCont  & LM corrupted continuation \\
2C-Flip         & Two-choice flip \\
MC-FirstDistr   & First distractor (MC) \\
MC-RandDistr    & Random distractor (MC) \\
MC-LetterSwap   & Letter swap (MC) \\
Bool-Flip       & Boolean flip \\
EM-PartialMask  & Exact-match partial mask \\
KP-Del          & Keyword-preserving deletion \\
Summ-WordDrop   & Summary word drop \\
Num+1           & Numeric offset (+1) \\
\end{tabular}
\end{minipage}

% ======================== TABLE REASONING========================
\begin{longtable}{p{0.32\textwidth} p{0.12\textwidth} p{0.24\textwidth} p{0.26\textwidth}}
\caption{Benchmarks (short names), evaluation abbreviations, contrastive method (short), and traits. Versions merged where applicable.}
\label{tab:benchmarks-colored-short-cm}\\
\hline
\textbf{Benchmark} & \textbf{Eval} & \textbf{Method [CM]} & \textbf{Traits} \\
\hline
\endfirsthead
\hline
\textbf{Benchmark} & \textbf{Eval} & \textbf{Method [CM]} & \textbf{Traits} \\
\hline
\endhead

20\_newsgroups \cite{lang1995newsweeder} & \TG & \textbf{MC-FirstDistr} & reasoning \\
ag\_news \cite{zhang2015character} & \TG & \textbf{MC-FirstDistr} & reasoning \\
argument\_topic \cite{gretz2020argument} & \TG & \textbf{MC-FirstDistr} & reasoning \\
banking77 \cite{casanueva2020banking77} & \TG & \textbf{MC-FirstDistr} & reasoning \\
boolq \cite{clark2019boolq} & \LL & \textbf{2C-Flip} & reasoning \\
boolq-seq2seq \cite{clark2019boolq} & \TG & \textbf{2C-Flip} & reasoning \\
cb \cite{demarneffe2019commitmentbank} & \LL & \textbf{MC-FirstDistr} & reasoning \\
claim stance topic \cite{barhaim2017stance} & \TG & \textbf{MC-FirstDistr} & reasoning \\
cnn dailymail \cite{hermann2015teaching} & \TG & \textbf{Generic} & reasoning \\
dpedia 14 \cite{zhang2015character} & \TG & \textbf{MC-FirstDistr} & reasoning \\
ethos binary \cite{mollas2020ethos} & \TG & \textbf{MC-FirstDistr} & reasoning \\
financial tweets \cite{malo2014good} & \TG & \textbf{MC-FirstDistr} & reasoning \\
squadv2 \cite{rajpurkar2018squad2} & \TG & \textbf{RC-Abstain} & reasoning \\
logieval \cite{liu2023logieval} & \TG & \textbf{MC-FirstDistr} & reasoning \\
ledgar \cite{tuggener2020ledgar} & \TG & \textbf{MC-FirstDistr} & reasoning \\
logieval \cite{liu2023logieval} & \TG & \textbf{MC-FirstDistr} & reasoning \\
penn treebank \cite{marcus1993building} & \PPL & \textbf{LM-CorruptCont} & reasoning \\
medical abstracts \cite{schopf2022unsupervised} & \TG & \textbf{MC-FirstDistr} & reasoning \\
unfair tos \cite{lippi2019claudette} & \TG & \textbf{LM-CorruptCont} & reasoning \\
record \cite{zhang2018record} & \LL & \textbf{MC-FirstDistr} & reasoning \\
stsb \cite{cer2017semeval} & \TG & \textbf{2C-Flip} & reasoning \\
sglue-rte \cite{wang2019superglue} & \LL & \textbf{2C-Flip} & reasoning \\
xsum \cite{narayan2018xsum} & \TG & \textbf{Generic} & reasoning \\
yashoo answers topics \cite{zhang2015character} & \TG & \textbf{MC-FirstDistr} & reasoning \\
\end{longtable}

% ======================== TABLE MATHEMATICS========================
\begin{longtable}{p{0.32\textwidth} p{0.12\textwidth} p{0.24\textwidth} p{0.26\textwidth}}
\caption{Benchmarks (short names), evaluation abbreviations, contrastive method (short), and traits. Versions merged where applicable.}
\label{tab:benchmarks-colored-short-cm}\\
\hline
\textbf{Benchmark} & \textbf{Eval} & \textbf{Method [CM]} & \textbf{Traits} \\
\hline
\endfirsthead
\hline
\textbf{Benchmark} & \textbf{Eval} & \textbf{Method [CM]} & \textbf{Traits} \\
\hline
\endhead

afrimgsm direct amh \cite{adelani2024irokobench} & \TG & \textbf{Num+1} & mathematics \\
aime \cite{} & \TG & \textbf{Num+1} & mathematics \\
aime2024 \cite{} & \TG & \textbf{Num+1} & mathematics \\
aime2025 \cite{} & \TG & \textbf{Num+1} & mathematics \\
gsm \cite{cobbe2021gsm8k} & \TG & \textbf{Num+1} & mathematics \\
hmmt \cite{} & \TG & \textbf{Num+1} & mathematics \\
math \cite{hendrycks2021math} & \TG & \textbf{Num+1} & mathematics \\
math500 \cite{hendrycks2021math} & \TG & \textbf{Num+1} & mathematics \\
polymath \cite{wang2025polymath} & \TG & \textbf{Num+1} & mathematics \\
livemathbench \cite{liu2024livemathbench} & \TG & \textbf{Num+1} & mathematics \\
\hline
\end{longtable}

% ======================== TABLE CODING========================
\begin{longtable}{p{0.32\textwidth} p{0.12\textwidth} p{0.24\textwidth} p{0.26\textwidth}}
\caption{Benchmarks (short names), evaluation abbreviations, contrastive method (short), and traits. Versions merged where applicable.}
\label{tab:benchmarks-colored-short-cm}\\
\hline
\textbf{Benchmark} & \textbf{Eval} & \textbf{Method [CM]} & \textbf{Traits} \\
\hline
\endfirsthead
\hline
\textbf{Benchmark} & \textbf{Eval} & \textbf{Method [CM]} & \textbf{Traits} \\
\hline
\endhead

conala \cite{yin2018conala} & \TG & \textbf{L-Shuff} & coding \\
humaneval \cite{chen2021evaluating} & \CE & \textbf{} & coding \\
humaneval plus \cite{liu2023evalplus} & \CE & \textbf{} & coding \\
codexglue code2text \cite{lu2021codexglue} & \TG & \textbf{} & coding \\
codexglue text2code \cite{lu2021codexglue} & \TG & \textbf{} & coding \\

\hline
\end{longtable}

% ======================== TABLE MULTILINGUAL========================
\begin{longtable}{p{0.32\textwidth} p{0.12\textwidth} p{0.24\textwidth} p{0.26\textwidth}}
\caption{Benchmarks (short names), evaluation abbreviations, contrastive method (short), and traits. Versions merged where applicable.}
\label{tab:benchmarks-colored-short-cm}\\
\hline
\textbf{Benchmark} & \textbf{Eval} & \textbf{Method [CM]} & \textbf{Traits} \\
\hline
\endfirsthead
\hline
\textbf{Benchmark} & \textbf{Eval} & \textbf{Method [CM]} & \textbf{Traits} \\
\hline
\endhead

afrimmlu direct amh \cite{adelani2024irokobench} & \LL & \textbf{MC-FirstDistr} & multilingual \\
afrixnli en direct amh \cite{adelani2024irokobench} & \TG & \textbf{MC-FirstDistr} & multilingual \\
arabic exams \cite{hardalov2020exams} & \LL & \textbf{MC-FirstDistr} & multilingual \\
bangla mmlu \cite{nahin2025titullms} & \LL & \textbf{MC-FirstDistr} & multilingual \\
basque glue \cite{urbizu2022basqueglue} & \LL & \textbf{2C-Flip} & multilingual \\
copa \cite{roemmele2011copa} & \LL & \textbf{2C-Flip} & multilingual \\
global mmlu \cite{singh2024globalmmlu} & \LL & \textbf{MC-FirstDistr} & multilingual \\
m mmlu \cite{lai2023okapi} & \LL & \textbf{MC-FirstDistr} & multilingual \\
noticia \cite{garciaferrero2024noticia} & \LL & \textbf{Generic} & multilingual \\
phrases ca-va \cite{} & \TG & \textbf{Generic} & multilingual \\
wmt14 \cite{bojar2014wmt} & \TG & \textbf{L-Shuff} & multilingual \\
wmt16 \cite{bojar2016wmt} & \TG & \textbf{L-Shuff} & multilingual \\
\hline
\end{longtable}


% ======================== TABLE LONGCONTEXT========================
\begin{longtable}{p{0.32\textwidth} p{0.12\textwidth} p{0.24\textwidth} p{0.26\textwidth}}
\caption{Benchmarks (short names), evaluation abbreviations, contrastive method (short), and traits. Versions merged where applicable.}
\label{tab:benchmarks-colored-short-cm}\\
\hline
\textbf{Benchmark} & \textbf{Eval} & \textbf{Method [CM]} & \textbf{Traits} \\
\hline
\endfirsthead
\hline
\textbf{Benchmark} & \textbf{Eval} & \textbf{Method [CM]} & \textbf{Traits} \\
\hline
\endhead

babilong \cite{kuratov2024babilong} & \LL & \textbf{MC-RandDistr} & longcontext \\

\hline
\end{longtable}

% ======================== TABLE MEDICAL========================
\begin{longtable}{p{0.32\textwidth} p{0.12\textwidth} p{0.24\textwidth} p{0.26\textwidth}}
\caption{Benchmarks (short names), evaluation abbreviations, contrastive method (short), and traits. Versions merged where applicable.}
\label{tab:benchmarks-colored-short-cm}\\
\hline
\textbf{Benchmark} & \textbf{Eval} & \textbf{Method [CM]} & \textbf{Traits} \\
\hline
\endfirsthead
\hline
\textbf{Benchmark} & \textbf{Eval} & \textbf{Method [CM]} & \textbf{Traits} \\
\hline
\endhead

glianorex \cite{griot2025glianorex} & \LL & \textbf{MC-FirstDistr} & medical \\

\hline
\end{longtable}

% ======================== TABLE GENERAL KNOWLEDGE========================
\begin{longtable}{p{0.32\textwidth} p{0.12\textwidth} p{0.24\textwidth} p{0.26\textwidth}}
\caption{Benchmarks (short names), evaluation abbreviations, contrastive method (short), and traits. Versions merged where applicable.}
\label{tab:benchmarks-colored-short-cm}\\
\hline
\textbf{Benchmark} & \textbf{Eval} & \textbf{Method [CM]} & \textbf{Traits} \\
\hline
\endfirsthead
\hline
\textbf{Benchmark} & \textbf{Eval} & \textbf{Method [CM]} & \textbf{Traits} \\
\hline
\endhead

wikitext103 \cite{merity2016pointersentinel} & \PPL & \textbf{LM-CorruptCont} & general knowledge \\

\hline
\end{longtable}







\newpage


\section{Per-Task Results}

\section{Detailed Classification Results}

\section{Benchmark-Aided Steering Results}

\section{Optimal Sample Size Calculations}

\section{Fully Synthethic Generation}

\section{Agentic Capabilities}

\end{document}