{
  "title": "Wisent Guard",
  "description": "Latent space monitoring and guardrails for AI models. Detect hallucinations, harmful content, and steer model behavior using representation engineering. Includes interactive Jupyter notebooks for learning and experimentation.",
  "type": "serverless",
  "category": "language",
  "iconUrl": "https://raw.githubusercontent.com/Wisent-AI/wisent-guard/main/wisent/examples/notebooks/images/wisent_logo.png",

  "config": {
    "runsOn": "GPU",
    "containerDiskInGb": 50,

    "gpuCount": 1,
    "gpuIds": "ADA_24,ADA_48,AMPERE_48,AMPERE_80",
    "allowedCudaVersions": [
      "12.4", "12.3", "12.2", "12.1", "12.0", "11.8"
    ],

    "presets": [
      {
        "name": "Qwen3-8B (Recommended)",
        "defaults": {
          "MODEL_NAME": "Qwen/Qwen3-8B",
          "TASK": "truthfulqa_gen",
          "LAYER": "19",
          "TRAINING_LIMIT": "100",
          "JUPYTER_PORT": "8888"
        }
      },
      {
        "name": "Llama-3.2-3B (Smaller)",
        "defaults": {
          "MODEL_NAME": "meta-llama/Llama-3.2-3B-Instruct",
          "TASK": "truthfulqa_gen",
          "LAYER": "14",
          "TRAINING_LIMIT": "100",
          "JUPYTER_PORT": "8888"
        }
      },
      {
        "name": "Mistral-7B-v0.3",
        "defaults": {
          "MODEL_NAME": "mistralai/Mistral-7B-Instruct-v0.3",
          "TASK": "truthfulqa_gen",
          "LAYER": "16",
          "TRAINING_LIMIT": "100",
          "JUPYTER_PORT": "8888"
        }
      }
    ],

    "env": [
      {
        "key": "MODEL_NAME",
        "input": {
          "name": "Model",
          "type": "huggingface",
          "description": "HuggingFace model ID for the base LLM to guard against hallucinations",
          "default": "Qwen/Qwen3-8B",
          "required": true
        }
      },
      {
        "key": "TASK",
        "input": {
          "name": "Task",
          "type": "string",
          "description": "Benchmark task for training the hallucination classifier",
          "options": [
            {"label": "TruthfulQA (Hallucination)", "value": "truthfulqa_gen"},
            {"label": "MMLU (Knowledge)", "value": "mmlu"},
            {"label": "HellaSwag (Reasoning)", "value": "hellaswag"},
            {"label": "ARC Challenge", "value": "arc_challenge"}
          ],
          "default": "truthfulqa_gen",
          "advanced": false
        }
      },
      {
        "key": "LAYER",
        "input": {
          "name": "Layer",
          "type": "number",
          "description": "Model layer to extract activations from (optimal layer varies by model)",
          "min": 1,
          "max": 80,
          "default": 19,
          "advanced": true
        }
      },
      {
        "key": "TRAINING_LIMIT",
        "input": {
          "name": "Training Samples",
          "type": "number",
          "description": "Number of contrastive pairs for training the classifier",
          "min": 50,
          "max": 1000,
          "default": 100,
          "advanced": true
        }
      },
      {
        "key": "HF_TOKEN",
        "input": {
          "name": "HuggingFace Token",
          "type": "string",
          "description": "HuggingFace API token for accessing gated models (e.g., Llama)",
          "default": "",
          "advanced": false
        }
      },
      {
        "key": "JUPYTER_PORT",
        "input": {
          "name": "Jupyter Port",
          "type": "number",
          "description": "Port for JupyterLab server",
          "min": 8000,
          "max": 9000,
          "default": 8888,
          "advanced": true
        }
      },
      {
        "key": "JUPYTER_PASSWORD",
        "input": {
          "name": "Jupyter Password",
          "type": "string",
          "description": "Password for JupyterLab access (leave empty for token auth)",
          "default": "",
          "advanced": true
        }
      }
    ]
  }
}
